import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import streamlit as st
from openai import AzureOpenAI
import tempfile
from io import BytesIO
from pydub import AudioSegment
import fitz
import torch
import pandas as pd
from dotenv import load_dotenv
import torchaudio
from speechbrain.pretrained import EncoderClassifier
import numpy as np
import zipfile
from datetime import timedelta, datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import json
import importlib
import base64
import uuid
import subprocess
from docx import Document as DocxDocument
from pptx import Presentation
from pathlib import Path
from streamlit.components.v1 import html as components_html

torch.classes.__path__ = []

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—ï¼ˆAzure OpenAI ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ»API ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰
AZURE_OPENAI_ENDPOINT = os.environ.get("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.environ.get("AZURE_OPENAI_API_KEY")
API_VERSION = "2025-03-01-preview"  # gpt-4o-transcribe ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³

# RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€è¨­å®š
DEFAULT_RAGDB_FOLDER = ""  # ç©ºæ–‡å­—åˆ—ã®å ´åˆã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
# ä¾‹: DEFAULT_RAGDB_FOLDER = "C:/Users/username/Documents/ragdb"
# ä¾‹: DEFAULT_RAGDB_FOLDER = "./data/ragdb"

DEFAULT_MEETING_TYPES = [
    {
        "name": "çµŒå–¶ä¼šè­°",
        "id": "executive_meeting",
        "embeddings_folder": "speaker_embeddings/executive",
        "description": "æœˆä¾‹çµŒå–¶ä¼šè­°ï¼ˆå½¹å“¡ãƒ¡ãƒ³ãƒãƒ¼å›ºå®šï¼‰",
    },
    {
        "name": "é–‹ç™ºãƒãƒ¼ãƒ å®šä¾‹",
        "id": "dev_team_meeting",
        "embeddings_folder": "speaker_embeddings/dev_team",
        "description": "é€±æ¬¡é–‹ç™ºãƒãƒ¼ãƒ ä¼šè­°",
    },
    {
        "name": "å–¶æ¥­å®šä¾‹",
        "id": "sales_meeting",
        "embeddings_folder": "speaker_embeddings/sales",
        "description": "æœˆæ¬¡å–¶æ¥­ä¼šè­°",
    },
    {
        "name": "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆæ‰‹å‹•é¸æŠï¼‰",
        "id": "custom",
        "embeddings_folder": "",
        "description": "ä¼šè­°ã‚¿ã‚¤ãƒ—ã‚’æŒ‡å®šã›ãšã€æ‰‹å‹•ã§è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’é¸æŠ",
    },
]


def _extract_pdf(file: BytesIO) -> str:
    file_bytes = file.read()
    file.seek(0)
    pdf_document = fitz.open(stream=file_bytes, filetype='pdf')
    text = "".join(page.get_text() for page in pdf_document)
    pdf_document.close()
    return text

def _extract_docx(file: BytesIO) -> str:
    doc = DocxDocument(file)
    text = "\n".join(p.text for p in doc.paragraphs)
    for table in doc.tables:
        text += "\n" + "\n".join(" ".join(cell.text for cell in row.cells) for row in table.rows)
    return text.strip()

def _extract_pptx(file: BytesIO) -> str:
    presentation = Presentation(file)
    text_parts = []
    for slide_num, slide in enumerate(presentation.slides, 1):
        text_parts.append(f"\n--- ã‚¹ãƒ©ã‚¤ãƒ‰ {slide_num} ---\n")
        for shape in slide.shapes:
            if hasattr(shape, "text") and shape.text:
                text_parts.append(shape.text + "\n")
            if shape.has_table:
                for row in shape.table.rows:
                    text_parts.append(" ".join(cell.text for cell in row.cells) + "\n")
    return "".join(text_parts).strip()

def _extract_msg(file: BytesIO) -> str:
    try:
        import extract_msg
    except ImportError:
        raise Exception("MSGãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«ã¯ extract-msg ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚pip install extract-msg ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".msg") as temp_file:
        temp_file.write(file.read())
        temp_path = temp_file.name

    try:
        msg = extract_msg.Message(temp_path)
        parts = []
        if msg.subject:
            parts.append(f"ä»¶å: {msg.subject}\n")
        if msg.sender:
            parts.append(f"é€ä¿¡è€…: {msg.sender}\n")
        if msg.to:
            parts.append(f"å®›å…ˆ: {msg.to}\n")
        if msg.body:
            parts.append(f"\n{msg.body}")
        msg.close()
        return "\n".join(parts).strip()
    finally:
        if os.path.exists(temp_path):
            os.unlink(temp_path)

def _extract_txt(file: BytesIO) -> str:
    file_content = file.read()
    for encoding in ['utf-8', 'cp932', 'shift_jis', 'utf-16', 'iso-2022-jp']:
        try:
            return file_content.decode(encoding).strip()
        except UnicodeDecodeError:
            continue
    raise Exception("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸ")

FILE_EXTRACTORS = {
    'pdf': _extract_pdf,
    'docx': _extract_docx,
    'pptx': _extract_pptx,
    'txt': _extract_txt,
    'msg': _extract_msg,
}

def extract_text_from_file(file, file_extension):
    """ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    extractor = FILE_EXTRACTORS.get(file_extension.lower())
    if not extractor:
        raise Exception(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file_extension}")
    try:
        return extractor(file)
    except Exception as e:
        raise Exception(f"{file_extension.upper()}èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def _create_azure_client():
    """Azure OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    return AzureOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=API_VERSION,
    )

def generate_summary(model, prompt, text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„"""
    client = _create_azure_client()
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": text},
        ],
    )
    print(f"Response: {response}")
    return response.choices[0].message.content

from contextlib import contextmanager

@contextmanager
def temp_file_path(data: bytes, suffix: str):
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ãƒ‘ã‚¹ã‚’è¿”ã™ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(data)
        tmp_path = tmp.name
    try:
        yield tmp_path
    finally:
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)


def trigger_auto_download(data: bytes, file_name: str, key: str | None, mime: str = "application/octet-stream"):
    """Streamlitã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ã£ã¦å³æ™‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹"""
    if not data:
        return

    encoded = base64.b64encode(data).decode()
    mime_js = json.dumps(mime)
    file_name_js = json.dumps(file_name)
    element_id_js = json.dumps(key or f"dl_{uuid.uuid4().hex}")

    components_html(
        f"""
        <div id={element_id_js}></div>
        <script>
            (function() {{
                const mimeType = {mime_js};
                const fileName = {file_name_js};
                const link = document.createElement('a');
                link.href = "data:" + mimeType + ";base64,{encoded}";
                link.download = fileName;
                link.style.display = 'none';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                const element = document.getElementById({element_id_js});
                if (element) {{
                    element.remove();
                }}
            }})();
        </script>
        """,
        height=0,
    )


def transcribe_audio_to_dataframe(uploaded_file: BytesIO, reference_file: BytesIO = None, model: str = "gpt-4o-transcribe-diarize"):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆãƒ¢ãƒ‡ãƒ«é¸æŠå¯èƒ½ã€25MBåˆ¶é™å¯¾å¿œï¼‰

    Args:
        uploaded_file: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        reference_file: å‚è€ƒè³‡æ–™ï¼ˆWhisperã®ã¿ã‚µãƒãƒ¼ãƒˆï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("gpt-4o-transcribe-diarize" ã¾ãŸã¯ "whisper")
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ25MB = 26,214,400 bytesï¼‰
    MAX_FILE_SIZE = 25 * 1024 * 1024
    uploaded_file.seek(0)
    file_size = len(uploaded_file.getvalue())
    uploaded_file.seek(0)

    # 25MBä»¥ä¸Šã®å ´åˆã¯åˆ†å‰²å‡¦ç†
    if file_size > MAX_FILE_SIZE:
        st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ {file_size / (1024*1024):.1f}MB ã§ã™ã€‚25MBåˆ¶é™ã®ãŸã‚ã€éŸ³å£°ã‚’åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")
        return _transcribe_large_audio_chunked(uploaded_file, reference_file, model)

    # 25MBæœªæº€ã®å ´åˆã¯é€šå¸¸å‡¦ç†
    return _transcribe_audio_single(uploaded_file, reference_file, model)

def _transcribe_large_audio_chunked(uploaded_file: BytesIO, reference_file: BytesIO = None, model: str = "gpt-4o-transcribe-diarize"):
    """å¤§ããªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦æ–‡å­—èµ·ã“ã—

    Args:
        uploaded_file: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        reference_file: å‚è€ƒè³‡æ–™
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«

    Returns:
        pd.DataFrame: æ–‡å­—èµ·ã“ã—çµæœ
    """
    try:
        suffix = f".{uploaded_file.name.split('.')[-1]}"

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        with temp_file_path(uploaded_file.getvalue(), suffix) as tmp_path:
            audio = AudioSegment.from_file(tmp_path)

        # éŸ³å£°ã®é•·ã•ï¼ˆãƒŸãƒªç§’ï¼‰
        total_duration_ms = len(audio)
        total_duration_sec = total_duration_ms / 1000

        # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’æ±ºå®šï¼ˆ10åˆ† = 600ç§’ = 600,000ãƒŸãƒªç§’ï¼‰
        CHUNK_DURATION_MS = 10 * 60 * 1000  # 10åˆ†

        # ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¨ˆç®—
        num_chunks = (total_duration_ms + CHUNK_DURATION_MS - 1) // CHUNK_DURATION_MS

        st.info(f"ğŸ“Š éŸ³å£°é•·: {total_duration_sec/60:.1f}åˆ†ã€{num_chunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™")

        # é€²æ—è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()

        all_segments = []

        for i in range(num_chunks):
            start_ms = i * CHUNK_DURATION_MS
            end_ms = min((i + 1) * CHUNK_DURATION_MS, total_duration_ms)

            status_text.write(f"ğŸ¤ ãƒãƒ£ãƒ³ã‚¯ {i+1}/{num_chunks} ã‚’å‡¦ç†ä¸­... ({start_ms/1000:.1f}ç§’ ï½ {end_ms/1000:.1f}ç§’)")

            # ãƒãƒ£ãƒ³ã‚¯ã‚’æŠ½å‡º
            chunk = audio[start_ms:end_ms]

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            chunk_io = BytesIO()
            chunk.export(chunk_io, format="mp3", bitrate="192k")
            chunk_io.seek(0)
            chunk_io.name = f"chunk_{i}.mp3"

            # ãƒãƒ£ãƒ³ã‚¯ã‚’æ–‡å­—èµ·ã“ã—
            try:
                chunk_df = _transcribe_audio_single(chunk_io, reference_file, model)

                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´
                if not chunk_df.empty and 'start' in chunk_df.columns and 'end' in chunk_df.columns:
                    offset_sec = start_ms / 1000
                    chunk_df['start'] = chunk_df['start'] + offset_sec
                    chunk_df['end'] = chunk_df['end'] + offset_sec

                all_segments.append(chunk_df)

            except Exception as e:
                st.error(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

            progress_bar.progress((i + 1) / num_chunks)

        # ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
        if all_segments:
            result_df = pd.concat(all_segments, ignore_index=True)
            status_text.write(f"âœ… åˆ†å‰²å‡¦ç†å®Œäº†ï¼åˆè¨ˆ {len(result_df)} å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
            return result_df
        else:
            st.error("âŒ ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pd.DataFrame(columns=["start", "end", "speaker", "text"])

    except Exception as e:
        st.error(f"âŒ åˆ†å‰²å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        st.error(traceback.format_exc())
        return pd.DataFrame(columns=["start", "end", "speaker", "text"])

def _transcribe_audio_single(uploaded_file: BytesIO, reference_file: BytesIO = None, model: str = "gpt-4o-transcribe-diarize"):
    """å˜ä¸€ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆå†…éƒ¨ç”¨ï¼‰

    Args:
        uploaded_file: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        reference_file: å‚è€ƒè³‡æ–™ï¼ˆWhisperã®ã¿ã‚µãƒãƒ¼ãƒˆï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("gpt-4o-transcribe-diarize" ã¾ãŸã¯ "whisper")
    """
    # ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ãŸAPIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’é¸æŠ
    if model == "whisper":
        api_version = "2024-06-01"  # Whisperç”¨ã®å®‰å®šç‰ˆAPIãƒãƒ¼ã‚¸ãƒ§ãƒ³
        st.info(f"ğŸ”§ Whisperãƒ¢ãƒ‡ãƒ«ç”¨ã«APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ {api_version} ã‚’ä½¿ç”¨ã—ã¾ã™")
    else:
        api_version = "2025-03-01-preview"  # gpt-4o-transcribe-diarizeç”¨

    # ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    client = AzureOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=api_version,
    )

    try:
        suffix = f".{uploaded_file.name.split('.')[-1]}"

        if model == "gpt-4o-transcribe-diarize":
            # gpt-4o-transcribe-diarizeãƒ¢ãƒ‡ãƒ«ï¼ˆè©±è€…è­˜åˆ¥ä»˜ãï¼‰
            if reference_file:
                st.warning("âš ï¸ gpt-4o-transcribe-diarizeãƒ¢ãƒ‡ãƒ«ã¯å‚è€ƒè³‡æ–™ï¼ˆpromptï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚å‚è€ƒè³‡æ–™ã¯ç„¡è¦–ã•ã‚Œã¾ã™ã€‚")

            st.info("æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆgpt-4o-transcribe-diarizeã€è©±è€…è­˜åˆ¥ä»˜ãï¼‰...")

            with temp_file_path(uploaded_file.getvalue(), suffix) as tmp_path:
                with open(tmp_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="gpt-4o-transcribe-diarize",
                        file=(uploaded_file.name, audio_file, f"audio/{uploaded_file.name.split('.')[-1]}"),
                        response_format="diarized_json",
                        chunking_strategy="auto"
                    )

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            transcript_dict = transcript.model_dump()
            segments = transcript_dict.get("segments", [])

            if segments:
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                seg_list = []
                for seg in segments:
                    seg_list.append({
                        "start": seg.get("start", 0),
                        "end": seg.get("end", 0),
                        "speaker": seg.get("speaker", ""),
                        "text": seg.get("text", "")
                    })

                st.success(f"æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆ{len(seg_list)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã€è©±è€…è­˜åˆ¥ä»˜ãï¼‰")
                seg_df = pd.DataFrame(seg_list)
                return seg_df
            else:
                # segmentsãŒãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’å–å¾—
                text = transcript_dict.get("text", "")
                if text:
                    st.warning("âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")
                    seg_df = pd.DataFrame([{
                        "start": 0,
                        "end": 0,
                        "speaker": "",
                        "text": text
                    }])
                    return seg_df
                else:
                    st.error("âŒ æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸ")
                    return pd.DataFrame(columns=["start", "end", "speaker", "text"])

        elif model == "whisper":
            # Whisperãƒ¢ãƒ‡ãƒ«ï¼ˆè©±è€…è­˜åˆ¥ãªã—ï¼‰
            st.info("æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆWhisperã€è©±è€…è­˜åˆ¥ãªã—ï¼‰...")

            with temp_file_path(uploaded_file.getvalue(), suffix) as tmp_path:
                with open(tmp_path, "rb") as audio_file:
                    # promptãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æº–å‚™
                    kwargs = {
                        "model": "whisper",
                        "file": (uploaded_file.name, audio_file, f"audio/{uploaded_file.name.split('.')[-1]}"),
                        "response_format": "verbose_json"
                    }

                    # å‚è€ƒè³‡æ–™ãŒã‚ã‚‹å ´åˆã¯promptã¨ã—ã¦ä½¿ç”¨
                    if reference_file:
                        try:
                            file_extension = reference_file.name.split(".")[-1].lower()
                            reference_text = extract_text_from_file(BytesIO(reference_file.read()), file_extension)
                            if reference_text:
                                # promptã¯æœ€å¤§224ãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ã«åˆ¶é™ï¼ˆç´„1000æ–‡å­—ï¼‰
                                kwargs["prompt"] = reference_text[:1000]
                                st.info("âœ… å‚è€ƒè³‡æ–™ã‚’promptã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™")
                        except Exception as e:
                            st.warning(f"âš ï¸ å‚è€ƒè³‡æ–™ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

                    transcript = client.audio.transcriptions.create(**kwargs)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            transcript_dict = transcript.model_dump()
            segments = transcript_dict.get("segments", [])

            if segments:
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ï¼ˆè©±è€…æƒ…å ±ã¯ç©ºï¼‰
                seg_list = []
                for seg in segments:
                    seg_list.append({
                        "start": seg.get("start", 0),
                        "end": seg.get("end", 0),
                        "speaker": "",  # Whisperã¯è©±è€…è­˜åˆ¥ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„
                        "text": seg.get("text", "")
                    })

                st.success(f"æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆ{len(seg_list)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã€Whisperä½¿ç”¨ï¼‰")
                seg_df = pd.DataFrame(seg_list)
                return seg_df
            else:
                # segmentsãŒãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’å–å¾—
                text = transcript_dict.get("text", "")
                if text:
                    st.warning("âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")
                    seg_df = pd.DataFrame([{
                        "start": 0,
                        "end": 0,
                        "speaker": "",
                        "text": text
                    }])
                    return seg_df
                else:
                    st.error("âŒ æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸ")
                    return pd.DataFrame(columns=["start", "end", "speaker", "text"])
        else:
            st.error(f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«: {model}")
            return pd.DataFrame(columns=["start", "end", "speaker", "text"])

    except Exception as e:
        st.error(f"âŒ æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        st.error(f"**ã‚¨ãƒ©ãƒ¼è©³ç´°**: {str(e)}")
        st.error(f"**ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: {model}")
        st.error(f"**APIãƒãƒ¼ã‚¸ãƒ§ãƒ³**: {api_version}")

        import traceback
        error_details = traceback.format_exc()

        with st.expander("ğŸ” è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"):
            st.code(error_details, language="python")

        # ã‚¨ãƒ©ãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        print(f"===== Transcription Error =====")
        print(f"Model: {model}")
        print(f"API Version: {api_version}")
        print(f"Error: {e}")
        print(error_details)
        print(f"==============================")

        return pd.DataFrame(columns=["start", "end", "speaker", "text"])

@st.cache_resource
def load_speaker_encoder():
    """Caches the SpeechBrain speaker encoder model."""
    return EncoderClassifier.from_hparams(
        source="speechbrain/spkrec-ecapa-voxceleb",
        run_opts={"device": "cpu"}
    )

def _compute_embedding_from_wav_bytes(wav_bytes: bytes) -> np.ndarray:
    """Compute a speaker embedding from WAV bytes using SpeechBrain."""
    with temp_file_path(wav_bytes, ".wav") as wav_path:
        waveform, sample_rate = torchaudio.load(wav_path)

    if waveform.shape[0] > 1:
        waveform = waveform.mean(dim=0, keepdim=True)

    target_sr = 16000
    if sample_rate != target_sr:
        waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)(waveform)

    encoder = load_speaker_encoder()
    waveform = waveform.to(dtype=torch.float32)

    with torch.no_grad():
        embedding = encoder.encode_batch(waveform)

    return embedding.squeeze().cpu().numpy()

def extract_embedding(audio_content):
    """Extracts embedding from audio content using SpeechBrain."""
    audio_bytes = audio_content.read()
    audio_content.seek(0)

    try:
        audio_segment = AudioSegment.from_file(BytesIO(audio_bytes))
        wav_bytes = audio_segment.export(format="wav").read()
    except Exception:
        wav_bytes = audio_bytes

    return _compute_embedding_from_wav_bytes(wav_bytes)

def load_speaker_embeddings_from_files(uploaded_files):
    """Loads known speaker embeddings from uploaded files.

    Args:
        uploaded_files: ãƒªã‚¹ãƒˆã¾ãŸã¯ã‚¿ãƒ—ãƒ«ã€‚å„è¦ç´ ã¯ä»¥ä¸‹ã®ã„ãšã‚Œã‹ï¼š
            - Streamlit UploadedFile ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆfile_uploaderã‹ã‚‰ï¼‰
            - è¾æ›¸ {'name': filename, 'data': file_bytes}ï¼ˆãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å ´åˆï¼‰

    Returns:
        dict: {speaker_name: embedding_array}
    """
    if not uploaded_files:
        st.warning("è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return {}

    speaker_embeddings = {}
    for uploaded_file in uploaded_files:
        try:
            # è¾æ›¸å½¢å¼ï¼ˆãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å ´åˆï¼‰ã‹UploadedFileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚’åˆ¤å®š
            if isinstance(uploaded_file, dict):
                # è¾æ›¸å½¢å¼: {'name': filename, 'data': file_bytes}
                filename = uploaded_file['name']
                file_data = BytesIO(uploaded_file['data'])
            else:
                # UploadedFile ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
                filename = uploaded_file.name
                file_data = uploaded_file

            filename_stem = Path(filename).stem
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®åŒºåˆ‡ã‚Šæ–‡å­—ã§è©±è€…åã‚’æŠ½å‡º
            for delimiter in ['â€—', '_']:
                if delimiter in filename_stem:
                    filename_stem = filename_stem.split(delimiter)[0]
                    break
            speaker_name = filename_stem.strip()

            if not speaker_name:
                speaker_name = Path(filename).stem

            speaker_embeddings[speaker_name] = np.load(file_data)
        except Exception as e:
            filename_str = uploaded_file.get('name') if isinstance(uploaded_file, dict) else getattr(uploaded_file, 'name', 'unknown')
            st.error(f"åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ {filename_str}: {e}")
    return speaker_embeddings

def _calculate_similarity(embedding1, embedding2):
    """2ã¤ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))

def _identify_speaker(segment_embedding, known_embeddings, threshold):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŸ‹ã‚è¾¼ã¿ã‹ã‚‰è©±è€…ã‚’è­˜åˆ¥"""
    best_speaker, best_similarity = None, -1
    for speaker_name, known_embedding in known_embeddings.items():
        similarity = _calculate_similarity(segment_embedding, known_embedding)
        print(f"Comparing segment with {speaker_name}: similarity = {similarity:.4f}")
        if similarity > best_similarity:
            best_similarity, best_speaker = similarity, speaker_name
    return best_speaker if best_similarity >= threshold else ""

def identify_speakers_in_dataframe(audio_file, df: pd.DataFrame, uploaded_embedding_files, similarity_threshold: float) -> pd.DataFrame:
    known_embeddings = load_speaker_embeddings_from_files(uploaded_embedding_files)
    if not known_embeddings:
        st.warning("æ—¢çŸ¥ã®è©±è€…åŸ‹ã‚è¾¼ã¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è­˜åˆ¥ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
        df['speaker'] = None
        return df

    st.info(f"Loaded embeddings for speakers: {list(known_embeddings.keys())}")

    with temp_file_path(audio_file.getvalue(), ".wav") as audio_path:
        try:
            audio = AudioSegment.from_file(audio_path)
            df['speaker'] = None
            progress_bar, status_text = st.progress(0), st.empty()

            for index, row in df.iterrows():
                segment = audio[row['start'] * 1000:row['end'] * 1000]

                try:
                    segment_wav_bytes = segment.export(format="wav").read()
                    segment_embedding = _compute_embedding_from_wav_bytes(segment_wav_bytes)
                    speaker = _identify_speaker(segment_embedding, known_embeddings, similarity_threshold)
                    df.at[index, 'speaker'] = speaker
                    status = f"Identified as {speaker}" if speaker else "Similarity below threshold"
                    status_text.text(f"Processed segment {index + 1}/{len(df)}: {status}")
                except Exception as e:
                    st.error(f"Error processing segment {row['start']}-{row['end']}s: {e}")
                    df.at[index, 'speaker'] = "Error"

                progress_bar.progress((index + 1) / len(df))

            status_text.text("Speaker identification complete.")
            return df

        except Exception as e:
            st.error(f"Error loading or processing audio file: {e}")
            return df

def build_meeting_text_from_dataframe(df: pd.DataFrame) -> str:
    """Generate combined meeting text in (speaker) utterance format from transcription data."""
    if df is None or df.empty or 'text' not in df.columns:
        return ""

    if 'speaker' in df.columns:
        df_copy = df.copy()
        df_copy['speaker_filled'] = df_copy['speaker'].replace('', pd.NA)
        df_copy['speaker_filled'] = df_copy['speaker_filled'].ffill()
        df_copy['group_id'] = (df_copy['speaker_filled'] != df_copy['speaker_filled'].shift()).cumsum()
        df_merged = df_copy.groupby('group_id').agg(
            speaker=('speaker_filled', 'first'),
            text=('text', lambda values: ' '.join(map(str, values)))
        ).reset_index(drop=True)

        lines = []
        for _, row in df_merged.iterrows():
            speaker = row.get('speaker')
            text = row.get('text', '')
            speaker_str = speaker if isinstance(speaker, str) and speaker else 'ä¸æ˜'
            lines.append(f"ï¼ˆ{speaker_str}ï¼‰{text}")
        return "\n".join(lines)

    # speakeråˆ—ãŒãªã„å ´åˆã¯ä¸æ˜è©±è€…ã¨ã—ã¦æ‰±ã†
    lines = []
    for text in df['text'].astype(str):
        lines.append(f"ï¼ˆä¸æ˜ï¼‰{text}")
    return "\n".join(lines)

def format_time(seconds):
    """Formats seconds into HH:MM:SS."""
    td = timedelta(seconds=seconds)
    hours, remainder = divmod(td.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{hours:02}:{minutes:02}:{seconds:02}"

def parse_time_to_seconds(time_str):
    """Converts HH:MM:SS or seconds string to total seconds."""
    if ':' in time_str:
        parts = list(map(int, time_str.split(':')))
        if len(parts) == 3:
            return parts[0] * 3600 + parts[1] * 60 + parts[2]
        elif len(parts) == 2:
            return parts[0] * 60 + parts[1]
        else:
            raise ValueError("Invalid time format. Use HH:MM:SS or MM:SS.")
    else:
        return int(time_str)

def split_text_by_lines(text, n_parts):
    """æ–‡å­—åˆ—ã‚’æ”¹è¡Œä½ç½®ã§é©åˆ‡ã«nåˆ†å‰²"""
    if n_parts <= 0:
        raise ValueError("åˆ†å‰²æ•°ã¯1ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
    if n_parts == 1:
        return [text]

    lines = text.split('\n')
    total_lines = len(lines)

    if total_lines <= n_parts:
        return lines + [""] * (n_parts - total_lines)

    lines_per_part = total_lines // n_parts
    remainder = total_lines % n_parts

    result, start = [], 0
    for i in range(n_parts):
        count = lines_per_part + (1 if i < remainder else 0)
        result.append('\n'.join(lines[start:start + count]))
        start += count

    return result

class RAGProofreadingSystem:
    """RAGæ©Ÿèƒ½å‰Šé™¤å¾Œã®ãƒ€ãƒŸãƒ¼æ ¡æ­£ã‚·ã‚¹ãƒ†ãƒ """

    DEFAULT_TEMPERATURE = 0.3

    def __init__(self, azure_endpoint, azure_api_key, api_version):
        self.azure_endpoint = azure_endpoint
        self.azure_api_key = azure_api_key
        self.api_version = api_version
        self.client = AzureOpenAI(
            azure_endpoint=azure_endpoint,
            api_key=azure_api_key,
            api_version=api_version
        )
        self.documents = []

    def create_knowledge_base(self, documents_text_list, mode="add", documents_metadata=None):
        st.info("RAGæ©Ÿèƒ½ã¯å‰Šé™¤ã•ã‚ŒãŸãŸã‚ã€ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        self.documents = []
        return False

    def retrieve_relevant_context(self, query, search_type="similarity", top_k=None):
        return ""

    def rag_enhanced_proofread(self, text, model="gpt-4o", search_type="similarity", top_k=None, prompt_preset="standard"):
        """RAGãªã—ã®ç°¡æ˜“æ ¡æ­£ã‚’å®Ÿè¡Œ"""
        try:
            system_prompt = (
                "ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚é–¢é€£è³‡æ–™ã‚’ç”¨ã„ãšã«ã€å…¥åŠ›ã•ã‚ŒãŸè­°äº‹éŒ²ã‚’åŸºæœ¬çš„ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚"
                "ä¸»ã«èª¤å­—è„±å­—ã¨æ˜ç¢ºã•ã®æ”¹å–„ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚"
            )
            st.info("RAGæ©Ÿèƒ½ã¯å‰Šé™¤ã•ã‚ŒãŸãŸã‚ã€å¤–éƒ¨æ–‡è„ˆã‚’å‚ç…§ã—ãªã„ç°¡æ˜“æ ¡æ­£ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                temperature=self.DEFAULT_TEMPERATURE,
            )
            return response.choices[0].message.content
        except Exception as e:
            st.error(f"æ ¡æ­£å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def save_knowledge_base(self, output_path):
        return False, "RAGæ©Ÿèƒ½å‰Šé™¤ã«ã‚ˆã‚Šä¿å­˜ã§ãã¾ã›ã‚“"

    def load_knowledge_base(self, input_path):
        return False, "RAGæ©Ÿèƒ½å‰Šé™¤ã«ã‚ˆã‚Šèª­ã¿è¾¼ã‚ã¾ã›ã‚“", {}

    def get_database_info(self):
        return {
            "has_data": False,
            "documents_count": 0,
            "is_indexed": False,
            "total_chunks": 0,
            "vector_files": 0,
            "output_files": 0,
            "search_types": []
        }

    def get_chunks_detail(self):
        return []

    def clear_knowledge_base(self):
        self.documents = []

# ========================================
# å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ========================================

def _init_rag_system():
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆå…±é€šå‡¦ç†ï¼‰"""
    if 'global_rag_system' not in st.session_state:
        st.session_state.global_rag_system = RAGProofreadingSystem(
            azure_endpoint=AZURE_OPENAI_ENDPOINT,
            azure_api_key=AZURE_OPENAI_API_KEY,
            api_version=API_VERSION
        )

    if 'global_db_info' not in st.session_state:
        st.session_state.global_db_info = st.session_state.global_rag_system.get_database_info()

    return st.session_state.global_rag_system

def _render_database_status(db_status, show_output_files=False):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹è¡¨ç¤ºï¼ˆå…±é€šå‡¦ç†ï¼‰"""
    metrics = [
        ("ãƒãƒ£ãƒ³ã‚¯æ•°", db_status.get('total_chunks', 0)),
        ("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹", "âœ… æ§‹ç¯‰æ¸ˆã¿" if db_status.get('is_indexed', False) else "âŒ æœªæ§‹ç¯‰")
    ]

    if show_output_files:
        metrics.insert(1, ("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•°", db_status.get('output_files', 0)))

    for col, (label, value) in zip(st.columns(len(metrics)), metrics):
        with col:
            st.metric(label, value)

def _render_database_operations(rag_system, key_prefix="", show_save=True):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œUIï¼ˆå…±é€šå‡¦ç†ï¼‰"""
    st.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ")

    has_data = st.session_state.global_db_info.get('has_data', False)
    cols = st.columns(3)

    # === ä¿å­˜ã‚°ãƒ«ãƒ¼ãƒ— ===
    with cols[0]:
        with st.container():
            st.markdown("##### ğŸ’¾ ä¿å­˜")
            st.markdown("---")

            if show_save and has_data:
                st.caption("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜")

                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã¨ã—ã¦ä¿å­˜
                if st.button("ğŸ“Œ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã«ä¿å­˜", key=f"{key_prefix}_save_default_db", use_container_width=True, type="primary"):
                    output_path = get_default_ragdb_path()
                    success, message = rag_system.save_knowledge_base(output_path)
                    if success:
                        st.success(f"âœ… ä¿å­˜å®Œäº†")
                    else:
                        st.error(f"âŒ {message}")

                st.markdown("")  # ã‚¹ãƒšãƒ¼ã‚µãƒ¼

                # åˆ¥åã§ä¿å­˜
                with st.expander("ğŸ“¥ åˆ¥åã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", expanded=False):
                    custom_filename = st.text_input(
                        "ãƒ•ã‚¡ã‚¤ãƒ«å",
                        value="custom_knowledge_base",
                        key=f"{key_prefix}_custom_filename",
                        placeholder="ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›"
                    )
                    if st.button("ä½œæˆ", key=f"{key_prefix}_save_custom_db", use_container_width=True):
                        # æ‹¡å¼µå­ã‚’è¿½åŠ 
                        filename_with_ext = custom_filename if custom_filename.endswith('.ragdb') else f"{custom_filename}.ragdb"

                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.ragdb') as tmp_file:
                            tmp_path = tmp_file.name

                        try:
                            success, message = rag_system.save_knowledge_base(tmp_path)
                            if success:
                                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³è¡¨ç¤º
                                with open(tmp_path, 'rb') as f:
                                    db_bytes = f.read()

                                st.success(f"âœ… ä½œæˆå®Œäº†")
                                st.download_button(
                                    label="ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                    data=db_bytes,
                                    file_name=filename_with_ext,
                                    mime="application/octet-stream",
                                    key=f"{key_prefix}_download_custom_db",
                                    use_container_width=True
                                )
                            else:
                                st.error(f"âŒ {message}")
                        finally:
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                            if os.path.exists(tmp_path):
                                os.remove(tmp_path)
            else:
                st.caption("ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                st.markdown("<br>", unsafe_allow_html=True)
                st.button("ğŸ“Œ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã«ä¿å­˜", key=f"{key_prefix}_save_default_db_disabled", use_container_width=True, disabled=True)

    # === èª­ã¿è¾¼ã¿ã‚°ãƒ«ãƒ¼ãƒ— ===
    with cols[1]:
        with st.container():
            st.markdown("##### ğŸ“‚ èª­ã¿è¾¼ã¿")
            st.markdown("---")
            st.caption("ä¿å­˜æ¸ˆã¿ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿")

            uploaded_db = st.file_uploader(
                "RAGDBãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                type=['ragdb'],
                key=f"{key_prefix}_load_db",
                label_visibility="collapsed"
            )
            if st.button("ğŸ“‚ èª­ã¿è¾¼ã¿å®Ÿè¡Œ", key=f"{key_prefix}_load_btn", use_container_width=True, type="primary", disabled=uploaded_db is None):
                with temp_file_path(uploaded_db.getvalue(), '.ragdb') as tmp_path:
                    success, message, metadata = rag_system.load_knowledge_base(tmp_path)
                    if success:
                        st.success("âœ… èª­ã¿è¾¼ã¿å®Œäº†")
                        st.session_state.global_db_info = rag_system.get_database_info()
                        st.rerun()
                    else:
                        st.error(message)

    # === ã‚¯ãƒªã‚¢ã‚°ãƒ«ãƒ¼ãƒ— ===
    with cols[2]:
        with st.container():
            st.markdown("##### ğŸ—‘ï¸ ã‚¯ãƒªã‚¢")
            st.markdown("---")

            if has_data:
                st.caption("ç¾åœ¨ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤")
                st.markdown("<br>", unsafe_allow_html=True)
                if st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢", key=f"{key_prefix}_clear_btn", use_container_width=True, type="primary"):
                    rag_system.clear_knowledge_base()
                    st.session_state.global_db_info = rag_system.get_database_info()
                    st.success("âœ… ã‚¯ãƒªã‚¢å®Œäº†")
                    st.rerun()
            else:
                st.caption("ã‚¯ãƒªã‚¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                st.markdown("<br>", unsafe_allow_html=True)
                st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢", key=f"{key_prefix}_clear_btn_disabled", use_container_width=True, disabled=True)

# ========================================
# ãƒšãƒ¼ã‚¸é–¢æ•°
# ========================================

def knowledge_base_management():
    st.title("ğŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†")
    st.write("RAGæ©Ÿèƒ½ã®å‰Šé™¤ã«ä¼´ã„ã€ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    st.info("æ—¢å­˜ã®RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚")


def proofread_meeting_minutes():
    st.title("ğŸ“ è­°äº‹éŒ²æ ¡æ­£ï¼ˆRAGï¼‰")
    st.write("RAGæ©Ÿèƒ½ã¯å‰Šé™¤ã•ã‚ŒãŸãŸã‚ã€ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    st.info("æ ¡æ­£ãŒå¿…è¦ãªå ´åˆã¯ã€æ–‡å­—èµ·ã“ã—çµæœã‚’æ‰‹å‹•ã§ç·¨é›†ã™ã‚‹ã‹ã€ä»Šå¾Œè¿½åŠ ã•ã‚Œã‚‹ä»£æ›¿æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")


def dspy_minutes_app():
    st.title("ğŸª„ dspyè­°äº‹éŒ²ãƒ¡ã‚¤ã‚«ãƒ¼")
    st.write("dspyã‚’æ´»ç”¨ã—ã¦æ–‡å­—èµ·ã“ã—ã‚’æ•´ç†ã—ã€ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„è­°äº‹éŒ²ã«æ•´å½¢ã—ã¾ã™ã€‚")

    st.sidebar.markdown("""
    ### ğŸª„ dspyè­°äº‹éŒ²ãƒ¡ã‚¤ã‚«ãƒ¼

    **ã§ãã‚‹ã“ã¨**
    - æ–‡å­—èµ·ã“ã—ã‚’è²¼ã‚Šä»˜ã‘ã¦å³åº§ã«è­°äº‹éŒ²åŒ–
    - ã‚¹ã‚¿ã‚¤ãƒ«ã‚„æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆã‚’æŒ‡å®šã—ã¦ãƒªãƒ©ã‚¤ãƒˆ
    - ç”Ÿæˆçµæœã‚’ã‚³ãƒ”ãƒ¼ã‚„ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

    **ãƒ’ãƒ³ãƒˆ**
    - Azure OpenAIã®è¨­å®šãŒå¿…è¦ã§ã™ã€‚
    - dspyãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®å ´åˆã¯ `pip install dspy-ai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
    """)

    _init_session_state({
        'dspy_minutes_input_text': "",
        'dspy_minutes_output': "",
        'dspy_minutes_backend': "",
        'dspy_minutes_uploaded_name': "",
        'dspy_minutes_focus': "",
        'dspy_minutes_prompt': DEFAULT_MINUTES_PROMPT,
        'dspy_minutes_dataset': [],
    })

    dspy_module, dspy_error = _load_dspy_module()
    dspy_status = "âœ… dspyã‚’åˆ©ç”¨ã§ãã¾ã™" if dspy_module else f"âš ï¸ {dspy_error}"

    st.markdown(
        f"<div style='padding:0.5rem 0; color:#4a5568'>æ¥ç¶šçŠ¶æ…‹: {dspy_status}</div>",
        unsafe_allow_html=True,
    )

    if not AZURE_OPENAI_ENDPOINT or not AZURE_OPENAI_API_KEY:
        st.warning("Azure OpenAIã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•° AZURE_OPENAI_ENDPOINT / AZURE_OPENAI_API_KEY ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    with st.container():
        uploaded_text = st.file_uploader(
            "æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ (txt/md)",
            type=["txt", "md"],
            key="dspy_minutes_file_upload"
        )
        if uploaded_text is not None:
            raw_bytes = uploaded_text.read()
            decoded = raw_bytes.decode("utf-8", errors="replace")
            st.session_state.dspy_minutes_input_text = decoded
            st.session_state.dspy_minutes_uploaded_name = uploaded_text.name
            st.info(f"{uploaded_text.name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    st.text_area(
        "æ–‡å­—èµ·ã“ã—ã‚’è²¼ã‚Šä»˜ã‘",
        key="dspy_minutes_input_text",
        height=260,
        placeholder="ã“ã“ã«æ–‡å­—èµ·ã“ã—çµæœã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚ä¸è¦ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯è‡ªå‹•ã§é™¤å»ã•ã‚Œã¾ã™ã€‚",
    )

    focus_points = st.text_area(
        "å¼·èª¿ã—ãŸã„è¦³ç‚¹ (ä»»æ„)",
        key="dspy_minutes_focus",
        placeholder="ä¾‹: æ±ºå®šäº‹é …ã€å®¿é¡Œã€è«–ç‚¹ã€ãƒªã‚¹ã‚¯ã€æ¬¡å›ã¾ã§ã®TODO ãªã©"
    )

    col1, col2 = st.columns(2)
    with col1:
        model_name = st.selectbox(
            "åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
            options=["gpt-4o", "gpt-4o-mini"],
            index=0,
            help="dspyãŠã‚ˆã³Azure OpenAIã§åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åã€‚"
        )
        style_label = st.radio(
            "æ•´å½¢ã‚¹ã‚¿ã‚¤ãƒ«",
            options=["è¦ç‚¹ã‚µãƒãƒªãƒ¼", "æ™‚ç³»åˆ—ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ", "æ±ºå®šäº‹é …ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆ"],
            index=0,
        )
    with col2:
        length_hint = st.slider(
            "åˆ†é‡ã®ç›®å®‰ (æ®µè½æ•°)",
            min_value=3,
            max_value=20,
            value=8,
            help="ç”Ÿæˆã™ã‚‹è­°äº‹éŒ²ã®ãŠãŠã‚ˆãã®é•·ã•ã‚’æŒ‡å®šã—ã¾ã™ã€‚"
        )
        include_todo = st.checkbox("æ±ºå®šäº‹é …ã¨TODOã‚’å¼·èª¿ã™ã‚‹", value=True)

    st.markdown("### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š")
    st.caption("dspyã«æ¸¡ã™åŸºç¤ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚MIPROv2ã§æ›´æ–°ã§ãã¾ã™ã€‚")
    st.text_area(
        "åŸºç¤ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
        key="dspy_minutes_prompt",
        height=140,
    )

    with st.expander("MIPROv2ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„ã™ã‚‹", expanded=False):
        st.markdown(
            "- transcriptï¼ˆæ–‡å­—èµ·ã“ã—ï¼‰ã¨ minutesï¼ˆç†Ÿç·´è€…ãŒä½œæˆã—ãŸè­°äº‹éŒ²ï¼‰ã®ãƒšã‚¢ã‚’JSON/JSONLã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
            "- JSONLã¯1è¡Œ1ã‚µãƒ³ãƒ—ãƒ«ã€‚JSONã¯é…åˆ—ã€ã¾ãŸã¯ `{'data': [...]} ã®å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚"
        )

        dataset_file = st.file_uploader(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (json / jsonl)",
            type=["json", "jsonl"],
            key="dspy_minutes_dataset_upload",
            help="å„ã‚µãƒ³ãƒ—ãƒ«ã« transcript ã¨ minutes ã®ã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚",
        )

        if dataset_file is not None:
            dataset, dataset_error = _parse_minutes_dataset(dataset_file)
            if dataset_error:
                st.error(dataset_error)
            else:
                st.session_state.dspy_minutes_dataset = dataset
                st.success(f"{len(dataset)}ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                preview = dataset[0] if dataset else {}
                if preview:
                    st.caption("ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                    st.json({
                        "transcript": (preview.get("transcript", "")[:80] + "...") if preview.get("transcript") else "",
                        "minutes": (preview.get("minutes", "")[:80] + "...") if preview.get("minutes") else "",
                    })

        opt_col1, opt_col2 = st.columns(2)
        with opt_col1:
            max_iters = st.slider("æœ€é©åŒ–ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", min_value=1, max_value=8, value=3)
        with opt_col2:
            num_candidates = st.slider("å€™è£œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°", min_value=2, max_value=10, value=4)

        if st.button("MIPROv2ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–", key="dspy_minutes_optimize", use_container_width=True):
            if not st.session_state.dspy_minutes_dataset:
                st.error("æœ€é©åŒ–ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
            else:
                with st.spinner("MIPROv2ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„ã—ã¦ã„ã¾ã™..."):
                    optimized_prompt, opt_error = _optimize_minutes_prompt(
                        st.session_state.dspy_minutes_dataset,
                        st.session_state.dspy_minutes_prompt,
                        model_name,
                        max_iters=max_iters,
                        num_candidates=num_candidates,
                    )
                if opt_error:
                    st.error(opt_error)
                else:
                    st.session_state.dspy_minutes_prompt = optimized_prompt
                    st.success("æœ€é©åŒ–æ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")

    base_prompt_text = st.session_state.dspy_minutes_prompt.strip() or DEFAULT_MINUTES_PROMPT

    if st.button("dspyã§è­°äº‹éŒ²ã‚’ç”Ÿæˆ", type="primary"):
        transcript_text = st.session_state.dspy_minutes_input_text.strip()
        if not transcript_text:
            st.error("æ–‡å­—èµ·ã“ã—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            directives = base_prompt_text + "\n" + _build_minutes_directives(style_label, focus_points, length_hint, include_todo)
            with st.spinner("dspyã§è­°äº‹éŒ²åŒ–ã—ã¦ã„ã¾ã™..."):
                minutes_text, error_message = _generate_minutes_with_dspy(transcript_text, directives, model_name)
                backend = "dspy"

                if not minutes_text:
                    backend = "Azure OpenAI"
                    if error_message:
                        st.warning(f"dspyçµŒç”±ã®ç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚Azure OpenAIã§å†å®Ÿè¡Œã—ã¾ã™: {error_message}")
                    minutes_text = _generate_minutes_with_fallback(transcript_text, directives, model_name)

                st.session_state.dspy_minutes_output = minutes_text
                st.session_state.dspy_minutes_backend = backend

            st.success(f"{st.session_state.dspy_minutes_backend}ã§è­°äº‹éŒ²ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")

    if st.session_state.dspy_minutes_output:
        st.subheader("ç”Ÿæˆã•ã‚ŒãŸè­°äº‹éŒ²")
        st.caption(f"å‡ºåŠ›å…ƒ: {st.session_state.dspy_minutes_backend}")
        st.text_area(
            "è­°äº‹éŒ²ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼",
            value=st.session_state.dspy_minutes_output,
            height=320,
            key="dspy_minutes_output_preview",
        )

        st.download_button(
            label="è­°äº‹éŒ²ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=st.session_state.dspy_minutes_output.encode("utf-8"),
            file_name="dspy_minutes.txt",
            mime="text/plain",
            key="dspy_minutes_download",
        )


def batch_processing_pipeline():
    """ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: 1æœ¬ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰è¤‡æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ®µéšçš„ã«å‡¦ç†"""
    st.title("ğŸš€ ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå‹•ç”»/éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒºé–“ã”ã¨ã«åˆ‡ã‚Šå‡ºã—ã€æ–‡å­—èµ·ã“ã—ã‹ã‚‰è©±è€…è­˜åˆ¥ã¾ã§ã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œã—ã¾ã™ã€‚")
    st.write("æ–‡å­—èµ·ã“ã— â†’ å€‹åˆ¥è©±è€…è­˜åˆ¥ â†’ å‡ºåŠ›ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é †ç•ªã«é€²ã‚ã‚‹ã ã‘ã§å®Œäº†ã—ã¾ã™ã€‚")

    st.sidebar.markdown("""
    ### ğŸš€ ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    **æ¦‚è¦**
    å‹•ç”»ãƒ»éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¿…è¦ãªåŒºé–“ã‚’åˆ‡ã‚Šå‡ºã—ã€ä¸€æ‹¬ã§æ–‡å­—èµ·ã“ã—ãƒ»è©±è€…è­˜åˆ¥ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

    **å‡¦ç†ãƒ•ãƒ­ãƒ¼**
    1. ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨åŒºé–“è¨­å®š
    2. ãƒ¢ãƒ‡ãƒ«é¸æŠã¨æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
    3. å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®è©±è€…è­˜åˆ¥ï¼ˆå€‹åˆ¥è¨­å®šå¯èƒ½ï¼‰
    4. å‡¦ç†çµæœã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

    **å¯¾å¿œå½¢å¼:** MP4, MOV, AVI, MKV, WebM, MP3, WAV, M4Aç­‰
    """)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    _init_session_state({
        'batch_uploaded_video': None,
        'batch_extracted_files': [],
        'batch_processing_results': {},
        'batch_processing_status': {},
        'batch_current_step': 1,
        'batch_rag_system': None,
        'batch_transcribe_model': 'whisper',
        'batch_reference_file': None,
        'batch_current_speaker_file_index': 0,
        'batch_db_info': None,
        'batch_meeting_type': None,
        'batch_default_embeddings': [],
        'batch_file_embeddings': {},  # å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®åŸ‹ã‚è¾¼ã¿è¨­å®š
        'batch_embedding_states': {},  # è©±è€…åŸ‹ã‚è¾¼ã¿ä½œæˆUIç”¨ã®çŠ¶æ…‹
        'batch_temp_dir': None,  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        'batch_cut_settings_df': None  # åˆ‡ã‚Šå‡ºã—è¨­å®šDataFrame
    })

    # Step 1: å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨éŸ³å£°åˆ‡ã‚Šå‡ºã—è¨­å®š
    st.subheader("Step 1: ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨éŸ³å£°åˆ‡ã‚Šå‡ºã—")
    st.write("å‹•ç”»ãƒ»éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€å‡¦ç†ã—ãŸã„åŒºé–“ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚è¤‡æ•°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŒ‡å®šã§ãã¾ã™ã€‚")
    st.caption("â€» åˆ‡ã‚Šå‡ºã—ã¯ä»»æ„ã§ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’ä½¿ã†å ´åˆã¯ãã®ã¾ã¾æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸é€²ã‚ã¾ã™ã€‚")

    uploaded_video = st.file_uploader(
        "ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=["wav", "mp3", "mp4", "mov", "avi", "mkv", "webm", "m4a"],
        key="batch_video_upload"
    )

    if uploaded_video is not None:
        st.success(f"âœ… ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ« '{uploaded_video.name}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

        # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        video_ext = os.path.splitext(uploaded_video.name)[1].lower()
        if video_ext in ['.mp4', '.mov', '.webm', '.avi', '.mkv']:
            st.video(uploaded_video)
        elif video_ext in ['.mp3', '.wav', '.m4a']:
            st.audio(uploaded_video)

        st.subheader("åˆ‡ã‚Šå‡ºã—åŒºé–“ã®è¨­å®š")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®data_editorãƒ‡ãƒ¼ã‚¿
        if st.session_state.batch_cut_settings_df is None:
            default_data = pd.DataFrame([
                {"é–‹å§‹æ™‚é–“": "00:00:00", "çµ‚äº†æ™‚é–“": "00:00:30", "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å": f"{os.path.splitext(uploaded_video.name)[0]}_"}
            ])
        else:
            default_data = st.session_state.batch_cut_settings_df

        edited_df = st.data_editor(
            default_data,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "é–‹å§‹æ™‚é–“": st.column_config.TextColumn(
                    "é–‹å§‹æ™‚é–“ (HH:MM:SS or seconds)",
                    help="åˆ‡ã‚Šå‡ºã—é–‹å§‹æ™‚é–“ (ä¾‹: 00:00:10 ã¾ãŸã¯ 10)",
                    default="00:00:00"
                ),
                "çµ‚äº†æ™‚é–“": st.column_config.TextColumn(
                    "çµ‚äº†æ™‚é–“ (HH:MM:SS or seconds)",
                    help="åˆ‡ã‚Šå‡ºã—çµ‚äº†æ™‚é–“ (ä¾‹: 00:00:30 ã¾ãŸã¯ 30)",
                    default="00:00:30"
                ),
                "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å": st.column_config.TextColumn(
                    "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å (.mp3)",
                    help="ã“ã®åŒºé–“ã®MP3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: meeting1.mp3)ã€‚ç©ºæ¬„ã®å ´åˆã€è‡ªå‹•ã§é€£ç•ªãŒæŒ¯ã‚‰ã‚Œã¾ã™ã€‚",
                    default=f"{os.path.splitext(uploaded_video.name)[0]}_"
                )
            },
            key="batch_cut_settings_editor"
        )

        # è¨­å®šã‚’ä¿å­˜
        st.session_state.batch_cut_settings_df = edited_df

        # éŸ³å£°åˆ‡ã‚Šå‡ºã—å®Ÿè¡Œ
        if st.button("ğŸµ éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—ã¦Step 2ã¸é€²ã‚€", key="batch_execute_cut", type="primary"):
            if edited_df.empty:
                st.warning("åˆ‡ã‚Šå‡ºã—åŒºé–“ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            else:
                with st.spinner("éŸ³å£°ã®åˆ‡ã‚Šå‡ºã—ã¨MP3ã¸ã®å¤‰æ›ä¸­..."):
                    try:
                        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                        if st.session_state.batch_temp_dir is None:
                            st.session_state.batch_temp_dir = tempfile.mkdtemp()

                        temp_dir = st.session_state.batch_temp_dir
                        temp_video_path = None
                        extracted_files = []

                        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
                        uploaded_video.seek(0)
                        temp_video_path = os.path.join(temp_dir, f"source_video{os.path.splitext(uploaded_video.name)[1]}")
                        with open(temp_video_path, 'wb') as f:
                            f.write(uploaded_video.read())

                        # å„åŒºé–“ã‚’åˆ‡ã‚Šå‡ºã—
                        for index, row in edited_df.iterrows():
                            start_time_str = str(row["é–‹å§‹æ™‚é–“"])
                            end_time_str = str(row["çµ‚äº†æ™‚é–“"])
                            output_filename_raw = str(row["å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å"]).strip()

                            try:
                                start_seconds = parse_time_to_seconds(start_time_str)
                                end_seconds = parse_time_to_seconds(end_time_str)

                                if start_seconds >= end_seconds:
                                    st.error(f"åŒºé–“ {index+1}: é–‹å§‹æ™‚é–“ ({start_time_str}) ã¯çµ‚äº†æ™‚é–“ ({end_time_str}) ã‚ˆã‚Šå‰ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚ã“ã®åŒºé–“ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
                                    continue

                                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
                                base_name_from_video = os.path.splitext(uploaded_video.name)[0]
                                if not output_filename_raw or output_filename_raw.upper() == "AUTO_GENERATE":
                                    output_filename = f"{base_name_from_video}_segment_{index+1}.mp3"
                                else:
                                    output_filename = output_filename_raw

                                # .mp3æ‹¡å¼µå­ã‚’ç¢ºä¿
                                if not output_filename.lower().endswith(".mp3"):
                                    output_filename += ".mp3"

                                output_audio_path = os.path.join(temp_dir, output_filename)

                                # FFmpegã§åˆ‡ã‚Šå‡ºã—
                                command = [
                                    "ffmpeg",
                                    "-i", temp_video_path,
                                    "-ss", format_time(start_seconds),
                                    "-to", format_time(end_seconds),
                                    "-vn",  # No video
                                    "-ab", "192k",  # Audio bitrate
                                    "-map_metadata", "-1",  # Remove metadata
                                    "-y",  # Overwrite output files without asking
                                    output_audio_path
                                ]

                                process = subprocess.run(command, capture_output=True, text=True, encoding="utf-8", check=True)

                                # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿
                                with open(output_audio_path, 'rb') as f:
                                    file_data = f.read()
                                    file_io = BytesIO(file_data)
                                    file_io.name = output_filename
                                    extracted_files.append({
                                        'name': output_filename,
                                        'data': file_io,
                                        'size': len(file_data)
                                    })

                                st.success(f"âœ… åŒºé–“ {index+1}: {output_filename} ã®åˆ‡ã‚Šå‡ºã—ãŒå®Œäº†ã—ã¾ã—ãŸ")

                            except subprocess.CalledProcessError as e:
                                st.error(f"âŒ åŒºé–“ {index+1}: FFmpegã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                                st.code(e.stderr)
                            except ValueError as e:
                                st.error(f"âŒ åŒºé–“ {index+1}: æ™‚é–“å½¢å¼ã‚¨ãƒ©ãƒ¼: {e}")
                            except Exception as e:
                                st.error(f"âŒ åŒºé–“ {index+1}: å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

                        if extracted_files:
                            # æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’session stateã«ä¿å­˜
                            st.session_state.batch_extracted_files = extracted_files
                            st.session_state.batch_current_step = 2

                            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çŠ¶æ…‹ã‚’åˆæœŸåŒ–
                            for file_info in extracted_files:
                                st.session_state.batch_processing_status[file_info['name']] = {
                                    'transcription': 'pending',
                                    'speaker_id': 'pending',
                                    'rag_proofread': 'pending'
                                }
                                st.session_state.batch_processing_results[file_info['name']] = {}

                            st.success(f"âœ… {len(extracted_files)} å€‹ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ‡ã‚Šå‡ºã—ãŒå®Œäº†ã—ã¾ã—ãŸ")
                            st.rerun()
                        else:
                            st.warning("âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒ1ã¤ã‚‚ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

                    except Exception as e:
                        st.error(f"âŒ éŸ³å£°åˆ‡ã‚Šå‡ºã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        import traceback
                        st.error(traceback.format_exc())

        if st.button("â­ åˆ‡ã‚Šå‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦Step 2ã¸é€²ã‚€", key="batch_skip_cut"):
            uploaded_video.seek(0)
            file_bytes = uploaded_video.read()

            if not file_bytes:
                st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                file_buffer = BytesIO(file_bytes)
                file_buffer.name = uploaded_video.name

                st.session_state.batch_extracted_files = [{
                    'name': uploaded_video.name,
                    'data': file_buffer,
                    'size': len(file_bytes)
                }]

                st.session_state.batch_processing_status = {
                    uploaded_video.name: {
                        'transcription': 'pending',
                        'speaker_id': 'pending',
                        'rag_proofread': 'pending'
                    }
                }
                st.session_state.batch_processing_results = {
                    uploaded_video.name: {}
                }
                st.session_state.batch_current_step = 2
                st.success("âœ… åˆ‡ã‚Šå‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚å…ƒã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Step 2ã§ãã®ã¾ã¾æ–‡å­—èµ·ã“ã—ã—ã¾ã™ã€‚")
                st.rerun()

    # Step 2: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨æ–‡å­—èµ·ã“ã—
    if st.session_state.batch_current_step >= 2 and len(st.session_state.batch_extracted_files) > 0:
        st.subheader("Step 2: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨æ–‡å­—èµ·ã“ã—")

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
        st.write(f"**æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(st.session_state.batch_extracted_files)}")

        file_df = pd.DataFrame([
            {
                'ãƒ•ã‚¡ã‚¤ãƒ«å': f['name'],
                'ã‚µã‚¤ã‚º (KB)': f'{f["size"] / 1024:.1f}'
            }
            for f in st.session_state.batch_extracted_files
        ])
        st.dataframe(file_df, use_container_width=True, hide_index=True)

        st.divider()

        reference_file = None
        meeting_types = load_meeting_type_config()
        col_settings, col_meeting = st.columns(2, gap="large")

        with col_settings:
            st.write("**æ–‡å­—èµ·ã“ã—è¨­å®š**")

            transcribe_model = st.selectbox(
                "æ–‡å­—èµ·ã“ã—ãƒ¢ãƒ‡ãƒ«",
                options=["whisper", "gpt-4o-transcribe-diarize"],
                index=0,
                key="batch_transcribe_model_select",
                help="whisper: å‚è€ƒè³‡æ–™å¯¾å¿œ | gpt-4o-transcribe-diarize: è‡ªå‹•è©±è€…è­˜åˆ¥ä»˜ã"
            )

            if transcribe_model == "whisper":
                reference_file = st.file_uploader(
                    "å‚è€ƒè³‡æ–™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
                    type=["pdf", "docx", "pptx", "txt", "msg"],
                    key="batch_reference_file_upload",
                    help="å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ç²¾åº¦å‘ä¸Šã«ä½¿ç”¨"
                )

        with col_meeting:
            st.write("**ä¼šè­°ã‚¿ã‚¤ãƒ—è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**")
            st.write("ä¼šè­°ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã™ã‚‹ã¨ã€äº‹å‰ã«è¨­å®šã•ã‚ŒãŸè©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«èª­ã¿è¾¼ã¿ã¾ã™ã€‚")

            if meeting_types:
                meeting_type_options = {mt['id']: f"{mt['name']} - {mt['description']}" for mt in meeting_types}

                selected_meeting_type_id = st.selectbox(
                    "ä¼šè­°ã‚¿ã‚¤ãƒ—",
                    options=list(meeting_type_options.keys()),
                    format_func=lambda x: meeting_type_options[x],
                    key="batch_meeting_type_select"
                )

                selected_meeting_type = next((mt for mt in meeting_types if mt['id'] == selected_meeting_type_id), None)

                if selected_meeting_type and selected_meeting_type['embeddings_folder']:
                    if st.session_state.batch_meeting_type != selected_meeting_type_id:
                        st.session_state.batch_meeting_type = selected_meeting_type_id
                        st.session_state.batch_default_embeddings = load_embeddings_from_folder(
                            selected_meeting_type['embeddings_folder']
                        )

                        if st.session_state.batch_default_embeddings:
                            st.success(f"âœ… {len(st.session_state.batch_default_embeddings)}å€‹ã®è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                            embedding_names = [emb['name'] for emb in st.session_state.batch_default_embeddings]
                            st.info(f"ğŸ“ èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(embedding_names)}")
                elif selected_meeting_type_id == 'custom':
                    st.session_state.batch_meeting_type = 'custom'
                    st.session_state.batch_default_embeddings = []
                    st.info("ğŸ’¡ ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ¼ãƒ‰: Step 3ã§å€‹åˆ¥ã«è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            else:
                st.warning("âš ï¸ ä¼šè­°ã‚¿ã‚¤ãƒ—ã®ãƒ—ãƒªã‚»ãƒƒãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æ‰‹å‹•ã§è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

        st.divider()

        # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
        if st.button("ğŸ“ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹", key="batch_start_transcription", type="primary"):
            # é€²æ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()

            total_files = len(st.session_state.batch_extracted_files)

            for idx, file_info in enumerate(st.session_state.batch_extracted_files):
                file_name = file_info['name']
                file_data = file_info['data']

                status_text.write(f"**æ–‡å­—èµ·ã“ã—ä¸­: {file_name}** ({idx + 1}/{total_files})")

                try:
                    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                    st.session_state.batch_processing_status[file_name]['transcription'] = 'processing'

                    file_data.seek(0)
                    seg_df = transcribe_audio_to_dataframe(
                        file_data,
                        reference_file=reference_file,
                        model=transcribe_model
                    )

                    st.session_state.batch_processing_results[file_name]['transcription_df'] = seg_df
                    st.session_state.batch_processing_status[file_name]['transcription'] = 'completed'
                    st.success(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {file_name} ({len(seg_df)}è¡Œ)")

                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {file_name} - {e}")
                    st.session_state.batch_processing_status[file_name]['transcription'] = 'error'
                    import traceback
                    st.error(traceback.format_exc())

                # é€²æ—ãƒãƒ¼æ›´æ–°
                progress_bar.progress((idx + 1) / total_files)

            status_text.write("âœ… **ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼**")
            st.session_state.batch_current_step = 3
            st.balloons()
            st.rerun()

    # Step 3: å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®è©±è€…è­˜åˆ¥
    if st.session_state.batch_current_step >= 3 and len(st.session_state.batch_extracted_files) > 0:
        st.subheader("Step 3: å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®è©±è€…è­˜åˆ¥")
        st.write("å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«è©±è€…è­˜åˆ¥ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ç•°ãªã‚‹è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚")

        # å‡¦ç†çŠ¶æ³ã‚µãƒãƒªãƒ¼
        transcription_completed = sum(1 for status in st.session_state.batch_processing_status.values() if status.get('transcription') == 'completed')
        speaker_id_completed = sum(1 for status in st.session_state.batch_processing_status.values() if status.get('speaker_id') == 'completed')

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ–‡å­—èµ·ã“ã—å®Œäº†", f"{transcription_completed}/{len(st.session_state.batch_extracted_files)}")
        with col2:
            st.metric("è©±è€…è­˜åˆ¥å®Œäº†", f"{speaker_id_completed}/{len(st.session_state.batch_extracted_files)}")
        with col3:
            if st.button("ğŸ”„ è©±è€…è­˜åˆ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã¸", key="skip_speaker_id"):
                st.session_state.batch_current_step = 4
                st.rerun()

        st.divider()

        # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚¿ãƒ–ã‚’ä½œæˆ
        file_names = [f['name'] for f in st.session_state.batch_extracted_files]
        file_tabs = st.tabs(file_names)

        for tab_idx, (file_tab, file_info) in enumerate(zip(file_tabs, st.session_state.batch_extracted_files)):
            with file_tab:
                selected_file_name = file_info['name']
                selected_file_info = file_info

                if selected_file_name in st.session_state.batch_processing_results:
                    result = st.session_state.batch_processing_results[selected_file_name]

                    # æ–‡å­—èµ·ã“ã—çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    if 'transcription_df' in result:
                        transcription_df = result['transcription_df']
                        with st.expander("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
                            if 'speaker' in transcription_df.columns:
                                disabled_columns = [col for col in transcription_df.columns if col != 'speaker']
                                edited_transcription = st.data_editor(
                                    transcription_df,
                                    hide_index=True,
                                    use_container_width=True,
                                    num_rows="dynamic",
                                    disabled=disabled_columns,
                                    column_config={
                                        "speaker": st.column_config.TextColumn(
                                            "è©±è€…",
                                            help="å¿…è¦ã«å¿œã˜ã¦è©±è€…åã‚’ç›´æ¥ç·¨é›†ã—ã¦ãã ã•ã„"
                                        )
                                    },
                                    key=f"transcription_editor_{selected_file_name}_{tab_idx}"
                                )

                                if isinstance(edited_transcription, pd.DataFrame):
                                    updated_transcription_df = edited_transcription.copy()
                                else:
                                    updated_transcription_df = pd.DataFrame(edited_transcription)

                                updated_transcription_df = updated_transcription_df.reset_index(drop=True)
                                transcription_df_normalized = transcription_df.reset_index(drop=True)

                                # Ensure original columns exist in editor output
                                for column in transcription_df_normalized.columns:
                                    if column not in updated_transcription_df.columns:
                                        updated_transcription_df[column] = transcription_df_normalized[column]
                                updated_transcription_df = updated_transcription_df[transcription_df_normalized.columns]

                                original_speaker = transcription_df_normalized['speaker'].astype(str).fillna("")
                                updated_speaker = updated_transcription_df['speaker'].astype(str).fillna("")

                                if not updated_speaker.equals(original_speaker):
                                    st.session_state.batch_processing_results[selected_file_name]['transcription_df'] = updated_transcription_df
                                    transcription_df = updated_transcription_df
                                    st.session_state.batch_processing_results[selected_file_name].pop('identified_df', None)
                                    st.session_state.batch_processing_results[selected_file_name].pop('meeting_text', None)
                                    st.session_state.batch_processing_results[selected_file_name].pop('proofread_text', None)

                                    status_entry = st.session_state.batch_processing_status.get(selected_file_name, {})
                                    status_entry['speaker_id'] = 'pending'
                                    status_entry['rag_proofread'] = 'pending'
                                    st.session_state.batch_processing_status[selected_file_name] = status_entry

                                    st.success("âœï¸ è©±è€…åˆ—ã®å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚å¿…è¦ã«å¿œã˜ã¦è©±è€…è­˜åˆ¥ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                            else:
                                st.dataframe(transcription_df.head(10), use_container_width=True)

                        tab_identify, tab_embed = st.tabs(["è©±è€…è­˜åˆ¥", "è©±è€…åŸ‹ã‚è¾¼ã¿ä½œæˆ"])

                        with tab_identify:
                            st.write("**è©±è€…è­˜åˆ¥è¨­å®š**")

                            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°è¡¨ç¤º
                            if st.session_state.batch_default_embeddings:
                                st.info(f"âœ… ä¼šè­°ã‚¿ã‚¤ãƒ—ã‹ã‚‰{len(st.session_state.batch_default_embeddings)}å€‹ã®è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’èª­ã¿è¾¼ã¿æ¸ˆã¿")
                                default_names = [emb['name'] for emb in st.session_state.batch_default_embeddings]
                                with st.expander("èª­ã¿è¾¼ã¿æ¸ˆã¿è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«", expanded=True):
                                    st.write(", ".join(default_names))

                            col1, col2 = st.columns(2)

                            with col1:
                                # è¿½åŠ ã®åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                                additional_embeddings = st.file_uploader(
                                    "è¿½åŠ ã®è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.npyï¼‰",
                                    type=["npy"],
                                    accept_multiple_files=True,
                                    key=f"batch_additional_embeddings_{selected_file_name}_{tab_idx}",
                                    help="ä¼šè­°ã‚¿ã‚¤ãƒ—ã§èª­ã¿è¾¼ã‚“ã ãƒ•ã‚¡ã‚¤ãƒ«ã«åŠ ãˆã¦ã€è¿½åŠ ã§åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã§ãã¾ã™"
                                )

                            with col2:
                                similarity_threshold = st.slider(
                                    "é¡ä¼¼åº¦é–¾å€¤",
                                    min_value=0.0,
                                    max_value=1.0,
                                    value=0.7,
                                    step=0.01,
                                    key=f"batch_similarity_threshold_{selected_file_name}_{tab_idx}"
                                )

                            # ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
                            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåŸ‹ã‚è¾¼ã¿ + è¿½åŠ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                            all_embeddings = list(st.session_state.batch_default_embeddings)
                            if additional_embeddings:
                                all_embeddings.extend(additional_embeddings)

                            # åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’è¡¨ç¤º
                            total_embeddings = len(all_embeddings)
                            if total_embeddings > 0:
                                st.success(f"ğŸ“Š åˆè¨ˆ {total_embeddings}å€‹ã®è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
                            else:
                                st.warning("âš ï¸ è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Step 2ã§ä¼šè­°ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã™ã‚‹ã‹ã€ä¸Šè¨˜ã§è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

                            # è©±è€…è­˜åˆ¥å®Ÿè¡Œ
                            if all_embeddings and st.button(f"ğŸ¤ {selected_file_name} ã®è©±è€…è­˜åˆ¥ã‚’å®Ÿè¡Œ", key=f"execute_speaker_id_{selected_file_name}_{tab_idx}", type="primary"):
                                with st.spinner(f"ğŸ¤ è©±è€…è­˜åˆ¥ä¸­: {selected_file_name}"):
                                    try:
                                        file_data = selected_file_info['data']
                                        file_data.seek(0)

                                        identified_df = identify_speakers_in_dataframe(
                                            file_data,
                                            transcription_df,
                                            all_embeddings,
                                            similarity_threshold
                                        )

                                        st.session_state.batch_processing_results[selected_file_name]['identified_df'] = identified_df
                                        st.session_state.batch_processing_status[selected_file_name]['speaker_id'] = 'completed'
                                        st.success(f"âœ… è©±è€…è­˜åˆ¥å®Œäº†: {selected_file_name}")
                                        st.rerun()

                                    except Exception as e:
                                        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
                                        st.session_state.batch_processing_status[selected_file_name]['speaker_id'] = 'error'
                                        import traceback
                                        st.error(traceback.format_exc())

                            if 'identified_df' in result and not result['identified_df'].empty:
                                st.divider()
                                st.write("**è©±è€…è­˜åˆ¥çµæœã®æ‰‹å‹•ä¿®æ­£**")
                                st.caption("è©±è€…åˆ—ã‚’ç›´æ¥ç·¨é›†ã—ã¦ãƒ©ãƒ™ãƒ«ã‚’èª¿æ•´ã§ãã¾ã™ã€‚ä¿®æ­£å¾Œã¯å¿…è¦ã«å¿œã˜ã¦å†åº¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

                                current_identified_df = result['identified_df'].copy()
                                if 'speaker' not in current_identified_df.columns:
                                    st.warning("è©±è€…åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è­˜åˆ¥çµæœã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                                else:
                                    disabled_cols = [col for col in current_identified_df.columns if col != 'speaker']
                                    edited_df = st.data_editor(
                                        current_identified_df,
                                        column_config={
                                            "speaker": st.column_config.TextColumn(
                                                "è©±è€…",
                                                help="å¿…è¦ã«å¿œã˜ã¦è©±è€…åã‚’ç›´æ¥å…¥åŠ›ã—ã¦ãã ã•ã„"
                                            )
                                        },
                                        disabled=disabled_cols,
                                        hide_index=True,
                                        use_container_width=True,
                                        key=f"identified_editor_{selected_file_name}_{tab_idx}"
                                    )

                                    if isinstance(edited_df, pd.DataFrame):
                                        updated_df = edited_df.copy()
                                    else:
                                        updated_df = pd.DataFrame(edited_df)

                                    updated_df = updated_df.reset_index(drop=True)
                                    current_normalized = current_identified_df.reset_index(drop=True)

                                    # Ensure column order matches original
                                    updated_df = updated_df[current_normalized.columns]

                                    if not updated_df.equals(current_normalized):
                                        st.session_state.batch_processing_results[selected_file_name]['identified_df'] = updated_df
                                        st.session_state.batch_processing_results[selected_file_name].pop('meeting_text', None)
                                        st.session_state.batch_processing_results[selected_file_name].pop('proofread_text', None)

                                        status_entry = st.session_state.batch_processing_status.get(selected_file_name, {})
                                        status_entry['speaker_id'] = 'completed'
                                        status_entry['rag_proofread'] = 'pending'
                                        st.session_state.batch_processing_status[selected_file_name] = status_entry

                                        st.success("âœï¸ è©±è€…ãƒ©ãƒ™ãƒ«ã®å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                                        st.info("å¤‰æ›´å†…å®¹ã‚’åæ˜ ã™ã‚‹ã«ã¯ã€å¿…è¦ã«å¿œã˜ã¦Step 4ä»¥é™ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

                        with tab_embed:
                            st.write("éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã—ã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç¢ºèªã—ã¦ã‹ã‚‰è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã§ãã¾ã™ã€‚")

                            target_df = result.get('identified_df', transcription_df).copy()

                            if len(target_df) == 0:
                                st.warning("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                            else:
                                embedding_states = st.session_state.batch_embedding_states
                                if selected_file_name not in embedding_states:
                                    embedding_states[selected_file_name] = {
                                        'selected_rows': set(),
                                        'preview_audio': None,
                                        'show_preview': False
                                    }
                                embedding_state = embedding_states[selected_file_name]

                                selection_mode = st.radio(
                                    "é¸æŠæ–¹å¼ã‚’é¸ã‚“ã§ãã ã•ã„",
                                    options=["ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰", "ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ¼ãƒ‰"],
                                    horizontal=True,
                                    help="ç¯„å›²æŒ‡å®š: é€£ç¶šã—ãŸè¡Œã‚’ç´ æ—©ãé¸æŠ | ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹: é£›ã³é£›ã³ã®è¡Œã‚’è‡ªç”±ã«é¸æŠ",
                                    key=f"batch_embedding_selection_mode_{selected_file_name}_{tab_idx}"
                                )

                                st.divider()

                                st.subheader("1ï¸âƒ£ éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠ")

                                if selection_mode == "ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰":
                                    embedding_row_labels = _create_row_labels(target_df)
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        start_row = st.selectbox(
                                            "é–‹å§‹è¡Œã‚’é¸æŠ",
                                            options=range(len(target_df)),
                                            format_func=lambda x: embedding_row_labels[x],
                                            key=f"batch_embedding_start_row_{selected_file_name}_{tab_idx}"
                                        )
                                    with col2:
                                        end_row = st.selectbox(
                                            "çµ‚äº†è¡Œã‚’é¸æŠ",
                                            options=range(len(target_df)),
                                            format_func=lambda x: embedding_row_labels[x],
                                            index=len(target_df) - 1 if len(target_df) > 0 else 0,
                                            key=f"batch_embedding_end_row_{selected_file_name}_{tab_idx}"
                                        )

                                    if start_row > end_row:
                                        st.error("âš ï¸ é–‹å§‹è¡Œã¯çµ‚äº†è¡Œä»¥å‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
                                        embedding_state['selected_rows'] = set()
                                    else:
                                        embedding_state['selected_rows'] = set(range(start_row, end_row + 1))
                                        st.success(f"âœ… è¡Œ {start_row} ï½ {end_row} ã‚’é¸æŠã—ã¾ã—ãŸ")
                                else:
                                    display_df = target_df.copy()
                                    display_df.insert(0, "é¸æŠ", False)

                                    if embedding_state['selected_rows']:
                                        for idx in embedding_state['selected_rows']:
                                            if idx in display_df.index:
                                                display_df.at[idx, "é¸æŠ"] = True

                                    disabled_columns = [col for col in ["start", "end", "speaker", "text"] if col in display_df.columns]

                                    edited_display = st.data_editor(
                                        display_df,
                                        column_config={
                                            "é¸æŠ": st.column_config.CheckboxColumn(
                                                "é¸æŠ",
                                                help="åŸ‹ã‚è¾¼ã¿ä½œæˆå¯¾è±¡ã®è¡Œã‚’ãƒã‚§ãƒƒã‚¯",
                                                default=False
                                            )
                                        },
                                        disabled=disabled_columns,
                                        use_container_width=True,
                                        hide_index=True,
                                        key=f"batch_embedding_data_editor_{selected_file_name}_{tab_idx}"
                                    )

                                    embedding_state['selected_rows'] = set(
                                        edited_display[edited_display["é¸æŠ"] == True].index.tolist()
                                    )

                                selected_rows = embedding_state['selected_rows']

                                if selected_rows:
                                    st.subheader("2ï¸âƒ£ é¸æŠæƒ…å ±ã®ç¢ºèª")

                                    selection_summary = get_selection_summary(target_df, selected_rows)

                                    info_cols = st.columns(4)
                                    with info_cols[0]:
                                        st.metric("é¸æŠè¡Œæ•°", selection_summary['count'])
                                    with info_cols[1]:
                                        st.metric("é–‹å§‹æ™‚åˆ»", format_time(selection_summary['start_time']))
                                    with info_cols[2]:
                                        st.metric("çµ‚äº†æ™‚åˆ»", format_time(selection_summary['end_time']))
                                    with info_cols[3]:
                                        st.metric("éŸ³å£°é•·", f"{selection_summary['duration']:.1f}ç§’")

                                    if selection_summary['speakers']:
                                        speakers_text = "ã€".join([s if s else "ä¸æ˜" for s in selection_summary['speakers']])
                                        st.info(f"ğŸ¤ é¸æŠç¯„å›²ã«å«ã¾ã‚Œã‚‹è©±è€…: {speakers_text}")

                                    st.subheader("3ï¸âƒ£ éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

                                    col_preview, col_clear = st.columns([3, 1])

                                    with col_preview:
                                        if st.button("ğŸ”Š ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆ", key=f"batch_generate_preview_{selected_file_name}_{tab_idx}"):
                                            try:
                                                with st.spinner("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                                                    audio_io = BytesIO(selected_file_info['data'].getvalue())
                                                    preview_bytes, duration = prepare_embedding_preview_audio(
                                                        audio_io,
                                                        target_df,
                                                        sorted(selected_rows)
                                                    )
                                                    embedding_state['preview_audio'] = preview_bytes
                                                    embedding_state['show_preview'] = True
                                                st.success(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆ{duration:.1f}ç§’ï¼‰")
                                            except Exception as e:
                                                st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

                                    with col_clear:
                                        if embedding_state.get('show_preview'):
                                            if st.button("âŒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢", key=f"batch_clear_preview_{selected_file_name}_{tab_idx}"):
                                                embedding_state['preview_audio'] = None
                                                embedding_state['show_preview'] = False
                                                st.rerun()

                                    if embedding_state.get('show_preview') and embedding_state.get('preview_audio'):
                                        st.audio(embedding_state['preview_audio'], format="audio/wav")

                                    st.subheader("4ï¸âƒ£ ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š")

                                    embedding_filename = st.text_input(
                                        "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ.npyæ‹¡å¼µå­ã¯è‡ªå‹•è¿½åŠ ï¼‰",
                                        value="speaker_embedding",
                                        key=f"batch_embedding_filename_{selected_file_name}_{tab_idx}",
                                        help="ä½œæˆã™ã‚‹è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
                                    )

                                    st.subheader("5ï¸âƒ£ åŸ‹ã‚è¾¼ã¿ä½œæˆ")

                                    if st.button("âœ¨ è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key=f"batch_create_embedding_{selected_file_name}_{tab_idx}", type="primary"):
                                        with st.spinner("è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆä¸­..."):
                                            try:
                                                audio_io = BytesIO(selected_file_info['data'].getvalue())
                                                embedding, duration = extract_audio_segment_for_embedding(
                                                    audio_io,
                                                    target_df,
                                                    sorted(selected_rows)
                                                )

                                                filename_with_ext = embedding_filename if embedding_filename.endswith('.npy') else f"{embedding_filename}.npy"

                                                embedding_io = BytesIO()
                                                np.save(embedding_io, embedding)
                                                embedding_io.seek(0)

                                                embedding_bytes = embedding_io.getvalue()

                                                st.success(f"âœ… è©±è€…åŸ‹ã‚è¾¼ã¿ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆéŸ³å£°é•·: {duration:.1f}ç§’ï¼‰")
                                                trigger_auto_download(
                                                    embedding_bytes,
                                                    filename_with_ext,
                                                    key=f"batch_download_embedding_{selected_file_name}_{tab_idx}",
                                                    mime="application/octet-stream"
                                                )

                                            except Exception as e:
                                                st.error(f"âŒ è©±è€…åŸ‹ã‚è¾¼ã¿ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                                                import traceback
                                                with st.expander("ğŸ” è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                                                    st.code(traceback.format_exc())
                                else:
                                    if selection_mode == "ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰":
                                        st.info("ğŸ’¡ ä¸Šè¨˜ã®selectboxã§é–‹å§‹è¡Œã¨çµ‚äº†è¡Œã‚’é¸æŠã—ã¦ãã ã•ã„")
                                    else:
                                        st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§åŸ‹ã‚è¾¼ã¿ä½œæˆå¯¾è±¡ã®è¡Œã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„")

                    # è©±è€…è­˜åˆ¥çµæœã®ç¢ºèª
                    if 'identified_df' in result:
                        st.success("âœ… ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®è©±è€…è­˜åˆ¥ã¯å®Œäº†ã—ã¦ã„ã¾ã™")
                else:
                    st.warning("âš ï¸ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã¾ã æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“")

        st.divider()

        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çŠ¶æ³ä¸€è¦§
        st.write("**å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çŠ¶æ³**")
        status_df = pd.DataFrame([
            {
                'ãƒ•ã‚¡ã‚¤ãƒ«å': f['name'],
                'æ–‡å­—èµ·ã“ã—': 'âœ…' if st.session_state.batch_processing_status.get(f['name'], {}).get('transcription') == 'completed' else 'âŒ',
                'è©±è€…è­˜åˆ¥': 'âœ…' if st.session_state.batch_processing_status.get(f['name'], {}).get('speaker_id') == 'completed' else 'â­ï¸'
            }
            for f in st.session_state.batch_extracted_files
        ])
        st.dataframe(status_df, use_container_width=True, hide_index=True)

        st.divider()

        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸
        if st.button("â¡ï¸ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸é€²ã‚€", key="proceed_to_rag", type="primary"):
            st.session_state.batch_current_step = 4
            st.rerun()

    # Step 4: æ ¡æ­£ï¼ˆRAGãªã—ï¼‰
    if st.session_state.batch_current_step >= 4:
        st.subheader("Step 4: æ ¡æ­£")
        st.write("RAGæ©Ÿèƒ½ã¯å‰Šé™¤ã•ã‚ŒãŸãŸã‚ã€ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯è‡ªå‹•æ ¡æ­£ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        st.session_state.batch_processing_status = {name: {**status, 'rag_proofread': 'skipped'} for name, status in st.session_state.batch_processing_status.items()}
        if st.button("â¡ï¸ æœ€çµ‚ç¢ºèªã¸é€²ã‚€", key="skip_rag_step", type="primary"):
            st.session_state.batch_current_step = 5
            st.rerun()

    if st.session_state.batch_current_step >= 5:
        st.subheader("Step 5: å‡¦ç†çµæœã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

        # å‡¦ç†çŠ¶æ…‹ã‚µãƒãƒªãƒ¼
        st.write("**å‡¦ç†çŠ¶æ…‹ã‚µãƒãƒªãƒ¼**")
        status_summary = []
        for file_name, status in st.session_state.batch_processing_status.items():
            status_summary.append({
                'ãƒ•ã‚¡ã‚¤ãƒ«å': file_name,
                'æ–‡å­—èµ·ã“ã—': 'âœ…' if status['transcription'] == 'completed' else 'âŒ' if status['transcription'] == 'error' else 'â­ï¸',
                'è©±è€…è­˜åˆ¥': 'âœ…' if status['speaker_id'] == 'completed' else 'âŒ' if status['speaker_id'] == 'error' else 'â­ï¸',
                'æ ¡æ­£': 'âœ…' if status['rag_proofread'] == 'completed' else 'âŒ' if status['rag_proofread'] == 'error' else 'â­ï¸'
            })

        st.dataframe(pd.DataFrame(status_summary), use_container_width=True, hide_index=True)

        st.divider()

        # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœè¡¨ç¤º
        st.write("**å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœ**")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚¿ãƒ–ã‚’ä½œæˆ
        file_names = [f['name'] for f in st.session_state.batch_extracted_files]
        file_tabs = st.tabs(file_names)

        for tab_idx, (file_tab, file_info) in enumerate(zip(file_tabs, st.session_state.batch_extracted_files)):
            with file_tab:
                selected_file = file_info['name']

                if selected_file in st.session_state.batch_processing_results:
                    result = st.session_state.batch_processing_results[selected_file]

                    content_tab1, content_tab2, content_tab3 = st.tabs(["ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ", "ğŸ¤ è©±è€…è­˜åˆ¥çµæœ", "ğŸ“š æ ¡æ­£çµæœ"])

                    with content_tab1:
                        if 'transcription_df' in result:
                            st.dataframe(result['transcription_df'], use_container_width=True)

                            # Excelå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            excel_buffer = BytesIO()
                            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                result['transcription_df'].to_excel(writer, index=False, sheet_name='æ–‡å­—èµ·ã“ã—')
                            excel_buffer.seek(0)

                            st.download_button(
                                label="ğŸ“¥ Excelå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=excel_buffer,
                                file_name=f"{os.path.splitext(selected_file)[0]}_transcription.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key=f"download_excel_{selected_file}_{tab_idx}"
                            )
                        else:
                            st.info("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“")

                    with content_tab2:
                        meeting_text = result.get('meeting_text')
                        if not meeting_text:
                            source_df = result.get('identified_df') or result.get('transcription_df')
                            meeting_text = build_meeting_text_from_dataframe(source_df) if source_df is not None else ""
                            if meeting_text:
                                st.session_state.batch_processing_results[selected_file]['meeting_text'] = meeting_text

                        if meeting_text:
                            st.text_area(
                                "è­°äº‹éŒ²å½¢å¼ãƒ†ã‚­ã‚¹ãƒˆ",
                                meeting_text,
                                height=400,
                                key=f"meeting_text_view_{selected_file}_{tab_idx}"
                            )

                            doc = DocxDocument()
                            doc.add_heading(f'è­°äº‹éŒ²: {selected_file}', level=1)
                            for line in meeting_text.splitlines():
                                doc.add_paragraph(line)

                            docx_buffer = BytesIO()
                            doc.save(docx_buffer)
                            docx_buffer.seek(0)

                            st.download_button(
                                label="ğŸ“¥ è­°äº‹éŒ²ï¼ˆWordï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=docx_buffer,
                                file_name=f"{os.path.splitext(selected_file)[0]}_minutes.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                key=f"download_docx_{selected_file}_{tab_idx}"
                            )
                        else:
                            st.info("è­°äº‹éŒ²å½¢å¼ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆè©±è€…è­˜åˆ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå ´åˆã¯Step 2ã®çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")

                    with content_tab3:
                        if 'proofread_text' in result:
                            st.text_area(
                                "æ ¡æ­£å¾Œãƒ†ã‚­ã‚¹ãƒˆ",
                                value=result['proofread_text'],
                                height=400,
                                key=f"proofread_view_{selected_file}_{tab_idx}"
                            )

                            # Wordå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            doc = DocxDocument()
                            doc.add_heading(f'æ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²: {selected_file}', level=1)
                            doc.add_paragraph(result['proofread_text'])

                            docx_buffer = BytesIO()
                            doc.save(docx_buffer)
                            docx_buffer.seek(0)

                            st.download_button(
                                label="ğŸ“¥ æ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²ï¼ˆWordï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=docx_buffer,
                                file_name=f"{os.path.splitext(selected_file)[0]}_proofread.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                key=f"download_proofread_{selected_file}_{tab_idx}"
                            )
                        else:
                            st.info("æ ¡æ­£çµæœãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰")
                else:
                    st.info("ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“")

        st.divider()

        # ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
        st.write("**ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**")
        st.write("ã™ã¹ã¦ã®å‡¦ç†çµæœã‚’ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")

        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("ğŸ“¦ ZIPã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="batch_download_all", use_container_width=True):
                with st.spinner("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                    try:
                        zip_buffer = BytesIO()

                        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                            for file_name, result in st.session_state.batch_processing_results.items():
                                base_name = os.path.splitext(file_name)[0]

                                # æ–‡å­—èµ·ã“ã—çµæœï¼ˆExcelï¼‰
                                if 'transcription_df' in result:
                                    excel_buffer = BytesIO()
                                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                        result['transcription_df'].to_excel(writer, index=False, sheet_name='æ–‡å­—èµ·ã“ã—')
                                    excel_buffer.seek(0)
                                    zip_file.writestr(f"{base_name}_transcription.xlsx", excel_buffer.read())

                                # è©±è€…è­˜åˆ¥çµæœï¼ˆWordï¼‰
                                if 'identified_df' in result:
                                    doc = DocxDocument()
                                    doc.add_heading(f'è­°äº‹éŒ²: {file_name}', level=1)

                                    # é€£ç¶šã™ã‚‹åŒã˜è©±è€…ã®ç™ºè¨€ã‚’çµåˆ
                                    df = result['identified_df'].copy()
                                    df['speaker_filled'] = df['speaker'].replace('', pd.NA)
                                    df['speaker_filled'] = df['speaker_filled'].ffill()
                                    df['group_id'] = (df['speaker_filled'] != df['speaker_filled'].shift()).cumsum()
                                    df_merged = df.groupby('group_id').agg(
                                        speaker=('speaker_filled', 'first'),
                                        text=('text', ' '.join)
                                    ).reset_index(drop=True)

                                    for _, row in df_merged.iterrows():
                                        speaker = row.get('speaker', 'ä¸æ˜')
                                        text = row.get('text', '')
                                        speaker_str = speaker if speaker else 'ä¸æ˜'
                                        doc.add_paragraph(f"ï¼ˆ{speaker_str}ï¼‰{text}")

                                    docx_buffer = BytesIO()
                                    doc.save(docx_buffer)
                                    docx_buffer.seek(0)
                                    zip_file.writestr(f"{base_name}_minutes.docx", docx_buffer.read())

                                # RAGæ ¡æ­£çµæœï¼ˆWordï¼‰
                                if 'proofread_text' in result:
                                    doc = DocxDocument()
                                    doc.add_heading(f'æ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²: {file_name}', level=1)
                                    doc.add_paragraph(result['proofread_text'])
                                    docx_buffer = BytesIO()
                                    doc.save(docx_buffer)
                                    docx_buffer.seek(0)
                                    zip_file.writestr(f"{base_name}_proofread.docx", docx_buffer.read())

                        zip_buffer.seek(0)

                        trigger_auto_download(
                            zip_buffer.getvalue(),
                            file_name=f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                            key="batch_final_download",
                            mime="application/zip"
                        )

                        st.success("âœ… ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                    except Exception as e:
                        st.error(f"âŒ ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        import traceback
                        st.error(traceback.format_exc())

        with col2:
            if st.button("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœWordã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="batch_download_transcription_word", use_container_width=True):
                with st.spinner("Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                    try:
                        # 1ã¤ã®Wordãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
                        doc = DocxDocument()
                        doc.add_heading('æ–‡å­—èµ·ã“ã—çµæœï¼ˆä¸€æ‹¬ï¼‰', level=0)
                        doc.add_paragraph(f'ä½œæˆæ—¥æ™‚: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}')
                        doc.add_paragraph('')

                        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœã‚’è¿½åŠ 
                        for idx, (file_name, result) in enumerate(st.session_state.batch_processing_results.items(), 1):
                            # ãƒ•ã‚¡ã‚¤ãƒ«è¦‹å‡ºã—
                            doc.add_heading(f'{idx}. {file_name}', level=1)
                            doc.add_paragraph('')

                            base_df = result.get('identified_df')
                            if base_df is None or base_df.empty:
                                fallback_df = result.get('transcription_df')
                                base_df = fallback_df if fallback_df is not None else None
                            meeting_text = result.get('meeting_text')
                            if meeting_text is None and base_df is not None and not base_df.empty:
                                meeting_text = build_meeting_text_from_dataframe(base_df)
                                if meeting_text:
                                    st.session_state.batch_processing_results[file_name]['meeting_text'] = meeting_text

                            if meeting_text:
                                doc.add_heading('è­°äº‹éŒ²ï¼ˆè©±è€…è­˜åˆ¥çµæœï¼‰', level=2)
                                for line in meeting_text.splitlines():
                                    if line.strip():
                                        doc.add_paragraph(line)
                            else:
                                doc.add_paragraph('ï¼ˆæ–‡å­—èµ·ã“ã—çµæœãªã—ï¼‰')

                            doc.add_paragraph('')

                            # ãƒ•ã‚¡ã‚¤ãƒ«é–“ã®åŒºåˆ‡ã‚Š
                            if idx < len(st.session_state.batch_processing_results):
                                doc.add_page_break()

                        # Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                        docx_buffer = BytesIO()
                        doc.save(docx_buffer)
                        docx_buffer.seek(0)

                        trigger_auto_download(
                            docx_buffer.getvalue(),
                            file_name=f"batch_transcription_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                            key="batch_final_download_transcription_word",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )

                        st.success("âœ… Wordãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                    except Exception as e:
                        st.error(f"âŒ Wordãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        import traceback
                        st.error(traceback.format_exc())

        with col3:
            if st.button("ğŸ“š æ ¡æ­£çµæœWordã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="batch_download_rag_word", use_container_width=True):
                with st.spinner("Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                    try:
                        # 1ã¤ã®Wordãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
                        doc = DocxDocument()
                        doc.add_heading('æ ¡æ­£çµæœï¼ˆä¸€æ‹¬ï¼‰', level=0)
                        doc.add_paragraph(f'ä½œæˆæ—¥æ™‚: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}')
                        doc.add_paragraph('')

                        # æ ¡æ­£çµæœãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
                        rag_count = 0
                        for idx, (file_name, result) in enumerate(st.session_state.batch_processing_results.items(), 1):
                            if 'proofread_text' in result:
                                rag_count += 1
                                # ãƒ•ã‚¡ã‚¤ãƒ«è¦‹å‡ºã—
                                doc.add_heading(f'{rag_count}. {file_name}', level=1)
                                doc.add_paragraph('')

                                # æ ¡æ­£çµæœ
                                doc.add_heading('æ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²', level=2)
                                # æ®µè½ã”ã¨ã«åˆ†å‰²ã—ã¦è¿½åŠ 
                                for paragraph in result['proofread_text'].split('\n'):
                                    if paragraph.strip():
                                        doc.add_paragraph(paragraph)
                                doc.add_paragraph('')

                                # ãƒ•ã‚¡ã‚¤ãƒ«é–“ã®åŒºåˆ‡ã‚Šï¼ˆæœ€å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ä»¥å¤–ï¼‰
                                if rag_count < sum(1 for r in st.session_state.batch_processing_results.values() if 'proofread_text' in r):
                                    doc.add_page_break()

                        if rag_count == 0:
                            doc.add_paragraph('ï¼ˆæ ¡æ­£çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¦ã„ã¾ã™ï¼‰')

                        # Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                        docx_buffer = BytesIO()
                        doc.save(docx_buffer)
                        docx_buffer.seek(0)

                        trigger_auto_download(
                            docx_buffer.getvalue(),
                            file_name=f"batch_rag_proofread_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                            key="batch_final_download_rag_word",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )

                        st.success("âœ… Wordãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                    except Exception as e:
                        st.error(f"âŒ Wordãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        import traceback
                        st.error(traceback.format_exc())


def video_to_audio_cutter_app():
    st.title("å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—MP3ã§ä¿å­˜")
    st.write("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ‡ã‚Šå‡ºã—ãŸã„é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚è¤‡æ•°ã®åŒºé–“ã‚’åˆ‡ã‚Šå‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚")

    uploaded_video = st.file_uploader("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["wav","mp3","mp4", "mov", "avi", "mkv", "webm"])

    if uploaded_video is not None:
        st.video(uploaded_video)

        st.subheader("åˆ‡ã‚Šå‡ºã—åŒºé–“ã®è¨­å®š")
        # Use st.data_editor for multiple time range inputs
        # Default for the first row includes segment_1
        default_data = pd.DataFrame([
            {"é–‹å§‹æ™‚é–“": "00:00:00", "çµ‚äº†æ™‚é–“": "00:00:30", "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å": f"{os.path.splitext(uploaded_video.name)[0]}_"}
        ])
        edited_df = st.data_editor(
            default_data,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "é–‹å§‹æ™‚é–“": st.column_config.TextColumn(
                    "é–‹å§‹æ™‚é–“ (HH:MM:SS or seconds)",
                    help="åˆ‡ã‚Šå‡ºã—é–‹å§‹æ™‚é–“ (ä¾‹: 00:00:10 ã¾ãŸã¯ 10)",
                    default="00:00:00"
                ),
                "çµ‚äº†æ™‚é–“": st.column_config.TextColumn(
                    "çµ‚äº†æ™‚é–“ (HH:MM:SS or seconds)",
                    help="åˆ‡ã‚Šå‡ºã—çµ‚äº†æ™‚é–“ (ä¾‹: 00:00:30 ã¾ãŸã¯ 30)",
                    default="00:00:30"
                ),
                "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å": st.column_config.TextColumn(
                    "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å (.mp3)",
                    help="ã“ã®åŒºé–“ã®MP3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: my_audio_segment.mp3)ã€‚'AUTO_GENERATE'ã¨å…¥åŠ›ã™ã‚‹ã‹ç©ºæ¬„ã®å ´åˆã€è‡ªå‹•ã§é€£ç•ªãŒæŒ¯ã‚‰ã‚Œã¾ã™ã€‚",
                    default=f"{os.path.splitext(uploaded_video.name)[0]}_" # Explicit placeholder for new rows
                )
            }
        )

        if st.button("éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—ã¦MP3ã§ä¿å­˜"):
            if edited_df.empty:
                st.warning("åˆ‡ã‚Šå‡ºã—åŒºé–“ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return

            temp_video_path = ""
            output_audio_paths = [] # List to store paths of all generated MP3s
            zip_buffer = BytesIO()

            try:
                # Save uploaded video to a temporary file
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_video.name.split('.')[-1]}") as temp_video_file:
                    temp_video_file.write(uploaded_video.read())
                    temp_video_path = temp_video_file.name

                with st.spinner("éŸ³å£°ã®åˆ‡ã‚Šå‡ºã—ã¨MP3ã¸ã®å¤‰æ›ä¸­..."):
                    for index, row in edited_df.iterrows():
                        start_time_str = str(row["é–‹å§‹æ™‚é–“"])
                        end_time_str = str(row["çµ‚äº†æ™‚é–“"])
                        output_filename_raw = str(row["å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å"]).strip()

                        try:
                            start_seconds = parse_time_to_seconds(start_time_str)
                            end_seconds = parse_time_to_seconds(end_time_str)

                            if start_seconds >= end_seconds:
                                st.error(f"åŒºé–“ {index+1}: é–‹å§‹æ™‚é–“ ({start_time_str}) ã¯çµ‚äº†æ™‚é–“ ({end_time_str}) ã‚ˆã‚Šå‰ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚ã“ã®åŒºé–“ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
                                continue

                            # If output filename is empty or matches the explicit placeholder, generate one with index
                            base_name_from_video = os.path.splitext(uploaded_video.name)[0]

                            if not output_filename_raw or output_filename_raw.upper() == "AUTO_GENERATE":
                                output_filename_to_use = f"{base_name_from_video}_segment_{index+1}.mp3"
                            else:
                                output_filename_to_use = output_filename_raw

                            # Ensure the output filename ends with .mp3
                            if not output_filename_to_use.lower().endswith(".mp3"):
                                output_filename_to_use += ".mp3"

                            output_audio_path = os.path.join(tempfile.gettempdir(), output_filename_to_use)

                            command = [
                                "ffmpeg",
                                "-i", temp_video_path,
                                "-ss", format_time(start_seconds),
                                "-to", format_time(end_seconds),
                                "-vn",  # No video
                                "-ab", "192k", # Audio bitrate
                                "-map_metadata", "-1", # Remove metadata
                                "-y", # Overwrite output files without asking
                                output_audio_path
                            ]

                            st.info(f"åŒºé–“ {index+1} FFmpegã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œä¸­: {' '.join(command)}")

                            process = subprocess.run(command, capture_output=True, text=True, encoding="utf-8", check=True)
                            st.success(f"åŒºé–“ {index+1} ã®éŸ³å£°åˆ‡ã‚Šå‡ºã—ã¨MP3ã¸ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            st.code(process.stdout)
                            st.code(process.stderr)
                            output_audio_paths.append(output_audio_path)

                        except subprocess.CalledProcessError as e:
                            st.error(f"åŒºé–“ {index+1} FFmpegã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                            st.code(e.stdout)
                            st.code(e.stderr)
                            st.warning("FFmpegãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã€PATHãŒé€šã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        except ValueError as e:
                            st.error(f"åŒºé–“ {index+1} æ™‚é–“å½¢å¼ã‚¨ãƒ©ãƒ¼: {e}")
                        except Exception as e:
                            st.error(f"åŒºé–“ {index+1} å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

                if output_audio_paths:
                    st.subheader("ç”Ÿæˆã•ã‚ŒãŸMP3ãƒ•ã‚¡ã‚¤ãƒ«")
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                        for audio_path in output_audio_paths:
                            if os.path.exists(audio_path):
                                zf.write(audio_path, os.path.basename(audio_path))
                                st.write(f"- {os.path.basename(audio_path)}")
                    zip_buffer.seek(0)

                    st.download_button(
                        label="å…¨ã¦ã®MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)",
                        data=zip_buffer,
                        file_name=f"{os.path.splitext(uploaded_video.name)[0]}_cut_audios.zip",
                        mime="application/zip"
                    )
                else:
                    st.warning("åˆ‡ã‚Šå‡ºã•ã‚ŒãŸMP3ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

            except Exception as e:
                st.error(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            finally:
                # Clean up temporary files
                if os.path.exists(temp_video_path):
                    os.remove(temp_video_path)
                for audio_path in output_audio_paths:
                    if os.path.exists(audio_path):
                        os.remove(audio_path)

def _init_session_state(defaults):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def _load_dspy_module():
    """dspyã®èª­ã¿è¾¼ã¿ã‚’è©¦ã¿ã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨çŠ¶æ…‹ã‚’è¿”å´"""
    spec = importlib.util.find_spec("dspy")
    if spec is None:
        return None, "dspyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install dspy-ai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"

    dspy = importlib.import_module("dspy")
    return dspy, None


DEFAULT_MINUTES_PROMPT = (
    "ã‚ãªãŸã¯ç†Ÿç·´ã®è­°äº‹éŒ²å°‚é–€å®¶ã§ã™ã€‚ç™ºè¨€ã®æ„å›³ã‚’æ±²ã¿å–ã‚Šã€æ±ºå®šäº‹é …ãƒ»TODOãƒ»è«–ç‚¹ã‚’ä¸­å¿ƒã«ã€"
    "ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®æ®µè½ã«æ•´å½¢ã—ã¦ãã ã•ã„ã€‚ä¸è¦ãªãƒã‚¤ã‚ºã‚„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯é™¤å»ã—ã¾ã™ã€‚"
)


def _build_minutes_directives(style_label: str, focus_points: str, length_hint: int, include_todo: bool) -> str:
    """è­°äº‹éŒ²æ•´å½¢ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒ†ã‚£ãƒ–æ–‡å­—åˆ—ã‚’ç”Ÿæˆ"""
    focus_text = focus_points.strip() if focus_points else "æ±ºå®šäº‹é …ãƒ»TODOãƒ»è«–ç‚¹ã‚’ä¸­å¿ƒã«æ•´ç†ã—ã¦ãã ã•ã„ã€‚"
    style_templates = {
        "è¦ç‚¹ã‚µãƒãƒªãƒ¼": "é‡è¦ãªæ„æ€æ±ºå®šãƒ»è«–ç‚¹ãƒ»TODOã‚’è¦‹å‡ºã—ä»˜ãã§ç®‡æ¡æ›¸ãã€‚1é …ç›®ã«ã¤ã1-2æ–‡ã§ç«¯çš„ã«ã€‚",
        "æ™‚ç³»åˆ—ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ": "è­°äº‹é€²è¡Œã®é †ã«ã€ç™ºè¨€ã®ã¾ã¨ã¾ã‚Šã”ã¨ã«çŸ­ã„æ®µè½ã§ã¾ã¨ã‚ã‚‹ã€‚æµã‚ŒãŒè¿½ã„ã‚„ã™ã„ã‚ˆã†æ¥ç¶šè©ã‚’é©åº¦ã«é…ç½®ã€‚",
        "æ±ºå®šäº‹é …ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆ": "æ±ºå®šäº‹é …ãƒ»åˆæ„äº‹é …ã‚’å…ˆé ­ã«ã¾ã¨ã‚ã€ç¶šã‘ã¦æ ¹æ‹ ã‚„æ‡¸å¿µç‚¹ã‚’ç°¡æ½”ã«åˆ—æŒ™ã€‚",
    }
    todo_line = "æ±ºå®šäº‹é …ã¨TODOã¯å¤ªå­—ã®è¦‹å‡ºã—ã§ã¾ã¨ã‚ã€ç®‡æ¡æ›¸ãã§ç°¡æ½”ã«æ›¸ã„ã¦ãã ã•ã„ã€‚" if include_todo else "é‡è¦ç®‡æ¡æ›¸ãã¯ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"

    return (
        f"æ•´ç†ã‚¹ã‚¿ã‚¤ãƒ«: {style_templates.get(style_label, style_label)}\n"
        f"ãƒ•ã‚©ãƒ¼ã‚«ã‚¹: {focus_text}\n"
        f"é•·ã•ã®ç›®å®‰: {length_hint} æ®µè½ç¨‹åº¦ã§ç°¡æ½”ã«\n"
        f"{todo_line}\n"
        "æ™‚åˆ»è¡¨ç¾ã‚„ãƒã‚¤ã‚ºã¯é™¤å»ã—ã€æ—¥æœ¬èªã§èª­ã¿ã‚„ã™ãç·¨é›†ã—ã¾ã™ã€‚"
    )


def _parse_minutes_dataset(uploaded_file):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    try:
        content = uploaded_file.read().decode("utf-8")
    except Exception as e:
        return [], f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

    records = []
    try:
        if uploaded_file.name.lower().endswith(".jsonl"):
            for line in content.splitlines():
                if not line.strip():
                    continue
                data = json.loads(line)
                transcript = data.get("transcript")
                minutes = data.get("minutes")
                if transcript and minutes:
                    records.append({"transcript": transcript, "minutes": minutes})
        else:
            data = json.loads(content)
            if isinstance(data, list):
                for item in data:
                    transcript = item.get("transcript")
                    minutes = item.get("minutes")
                    if transcript and minutes:
                        records.append({"transcript": transcript, "minutes": minutes})
            elif isinstance(data, dict):
                dataset_items = data.get("data") or []
                for item in dataset_items:
                    transcript = item.get("transcript")
                    minutes = item.get("minutes")
                    if transcript and minutes:
                        records.append({"transcript": transcript, "minutes": minutes})
    except json.JSONDecodeError as e:
        return [], f"JSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

    if not records:
        return [], "æœ‰åŠ¹ãªtranscriptãƒ»minutesã®ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

    return records, None


def _minutes_similarity_metric(example, prediction, trace=None):
    """MIPROv2ç”¨ã®ç°¡æ˜“é¡ä¼¼åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    target_minutes = getattr(example, "minutes", "") or ""
    predicted_minutes = getattr(prediction, "minutes", "") or ""

    if not target_minutes or not predicted_minutes:
        return 0.0

    target_tokens = set(target_minutes.split())
    predicted_tokens = set(predicted_minutes.split())
    if not target_tokens:
        return 0.0

    overlap = len(target_tokens & predicted_tokens)
    return overlap / len(target_tokens)


def _optimize_minutes_prompt(dataset, base_prompt, model_name, max_iters=3, num_candidates=4):
    """MIPROv2ã‚’ç”¨ã„ã¦è­°äº‹éŒ²ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€é©åŒ–"""
    dspy, error_message = _load_dspy_module()
    if dspy is None:
        return None, error_message

    teleprompt_spec = importlib.util.find_spec("dspy.teleprompt")
    if teleprompt_spec is None:
        return None, "dspy.teleprompt ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚dspyã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

    teleprompt_module = importlib.import_module("dspy.teleprompt")
    if not hasattr(teleprompt_module, "MIPROv2"):
        return None, "MIPROv2 ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚dspyã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚"

    MIPROv2 = getattr(teleprompt_module, "MIPROv2")

    azure_lm = dspy.AzureOpenAI(
        model=model_name,
        api_base=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=API_VERSION,
        max_tokens=1200,
        temperature=0.3,
    )
    dspy.settings.configure(lm=azure_lm)

    class MinutesRewrite(dspy.Signature):
        """MIPROç”¨ã®è­°äº‹éŒ²ãƒªãƒ©ã‚¤ãƒˆã‚·ã‚°ãƒãƒãƒ£"""

        transcript: str = dspy.InputField(desc="å…ƒã®æ–‡å­—èµ·ã“ã—")
        refinement_directives: str = dspy.InputField(desc="æ•´å½¢æ–¹é‡")
        minutes: str = dspy.OutputField(desc="æ•´å½¢æ¸ˆã¿è­°äº‹éŒ²")

    program = dspy.Predict(MinutesRewrite)

    trainset = []
    for item in dataset:
        transcript = item.get("transcript")
        minutes = item.get("minutes")
        if not transcript or not minutes:
            continue
        example = dspy.Example(
            transcript=transcript,
            refinement_directives=base_prompt,
            minutes=minutes,
        ).with_inputs("transcript", "refinement_directives")
        trainset.append(example)

    if not trainset:
        return None, "å­¦ç¿’ã«ä½¿ãˆã‚‹ã‚µãƒ³ãƒ—ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

    teleprompter = MIPROv2(
        metric=_minutes_similarity_metric,
        init_prompt=base_prompt,
        num_candidates=num_candidates,
        max_iters=max_iters,
        allow_refusal=False,
        verbose=False,
    )

    optimized_program = teleprompter.compile(program, trainset=trainset)

    optimized_prompt = getattr(teleprompter, "best_prompt", None)
    if not optimized_prompt:
        optimized_prompt = getattr(optimized_program, "prompt", None)
    if not optimized_prompt and hasattr(optimized_program, "signature"):
        optimized_prompt = getattr(optimized_program.signature, "instructions", None)

    return optimized_prompt or base_prompt, None


def _generate_minutes_with_dspy(transcript_text: str, directives: str, model_name: str):
    """dspyã‚’åˆ©ç”¨ã—ã¦è­°äº‹éŒ²ã‚’ç”Ÿæˆ"""
    dspy, error_message = _load_dspy_module()
    if dspy is None:
        return None, error_message

    try:
        azure_lm = dspy.AzureOpenAI(
            model=model_name,
            api_base=AZURE_OPENAI_ENDPOINT,
            api_key=AZURE_OPENAI_API_KEY,
            api_version=API_VERSION,
            max_tokens=1200,
            temperature=0.3,
        )
        dspy.settings.configure(lm=azure_lm)

        class MinutesRewrite(dspy.Signature):
            """æ–‡å­—èµ·ã“ã—ã‚’è­°äº‹éŒ²å½¢å¼ã«æ•´ãˆã‚‹"""

            transcript: str = dspy.InputField(desc="å…ƒã®æ–‡å­—èµ·ã“ã—")
            refinement_directives: str = dspy.InputField(desc="æ•´å½¢æ–¹é‡")
            minutes: str = dspy.OutputField(desc="æ•´å½¢æ¸ˆã¿è­°äº‹éŒ²")

        predictor = dspy.Predict(MinutesRewrite)
        result = predictor(
            transcript=transcript_text,
            refinement_directives=directives
        )

        minutes_text = getattr(result, "minutes", None)
        if not minutes_text and hasattr(result, "response"):
            minutes_text = getattr(result, "response")

        return minutes_text, None
    except Exception as e:
        return None, str(e)


def _generate_minutes_with_fallback(transcript_text: str, directives: str, model_name: str):
    """Azure OpenAIã‚’ä½¿ã£ãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®è­°äº‹éŒ²ç”Ÿæˆ"""
    fallback_system_prompt = (
        "ã‚ãªãŸã¯è­°äº‹éŒ²è¦ç´„ã®å°‚é–€å®¶ã§ã™ã€‚æ–‡å­—èµ·ã“ã—ã‚’èª­ã¿ã‚„ã™ãæ•´ç†ã—ã€å‚åŠ è€…ãŒã™ãã«æŒ¯ã‚Šè¿”ã‚Œã‚‹å½¢ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
        "ä¸è¦ãªç›¸æ§Œã‚„ãƒã‚¤ã‚ºã¯é™¤å»ã—ã€æ–‡ä½“ã‚’æ•´ãˆã¾ã™ã€‚æ±ºå®šäº‹é …ãƒ»TODOãƒ»è«–ç‚¹ãŒåˆ†ã‹ã‚‹ã‚ˆã†ã«çŸ­ã„è¦‹å‡ºã—ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚\n"
        f"{directives}\n"
        "å‡ºåŠ›ã¯æ—¥æœ¬èªã§ã€éåº¦ã«é•·ããªã‚‰ãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚"
    )

    return generate_summary(model_name, fallback_system_prompt, transcript_text)


def _create_row_labels(df):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰è¡Œé¸æŠç”¨ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆ"""
    labels = []
    for idx, row in df.iterrows():
        text = row.get('text', '')
        text_display = text[:30] + "..." if len(text) > 30 else text
        label = f"{idx}: {row.get('start', '')} | {row.get('end', '')} | {row.get('speaker', '')} | {text_display}"
        labels.append(label)
    return labels

def prepare_embedding_preview_audio(audio_io, df, selected_indices):
    """ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®éŸ³å£°ã‚’æº–å‚™

    Args:
        audio_io: BytesIO - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        df: DataFrame - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å«ã‚€
        selected_indices: list - é¸æŠè¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ

    Returns:
        preview_bytes: bytes - WAVå½¢å¼ã®éŸ³å£°ãƒã‚¤ãƒˆåˆ—
        duration: float - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰
    """
    if not selected_indices:
        raise ValueError("é¸æŠè¡ŒãŒã‚ã‚Šã¾ã›ã‚“")

    selected_rows = df.iloc[sorted(selected_indices)]
    start_sec = selected_rows['start'].min()
    end_sec = selected_rows['end'].max()

    audio_io.seek(0)
    with temp_file_path(audio_io.getvalue(), ".mp3") as audio_path:
        audio = AudioSegment.from_file(audio_path)

        start_ms = int(start_sec * 1000)
        end_ms = int(end_sec * 1000)
        audio_segment = audio[start_ms:end_ms]

        preview_bytes = audio_segment.export(format="wav").read()

    return preview_bytes, (end_sec - start_sec)

def extract_audio_segment_for_embedding(audio_io, df, selected_indices):
    """é¸æŠè¡Œã‹ã‚‰éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡ºã—ã¦åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆ

    Args:
        audio_io: BytesIO - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        df: DataFrame - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å«ã‚€
        selected_indices: list - é¸æŠè¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ

    Returns:
        embedding: np.ndarray - ç”Ÿæˆã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
        duration: float - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰
    """
    if not selected_indices:
        raise ValueError("é¸æŠè¡ŒãŒã‚ã‚Šã¾ã›ã‚“")

    selected_rows = df.iloc[sorted(selected_indices)]
    start_sec = selected_rows['start'].min()
    end_sec = selected_rows['end'].max()

    audio_io.seek(0)
    with temp_file_path(audio_io.getvalue(), ".mp3") as audio_path:
        audio = AudioSegment.from_file(audio_path)

        start_ms = int(start_sec * 1000)
        end_ms = int(end_sec * 1000)
        audio_segment = audio[start_ms:end_ms]

        wav_bytes = audio_segment.export(format="wav").read()

    embedding = _compute_embedding_from_wav_bytes(wav_bytes)

    return embedding, (end_sec - start_sec)

def get_selection_summary(df, selected_indices):
    """é¸æŠè¡Œã®æ¦‚è¦æƒ…å ±ã‚’å–å¾—

    Args:
        df: DataFrame
        selected_indices: set or list - é¸æŠè¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

    Returns:
        dict - æ¦‚è¦æƒ…å ±
    """
    if not selected_indices:
        return {
            'count': 0,
            'start_time': None,
            'end_time': None,
            'duration': 0,
            'speakers': []
        }

    sorted_indices = sorted(selected_indices)
    selected_rows = df.iloc[sorted_indices]

    start_time = selected_rows['start'].min()
    end_time = selected_rows['end'].max()
    duration = end_time - start_time
    speakers = selected_rows['speaker'].dropna().unique().tolist() if 'speaker' in selected_rows.columns else []

    return {
        'count': len(sorted_indices),
        'start_time': start_time,
        'end_time': end_time,
        'duration': duration,
        'speakers': speakers
    }

def get_default_ragdb_path():
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆRAGDBãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—

    Returns:
        str - RAGDBãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹
    """
    if DEFAULT_RAGDB_FOLDER:
        # ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        os.makedirs(DEFAULT_RAGDB_FOLDER, exist_ok=True)
        return os.path.join(DEFAULT_RAGDB_FOLDER, "default_knowledge_base.ragdb")
    else:
        return "default_knowledge_base.ragdb"

def load_meeting_type_config():
    """ä¼šè­°ã‚¿ã‚¤ãƒ—è¨­å®šã‚’å–å¾—

    Returns:
        list - ä¼šè­°ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ
    """
    try:
        return [dict(item) for item in DEFAULT_MEETING_TYPES]
    except Exception as e:
        st.error(f"âŒ ä¼šè­°ã‚¿ã‚¤ãƒ—è¨­å®šã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def load_embeddings_from_folder(folder_path):
    """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.npyï¼‰ã‚’ä¸€æ‹¬èª­ã¿è¾¼ã¿

    Args:
        folder_path (str): è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹

    Returns:
        list - ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ãƒªã‚¹ãƒˆ [{'name': filename, 'data': file_content_bytes}, ...]
                èª­ã¿è¾¼ã‚ãªã„å ´åˆã¯ç©ºãƒªã‚¹ãƒˆ
    """
    embeddings = []

    try:
        # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
        if not os.path.isabs(folder_path):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            folder_path = os.path.join(script_dir, folder_path)

        if not os.path.exists(folder_path):
            st.warning(f"âš ï¸ è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {folder_path}")
            return []

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®.npyãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        npy_files = [f for f in os.listdir(folder_path) if f.endswith('.npy')]

        if not npy_files:
            st.info(f"ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€å†…ã«.npyãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {folder_path}")
            return []

        # å„.npyãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        for filename in npy_files:
            file_path = os.path.join(folder_path, filename)
            with open(file_path, 'rb') as f:
                file_bytes = f.read()
                embeddings.append({
                    'name': filename,
                    'data': file_bytes
                })

        return embeddings

    except Exception as e:
        st.error(f"âŒ è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def video_transcribe_and_identify():
    st.title("æ–‡å­—èµ·ã“ã—")
    st.write("éŸ³å£°ãƒ»å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã€è­°äº‹éŒ²ã‚’ä½œæˆã—ã¾ã™ã€‚")

    st.sidebar.markdown("""
    ### ğŸ“ æ–‡å­—èµ·ã“ã—

    **æ¦‚è¦**
    æ–‡å­—èµ·ã“ã—ã¨è©±è€…è­˜åˆ¥ã«å¯¾å¿œã€‚ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠå¯èƒ½ã€‚

    **ä¸»ãªæ©Ÿèƒ½**
    - AIæ–‡å­—èµ·ã“ã—: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã
    - ãƒ¢ãƒ‡ãƒ«é¸æŠå¯èƒ½:
      - gpt-4o-transcribe-diarizeï¼ˆè‡ªå‹•è©±è€…è­˜åˆ¥ä»˜ãï¼‰
      - Whisperï¼ˆå‚è€ƒè³‡æ–™å¯¾å¿œã€å¾Œã‹ã‚‰è©±è€…è­˜åˆ¥å¯èƒ½ï¼‰
    - è­°äº‹éŒ²å‡ºåŠ›: Wordãƒ»Excelå½¢å¼

    **å¯¾å¿œå½¢å¼:** MP3, WAV, M4A, MP4, WebM, OGG, MOV, AVI, MKV
    """)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    _init_session_state({
        'video_combined_step': 1,
        'video_combined_audio_io': None,
        'video_combined_df': None,
        'video_combined_identified_df': pd.DataFrame(),
        'video_combined_uploaded_file_name': "",
        # è©±è€…åŸ‹ã‚è¾¼ã¿ä½œæˆç”¨ã®çŠ¶æ…‹å¤‰æ•°
        'embedding_selected_rows': set(),
        'embedding_preview_audio': None,
        'embedding_show_preview': False
    })

    # Step 1: ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.subheader("Step 1: ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_media = st.file_uploader(
        "ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=["mp3", "wav", "m4a", "mp4", "webm", "ogg", "mov", "avi", "mkv"],
        key="video_combined_media_upload"
    )

    if uploaded_media is not None:
        st.session_state.video_combined_uploaded_file_name = uploaded_media.name
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ« '{uploaded_media.name}' ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")

        # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå‹•ç”»ã¾ãŸã¯éŸ³å£°ï¼‰
        file_extension = uploaded_media.name.split(".")[-1].lower()
        if file_extension in ["mp4", "webm", "ogg", "mov", "avi", "mkv"]:
            st.video(uploaded_media)
        else:
            st.audio(uploaded_media)

        # Step 2: æ–‡å­—èµ·ã“ã—
        st.subheader("Step 2: æ–‡å­—èµ·ã“ã—")

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        transcribe_model = st.selectbox(
            "æ–‡å­—èµ·ã“ã—ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            options=["gpt-4o-transcribe-diarize", "whisper"],
            index=1,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: whisper
            key="video_combined_model_selection",
            help="gpt-4o-transcribe-diarize: è©±è€…è­˜åˆ¥ä»˜ãï¼ˆå‚è€ƒè³‡æ–™éå¯¾å¿œï¼‰\nwhisper: è©±è€…è­˜åˆ¥ãªã—ï¼ˆå‚è€ƒè³‡æ–™å¯¾å¿œï¼‰"
        )

        # ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜
        if transcribe_model == "gpt-4o-transcribe-diarize":
            st.info("ğŸ¯ **gpt-4o-transcribe-diarize**: è‡ªå‹•è©±è€…è­˜åˆ¥ä»˜ãæ–‡å­—èµ·ã“ã—ã€‚å‚è€ƒè³‡æ–™ï¼ˆpromptï¼‰ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
        else:
            st.info("ğŸ¤ **Whisper**: æ±ç”¨éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã€‚å‚è€ƒè³‡æ–™ã‚’ä½¿ç”¨å¯èƒ½ã€‚Step 4ã§è©±è€…è­˜åˆ¥ã‚’å¾Œã‹ã‚‰å®Ÿè¡Œã§ãã¾ã™ã€‚")

        # å‚è€ƒè³‡æ–™ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        reference_file = st.file_uploader(
            "å‚è€ƒè³‡æ–™ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
            type=["pdf", "docx", "pptx", "txt", "msg"],
            key="video_combined_reference_file",
            help="æ–‡å­—èµ·ã“ã—ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®å‚è€ƒè³‡æ–™ï¼ˆWhisperã®ã¿ã‚µãƒãƒ¼ãƒˆï¼‰"
        )

        if st.button("æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ", key="video_combined_transcribe"):
            with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­..."):
                try:
                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ç”¨
                    uploaded_media.seek(0)
                    audio_file_io = BytesIO(uploaded_media.read())
                    audio_file_io.name = uploaded_media.name

                    seg_df = transcribe_audio_to_dataframe(audio_file_io, reference_file=reference_file, model=transcribe_model)

                    st.session_state.video_combined_df = seg_df
                    st.session_state.video_combined_step = 3

                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆè©±è€…è­˜åˆ¥ç”¨ï¼‰
                    uploaded_media.seek(0)
                    st.session_state.video_combined_audio_io = BytesIO(uploaded_media.read())
                    st.session_state.video_combined_audio_io.name = uploaded_media.name

                    st.success(f"æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆ{len(seg_df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ï¼‰")
                    st.rerun()
                except Exception as e:
                    st.error(f"æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    import traceback
                    st.error(traceback.format_exc())

        # Step 3: çµæœã®ç¢ºèªã¨ç·¨é›†
        if st.session_state.video_combined_step >= 3 and st.session_state.video_combined_df is not None:
            st.subheader("Step 3: çµæœã®ç¢ºèªã¨ç·¨é›†")

            if len(st.session_state.video_combined_df) > 0:
                st.write("æ–‡å­—èµ·ã“ã—çµæœã‚’ç¢ºèªãƒ»ç·¨é›†ã—ã¦ãã ã•ã„:")
                base_df = st.session_state.video_combined_df.copy()
                editable_columns = [col for col in base_df.columns if col in ("speaker",)]
                disabled_cols = [col for col in base_df.columns if col not in editable_columns]

                edited_df = st.data_editor(
                    base_df,
                    num_rows="dynamic",
                    use_container_width=True,
                    disabled=disabled_cols,
                    column_config={
                        "speaker": st.column_config.TextColumn(
                            "è©±è€…",
                            help="å¿…è¦ã«å¿œã˜ã¦è©±è€…åã‚’æ‰‹å‹•ã§èª¿æ•´ã—ã¦ãã ã•ã„"
                        )
                    },
                    key="video_combined_editor"
                )

                if isinstance(edited_df, pd.DataFrame):
                    updated_df = edited_df.copy()
                else:
                    updated_df = pd.DataFrame(edited_df)

                updated_df = updated_df.reset_index(drop=True)
                base_df = base_df.reset_index(drop=True)

                # Ensure all original columns remain
                for column in base_df.columns:
                    if column not in updated_df.columns:
                        updated_df[column] = base_df[column]
                updated_df = updated_df[base_df.columns]

                original_speaker = base_df['speaker'].astype(str).fillna("") if 'speaker' in base_df.columns else None
                updated_speaker = updated_df['speaker'].astype(str).fillna("") if 'speaker' in updated_df.columns else None

                if original_speaker is None or not updated_speaker.equals(original_speaker):
                    st.session_state.video_combined_df = updated_df
                    st.session_state.video_combined_identified_df = updated_df.copy()
                    st.info("âœï¸ è©±è€…ãƒ©ãƒ™ãƒ«ã®å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚å¿…è¦ã«å¿œã˜ã¦Step 4ä»¥é™ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã§ã™ã€‚æ–‡å­—èµ·ã“ã—å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        # Step 4: è©±è€…è­˜åˆ¥
        if st.session_state.video_combined_step >= 3 and st.session_state.video_combined_df is not None:
            st.subheader("Step 4: è©±è€…è­˜åˆ¥")

            # ã‚¿ãƒ–ã§è©±è€…è­˜åˆ¥ã¨åŸ‹ã‚è¾¼ã¿ä½œæˆã‚’åˆ†é›¢
            tab1, tab2 = st.tabs(["è©±è€…è­˜åˆ¥", "è©±è€…åŸ‹ã‚è¾¼ã¿ä½œæˆ"])

            with tab1:
                st.write("è©±è€…è­˜åˆ¥ã‚’è¡Œã†ç¯„å›²ã‚’é¸æŠã—ã¦ãã ã•ã„:")

                # æœ€æ–°ã®ç·¨é›†å†…å®¹ã‚’ä½¿ç”¨
                edited_df = st.session_state.video_combined_df.copy()

                # è­˜åˆ¥æ¸ˆã¿ã®è©±è€…æƒ…å ±ã‚’åæ˜ 
                display_df = edited_df.copy()
                if not st.session_state.video_combined_identified_df.empty:
                    if 'speaker' in st.session_state.video_combined_identified_df.columns:
                        display_df['speaker'] = st.session_state.video_combined_identified_df['speaker']

                if len(display_df) == 0:
                    st.warning("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                else:
                    row_labels = _create_row_labels(display_df)

                    col1, col2, col3 = st.columns([2, 2, 1])
                    with col1:
                        start_row = st.selectbox(
                            "é–‹å§‹è¡Œã‚’é¸æŠ",
                            options=range(len(display_df)),
                            format_func=lambda x: row_labels[x],
                            key="video_combined_start_row"
                        )
                    with col2:
                        end_row = st.selectbox(
                            "çµ‚äº†è¡Œã‚’é¸æŠ",
                            options=range(len(display_df)),
                            format_func=lambda x: row_labels[x],
                            index=len(display_df)-1 if len(display_df) > 0 else 0,
                            key="video_combined_end_row"
                        )
                    with col3:
                        similarity_threshold = st.number_input(
                            "é¡ä¼¼åº¦é–¾å€¤",
                            min_value=0.0,
                            max_value=1.0,
                            value=0.7,
                            step=0.01,
                            key="video_combined_similarity_threshold"
                        )

                    if start_row > end_row:
                        st.error("é–‹å§‹è¡Œã¯çµ‚äº†è¡Œä»¥å‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    else:
                        # è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                        uploaded_embeddings = st.file_uploader(
                            "è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                            type=["npy"],
                            accept_multiple_files=True,
                            key="video_combined_embeddings"
                        )

                        if st.button("è©±è€…è­˜åˆ¥ã‚’å®Ÿè¡Œ", key="video_combined_identify"):
                            if not uploaded_embeddings:
                                st.error("è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                            else:
                                with st.spinner("è©±è€…è­˜åˆ¥ä¸­..."):
                                    try:
                                        # é¸æŠç¯„å›²ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
                                        df_to_identify = edited_df.iloc[start_row:end_row+1].copy()

                                        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ¼ã‚¯ä½ç½®ã‚’ãƒªã‚»ãƒƒãƒˆ
                                        st.session_state.video_combined_audio_io.seek(0)

                                        # è©±è€…è­˜åˆ¥å®Ÿè¡Œ
                                        identified_df = identify_speakers_in_dataframe(
                                            st.session_state.video_combined_audio_io,
                                            df_to_identify,
                                            uploaded_embeddings,
                                            similarity_threshold
                                        )

                                        # é¸æŠç¯„å›²ã®ã¿æ›´æ–°
                                        full_identified_df = edited_df.copy()
                                        for col in identified_df.columns:
                                            full_identified_df.loc[start_row:end_row, col] = identified_df[col].values

                                        st.session_state.video_combined_identified_df = full_identified_df
                                        st.session_state.video_combined_df = full_identified_df
                                        st.session_state.video_combined_step = 5
                                        st.success("è©±è€…è­˜åˆ¥ãŒå®Œäº†ã—ã¾ã—ãŸ")
                                        st.rerun()

                                    except Exception as e:
                                        st.error(f"è©±è€…è­˜åˆ¥ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                                        import traceback
                                        st.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:")
                                        st.code(traceback.format_exc())

            with tab2:
                st.write("éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã—ã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç¢ºèªã—ã¦ã‹ã‚‰è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã§ãã¾ã™ã€‚")

                if len(edited_df) == 0:
                    st.warning("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                else:
                    # === é¸æŠæ–¹å¼ã®åˆ‡ã‚Šæ›¿ãˆ ===
                    selection_mode = st.radio(
                        "é¸æŠæ–¹å¼ã‚’é¸ã‚“ã§ãã ã•ã„",
                        options=["ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰", "ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ¼ãƒ‰"],
                        horizontal=True,
                        help="ç¯„å›²æŒ‡å®š: é€£ç¶šã—ãŸè¡Œã‚’ç´ æ—©ãé¸æŠ | ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹: é£›ã³é£›ã³ã®è¡Œã‚’è‡ªç”±ã«é¸æŠ"
                    )

                    st.divider()

                    # === Part 1: é¸æŠUIï¼ˆæ–¹å¼ã«å¿œã˜ã¦å¤‰æ›´ï¼‰ ===
                    st.subheader("1ï¸âƒ£ éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠ")

                    if selection_mode == "ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰":
                        # æ–¹å¼A: selectboxã«ã‚ˆã‚‹ç¯„å›²æŒ‡å®š
                        embedding_row_labels = _create_row_labels(edited_df)

                        col1, col2 = st.columns(2)
                        with col1:
                            embedding_start_row = st.selectbox(
                                "é–‹å§‹è¡Œã‚’é¸æŠ",
                                options=range(len(edited_df)),
                                format_func=lambda x: embedding_row_labels[x],
                                key="video_combined_embedding_start_row"
                            )
                        with col2:
                            embedding_end_row = st.selectbox(
                                "çµ‚äº†è¡Œã‚’é¸æŠ",
                                options=range(len(edited_df)),
                                format_func=lambda x: embedding_row_labels[x],
                                index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0è¡Œç›®
                                key="video_combined_embedding_end_row"
                            )

                        # ç¯„å›²æŒ‡å®šã®æ¤œè¨¼ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã¸ã®åæ˜ 
                        if embedding_start_row > embedding_end_row:
                            st.error("âš ï¸ é–‹å§‹è¡Œã¯çµ‚äº†è¡Œä»¥å‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
                            st.session_state.embedding_selected_rows = set()
                        else:
                            # ç¯„å›²ã‚’setã«å¤‰æ›
                            st.session_state.embedding_selected_rows = set(range(embedding_start_row, embedding_end_row + 1))
                            st.success(f"âœ… è¡Œ {embedding_start_row} ï½ {embedding_end_row} ã‚’é¸æŠã—ã¾ã—ãŸ")

                    else:
                        # æ–¹å¼B: data_editorã«ã‚ˆã‚‹ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹é¸æŠ
                        display_df = edited_df.copy()
                        display_df.insert(0, "é¸æŠ", False)

                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹é¸æŠè¡Œã‚’åæ˜ 
                        if st.session_state.embedding_selected_rows:
                            for idx in st.session_state.embedding_selected_rows:
                                if idx < len(display_df):
                                    display_df.at[idx, "é¸æŠ"] = True

                        edited_display = st.data_editor(
                            display_df,
                            column_config={
                                "é¸æŠ": st.column_config.CheckboxColumn(
                                    "é¸æŠ",
                                    help="åŸ‹ã‚è¾¼ã¿ä½œæˆå¯¾è±¡ã®è¡Œã‚’ãƒã‚§ãƒƒã‚¯",
                                    default=False
                                )
                            },
                            disabled=["start", "end", "speaker", "text"],
                            use_container_width=True,
                            hide_index=True,
                            key="embedding_data_editor"
                        )

                        # é¸æŠçŠ¶æ…‹ã‚’æ›´æ–°
                        st.session_state.embedding_selected_rows = set(
                            edited_display[edited_display["é¸æŠ"] == True].index.tolist()
                        )

                    # === Part 2ä»¥é™: å…±é€šå‡¦ç†ï¼ˆé¸æŠãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤ºï¼‰ ===
                    if st.session_state.embedding_selected_rows:
                        st.subheader("2ï¸âƒ£ é¸æŠæƒ…å ±ã®ç¢ºèª")

                        selection_summary = get_selection_summary(edited_df, st.session_state.embedding_selected_rows)

                        # æƒ…å ±è¡¨ç¤º
                        info_cols = st.columns(4)
                        with info_cols[0]:
                            st.metric("é¸æŠè¡Œæ•°", selection_summary['count'])
                        with info_cols[1]:
                            st.metric("é–‹å§‹æ™‚åˆ»", format_time(selection_summary['start_time']))
                        with info_cols[2]:
                            st.metric("çµ‚äº†æ™‚åˆ»", format_time(selection_summary['end_time']))
                        with info_cols[3]:
                            st.metric("éŸ³å£°é•·", f"{selection_summary['duration']:.1f}ç§’")

                        # è©±è€…æƒ…å ±ã®è¡¨ç¤º
                        if selection_summary['speakers']:
                            speakers_text = "ã€".join([s if s else "ä¸æ˜" for s in selection_summary['speakers']])
                            st.info(f"ğŸ¤ é¸æŠç¯„å›²ã«å«ã¾ã‚Œã‚‹è©±è€…: {speakers_text}")

                        # === Part 3: éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ===
                        st.subheader("3ï¸âƒ£ éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

                        col_preview, col_clear = st.columns([3, 1])

                        with col_preview:
                            if st.button("ğŸ”Š ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆ", key="generate_preview"):
                                try:
                                    with st.spinner("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                                        preview_bytes, duration = prepare_embedding_preview_audio(
                                            st.session_state.video_combined_audio_io,
                                            edited_df,
                                            list(st.session_state.embedding_selected_rows)
                                        )
                                        st.session_state.embedding_preview_audio = preview_bytes
                                        st.session_state.embedding_show_preview = True
                                    st.success(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆ{duration:.1f}ç§’ï¼‰")
                                except Exception as e:
                                    st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

                        with col_clear:
                            if st.session_state.embedding_show_preview:
                                if st.button("âŒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢", key="clear_preview"):
                                    st.session_state.embedding_preview_audio = None
                                    st.session_state.embedding_show_preview = False
                                    st.rerun()

                        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å†ç”Ÿ
                        if st.session_state.embedding_show_preview and st.session_state.embedding_preview_audio:
                            st.audio(st.session_state.embedding_preview_audio, format="audio/wav")

                        # === Part 4: ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š ===
                        st.subheader("4ï¸âƒ£ ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š")

                        embedding_filename = st.text_input(
                            "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ.npyæ‹¡å¼µå­ã¯è‡ªå‹•è¿½åŠ ï¼‰",
                            value="speaker_embedding",
                            key="video_combined_embedding_filename",
                            help="ä½œæˆã™ã‚‹è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
                        )

                        # === Part 5: ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ä½œæˆ ===
                        st.subheader("5ï¸âƒ£ åŸ‹ã‚è¾¼ã¿ä½œæˆ")

                        if st.button("âœ¨ è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="create_embedding_oneclick", type="primary"):
                            with st.spinner("è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆä¸­..."):
                                try:
                                    selected_indices = sorted(list(st.session_state.embedding_selected_rows))

                                    # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
                                    embedding, duration = extract_audio_segment_for_embedding(
                                        st.session_state.video_combined_audio_io,
                                        edited_df,
                                        selected_indices
                                    )

                                    # ãƒ•ã‚¡ã‚¤ãƒ«åå‡¦ç†
                                    filename_with_ext = embedding_filename if embedding_filename.endswith('.npy') else f"{embedding_filename}.npy"

                                    # åŸ‹ã‚è¾¼ã¿ã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›
                                    embedding_io = BytesIO()
                                    np.save(embedding_io, embedding)
                                    embedding_io.seek(0)

                                    embedding_bytes = embedding_io.getvalue()

                                    st.success(f"âœ… è©±è€…åŸ‹ã‚è¾¼ã¿ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆéŸ³å£°é•·: {duration:.1f}ç§’ï¼‰")
                                    trigger_auto_download(
                                        embedding_bytes,
                                        filename_with_ext,
                                        key="video_combined_download_embedding",
                                        mime="application/octet-stream"
                                    )

                                except Exception as e:
                                    st.error(f"âŒ è©±è€…åŸ‹ã‚è¾¼ã¿ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                                    import traceback
                                    with st.expander("ğŸ” è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                                        st.code(traceback.format_exc())

                    else:
                        if selection_mode == "ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰":
                            st.info("ğŸ’¡ ä¸Šè¨˜ã®selectboxã§é–‹å§‹è¡Œã¨çµ‚äº†è¡Œã‚’é¸æŠã—ã¦ãã ã•ã„")
                        else:
                            st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§åŸ‹ã‚è¾¼ã¿ä½œæˆå¯¾è±¡ã®è¡Œã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„")

        # Step 5: çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if st.session_state.video_combined_step >= 5 and not st.session_state.video_combined_identified_df.empty:
            st.subheader("Step 5: çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

            # è­°äº‹éŒ²å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆé€£ç¶šã™ã‚‹åŒã˜è©±è€…ã®ç™ºè¨€ã‚’çµåˆï¼‰
            df_for_transcript = st.session_state.video_combined_identified_df.copy()

            # è©±è€…åˆ—ã®å‰å‡¦ç†: ç©ºæ¬„ã‚’å‰å¾Œã®è©±è€…ã§åŸ‹ã‚ã‚‹
            df_for_transcript['speaker_filled'] = df_for_transcript['speaker'].replace('', pd.NA)
            df_for_transcript['speaker_filled'] = df_for_transcript['speaker_filled'].ffill()

            # è©±è€…ãŒå¤‰ã‚ã‚‹ã”ã¨ã«æ–°ã—ã„ã‚°ãƒ«ãƒ¼ãƒ—IDã‚’å‰²ã‚Šå½“ã¦ã‚‹
            df_for_transcript['group_id'] = (df_for_transcript['speaker_filled'] != df_for_transcript['speaker_filled'].shift()).cumsum()

            # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
            df_merged = df_for_transcript.groupby('group_id').agg(
                speaker=('speaker_filled', 'first'),
                text=('text', ' '.join)
            ).reset_index(drop=True)

            # è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            transcript_lines = []
            for idx, row in df_merged.iterrows():
                speaker = row.get('speaker', '')
                text = row.get('text', '')

                # Format: ï¼ˆè©±è€…ï¼‰ãƒ†ã‚­ã‚¹ãƒˆ
                speaker_str = speaker if speaker else 'ä¸æ˜'
                transcript_lines.append(f"ï¼ˆ{speaker_str}ï¼‰{text}")

            transcript_text = "\n".join(transcript_lines)

            # Wordæ–‡æ›¸ã¨ã—ã¦ç”Ÿæˆ
            doc = DocxDocument()
            doc.add_heading('è­°äº‹éŒ²', 0)

            for line in transcript_text.split('\n'):
                if line.strip():
                    doc.add_paragraph(line)
                else:
                    doc.add_paragraph('')  # ç©ºè¡Œã‚’ä¿æŒ

            docx_buffer = BytesIO()
            doc.save(docx_buffer)
            docx_buffer.seek(0)

            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label="è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=docx_buffer.getvalue(),
                    file_name=f"transcript_{st.session_state.video_combined_uploaded_file_name.split('.')[0]}.docx",
                    mime='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                    key="video_combined_download_transcript"
                )

            with col2:
                # Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ç”Ÿæˆ
                excel_buffer = BytesIO()
                with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                    st.session_state.video_combined_identified_df.to_excel(writer, index=False, sheet_name='æ–‡å­—èµ·ã“ã—')
                excel_buffer.seek(0)

                st.download_button(
                    label="Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=excel_buffer.getvalue(),
                    file_name=f"transcript_{st.session_state.video_combined_uploaded_file_name.split('.')[0]}.xlsx",
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    key="video_combined_download_excel"
                )

def main():
    st.set_page_config(
        page_title="æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒª",
        layout="wide",
        page_icon="ğŸ™ï¸",
        initial_sidebar_state="expanded"
    )

    # ã‚«ã‚¹ã‚¿ãƒ CSSã‚¹ã‚¿ã‚¤ãƒ«
    st.markdown("""
        <style>
        /* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒŠã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .main {
            background-color: #f8f9fa;
        }

        /* ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ã®èƒŒæ™¯ */
        .block-container {
            background: white;
            border-radius: 8px;
            padding: 2rem 3rem;
            margin-top: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.08);
        }

        /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        section[data-testid="stSidebar"] {
            background-color: #f8f9fa;
            border-right: 1px solid #e9ecef;
        }

        /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stButton > button {
            background-color: #4a5568;
            color: white;
            border: none;
            border-radius: 6px;
            padding: 0.5rem 1.5rem;
            font-weight: 500;
            font-size: 0.95rem;
            transition: background-color 0.2s ease;
        }

        .stButton > button:hover {
            background-color: #2d3748;
        }

        /* ãƒ—ãƒ©ã‚¤ãƒãƒªãƒœã‚¿ãƒ³ */
        .stButton > button[kind="primary"] {
            background-color: #3182ce;
        }

        .stButton > button[kind="primary"]:hover {
            background-color: #2c5282;
        }

        /* ã‚¿ã‚¤ãƒˆãƒ«ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        h1 {
            color: #1a202c;
            font-weight: 700;
            font-size: 2rem;
            padding: 0.5rem 0;
            margin-bottom: 1rem;
            border-bottom: 2px solid #e2e8f0;
        }

        /* ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        h2, h3 {
            color: #2d3748;
            font-weight: 600;
            margin-top: 1.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid #e2e8f0;
        }

        /* å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stTextInput > div > div > input,
        .stNumberInput > div > div > input,
        .stTextArea > div > div > textarea {
            border-radius: 6px;
            border: 1px solid #cbd5e0;
            padding: 0.5rem;
            transition: border-color 0.2s ease;
        }

        .stTextInput > div > div > input:focus,
        .stNumberInput > div > div > input:focus,
        .stTextArea > div > div > textarea:focus {
            border-color: #3182ce;
            box-shadow: 0 0 0 3px rgba(49, 130, 206, 0.1);
        }

        /* ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stSelectbox > div > div {
            border-radius: 6px;
            border: 1px solid #cbd5e0;
        }

        /* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stFileUploader {
            background-color: #f7fafc;
            border-radius: 8px;
            padding: 1.5rem;
            border: 2px dashed #cbd5e0;
        }

        /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stDataFrame {
            border-radius: 6px;
            overflow: hidden;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.08);
        }

        /* ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ */
        .stDownloadButton > button {
            background-color: #38a169;
            color: white;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.2s ease;
        }

        .stDownloadButton > button:hover {
            background-color: #2f855a;
        }

        /* ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ */
        .stProgress > div > div > div {
            background-color: #3182ce;
        }

        /* ã‚«ãƒ©ãƒ ã®é–“éš”èª¿æ•´ */
        [data-testid="column"] {
            padding: 0.5rem;
        }

        /* ã‚¨ã‚¯ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ */
        .streamlit-expanderHeader {
            background-color: #f7fafc;
            border-radius: 6px;
            font-weight: 500;
            color: #2d3748;
        }

        /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ */
        .stSlider > div > div > div {
            background-color: #3182ce;
        }

        /* ã‚¿ãƒ– */
        .stTabs [data-baseweb="tab-list"] {
            gap: 4px;
        }

        .stTabs [data-baseweb="tab"] {
            background-color: #f7fafc;
            border-radius: 6px 6px 0 0;
            padding: 8px 16px;
            font-weight: 500;
            color: #4a5568;
        }

        .stTabs [aria-selected="true"] {
            background-color: #3182ce;
            color: white;
        }
        </style>
    """, unsafe_allow_html=True)

    st.sidebar.title("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    menu_options = [
        "æ–‡å­—èµ·ã“ã—",
        "ğŸª„ dspyè­°äº‹éŒ²ãƒ¡ã‚¤ã‚«ãƒ¼",
        "ğŸš€ ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³",
        "å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—MP3ã§ä¿å­˜"
    ]
    choice = st.sidebar.selectbox("æ©Ÿèƒ½ã‚’é¸æŠã—ã¦ãã ã•ã„", menu_options)

    if choice == "æ–‡å­—èµ·ã“ã—":
        video_transcribe_and_identify()
    elif choice == "ğŸª„ dspyè­°äº‹éŒ²ãƒ¡ã‚¤ã‚«ãƒ¼":
        dspy_minutes_app()
    elif choice == "ğŸš€ ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³":
        batch_processing_pipeline()
    elif choice == "å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—MP3ã§ä¿å­˜":
        video_to_audio_cutter_app()

if __name__ == "__main__":
    main()
