# Azure OpenAI Configuration (for Azure provider)
AZURE_OPENAI_ENDPOINT=your_endpoint_here
AZURE_OPENAI_API_KEY=your_api_key_here

# LLM Provider Configuration
# Provider options: "azure" (default), "ollama"
LLM_PROVIDER=azure

# Ollama Configuration (for local on-premise inference)
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3.1
OLLAMA_API_KEY=ollama

# OSS Whisper Configuration
# Provider options: "azure" (default), "faster-whisper"
WHISPER_PROVIDER=faster-whisper

# OSS Whisper Model (only used when WHISPER_PROVIDER=faster-whisper)
# Options: tiny, base, small, medium, large-v2, large-v3
OSS_WHISPER_MODEL=base

# OSS Whisper Device (only used when WHISPER_PROVIDER=faster-whisper)
# Options: cpu, cuda (for GPU)
OSS_WHISPER_DEVICE=cpu
