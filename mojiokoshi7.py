import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import streamlit as st
from openai import AzureOpenAI
import tempfile
from io import BytesIO
from pydub import AudioSegment
import fitz
import torch
import pandas as pd
from dotenv import load_dotenv
from resemblyzer import VoiceEncoder, preprocess_wav
import numpy as np
import zipfile
from datetime import timedelta, datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import json
import base64
import uuid
import subprocess
from docx import Document as DocxDocument
from pptx import Presentation
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import AzureOpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from pathlib import Path
from streamlit.components.v1 import html as components_html

torch.classes.__path__ = []

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—ï¼ˆAzure OpenAI ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ»API ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰
AZURE_OPENAI_ENDPOINT = os.environ.get("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.environ.get("AZURE_OPENAI_API_KEY")
API_VERSION = "2025-03-01-preview"  # gpt-4o-transcribe ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³

# RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€è¨­å®š
DEFAULT_RAGDB_FOLDER = ""  # ç©ºæ–‡å­—åˆ—ã®å ´åˆã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
# ä¾‹: DEFAULT_RAGDB_FOLDER = "C:/Users/username/Documents/ragdb"
# ä¾‹: DEFAULT_RAGDB_FOLDER = "./data/ragdb"

PROMPTS_DATA = {
    "rag_proofreading": {
        "presets": {
            "standard": {
                "name": "æ¨™æº–æ ¡æ­£",
                "description": "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ¨™æº–çš„ãªæ ¡æ­£",
                "system_prompt_with_context": ("""
        ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£è³‡æ–™ã‚’å‚ç…§ã—ã¦ã€è­°äº‹éŒ²ã‚’æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚

        ã€å‚ç…§è³‡æ–™ã€‘
        {context}

        ã€æ ¡æ­£æŒ‡ç¤ºã€‘
        1. èª¤å­—è„±å­—ã®ä¿®æ­£
        2. æ–‡æ³•ã®æ”¹å–„
        3. å°‚é–€ç”¨èªã®æ­£ç¢ºæ€§ç¢ºèª
        4. æ–‡è„ˆã«åŸºã¥ãå†…å®¹ã®è£œå®Œ
        5. èª­ã¿ã‚„ã™ã•ã®å‘ä¸Š

        å‚ç…§è³‡æ–™ã‚’æ´»ç”¨ã—ãªãŒã‚‰ã€æ­£ç¢ºã§èª­ã¿ã‚„ã™ã„è­°äº‹éŒ²ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚
"""
               ),
                "system_prompt_without_context": (
                    "ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€æ ¡æ­£æŒ‡ç¤ºã€‘\n"
                    "1. èª¤å­—è„±å­—ã®ä¿®æ­£\n"
                    "2. æ–‡æ³•ã®æ”¹å–„\n"
                    "3. èª­ã¿ã‚„ã™ã•ã®å‘ä¸Š\n\n"
                    "æ­£ç¢ºã§èª­ã¿ã‚„ã™ã„è­°äº‹éŒ²ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚"
                ),
            },
            "detailed": {
                "name": "è©³ç´°æ ¡æ­£",
                "description": "ã‚ˆã‚Šè©³ç´°ãªåˆ†æã¨æ”¹å–„ææ¡ˆã‚’å«ã‚€æ ¡æ­£",
                "system_prompt_with_context": (
                    "ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£è³‡æ–™ã‚’å‚ç…§ã—ã¦ã€è­°äº‹éŒ²ã‚’è©³ç´°ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€å‚ç…§è³‡æ–™ã€‘\n"
                    "{context}\n\n"
                    "ã€è©³ç´°æ ¡æ­£æŒ‡ç¤ºã€‘\n"
                    "1. èª¤å­—è„±å­—ã®ä¿®æ­£ã¨è©³ç´°ãªèª¬æ˜\n"
                    "2. æ–‡æ³•ã®æ”¹å–„ã¨ä»£æ›¿è¡¨ç¾ã®ææ¡ˆ\n"
                    "3. å°‚é–€ç”¨èªã®æ­£ç¢ºæ€§ç¢ºèªã¨å®šç¾©ã®è£œè¶³\n"
                    "4. æ–‡è„ˆã«åŸºã¥ãå†…å®¹ã®è£œå®Œã¨èƒŒæ™¯æƒ…å ±ã®è¿½åŠ \n"
                    "5. èª­ã¿ã‚„ã™ã•ã®å‘ä¸Šã¨æ–‡ç« æ§‹é€ ã®æœ€é©åŒ–\n"
                    "6. æ›–æ˜§ãªè¡¨ç¾ã®æ˜ç¢ºåŒ–\n"
                    "7. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã®å¼·èª¿\n\n"
                    "å‚ç…§è³‡æ–™ã‚’ååˆ†ã«æ´»ç”¨ã—ã€ã‚ˆã‚Šè©³ç´°ã§åˆ†ã‹ã‚Šã‚„ã™ã„è­°äº‹éŒ²ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚\n"
                    "å¿…è¦ã«å¿œã˜ã¦ã€æ”¹å–„ç‚¹ã®èª¬æ˜ã‚‚å«ã‚ã¦ãã ã•ã„ã€‚"
                ),
                "system_prompt_without_context": (
                    "ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è­°äº‹éŒ²ã‚’è©³ç´°ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€è©³ç´°æ ¡æ­£æŒ‡ç¤ºã€‘\n"
                    "1. èª¤å­—è„±å­—ã®ä¿®æ­£ã¨è©³ç´°ãªèª¬æ˜\n"
                    "2. æ–‡æ³•ã®æ”¹å–„ã¨ä»£æ›¿è¡¨ç¾ã®ææ¡ˆ\n"
                    "3. èª­ã¿ã‚„ã™ã•ã®å‘ä¸Šã¨æ–‡ç« æ§‹é€ ã®æœ€é©åŒ–\n"
                    "4. æ›–æ˜§ãªè¡¨ç¾ã®æ˜ç¢ºåŒ–\n"
                    "5. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã®å¼·èª¿\n\n"
                    "ã‚ˆã‚Šè©³ç´°ã§åˆ†ã‹ã‚Šã‚„ã™ã„è­°äº‹éŒ²ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚"
                ),
            },
            "simple": {
                "name": "ç°¡æ½”æ ¡æ­£",
                "description": "å¿…è¦æœ€å°é™ã®ä¿®æ­£ã®ã¿ã‚’è¡Œã†ç°¡æ½”ãªæ ¡æ­£",
                "system_prompt_with_context": (
                    "ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£è³‡æ–™ã‚’å‚ç…§ã—ã¦ã€è­°äº‹éŒ²ã‚’ç°¡æ½”ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€å‚ç…§è³‡æ–™ã€‘\n"
                    "{context}\n\n"
                    "ã€ç°¡æ½”æ ¡æ­£æŒ‡ç¤ºã€‘\n"
                    "1. æ˜ã‚‰ã‹ãªèª¤å­—è„±å­—ã®ã¿ä¿®æ­£\n"
                    "2. é‡å¤§ãªæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã®ã¿ä¿®æ­£\n"
                    "3. å…ƒã®æ–‡ç« ã‚’ã§ãã‚‹ã ã‘ç¶­æŒ\n\n"
                    "å‚ç…§è³‡æ–™ã‚’æ´»ç”¨ã—ãªãŒã‚‰ã€æœ€å°é™ã®ä¿®æ­£ã§èª­ã¿ã‚„ã™ã„è­°äº‹éŒ²ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚"
                ),
                "system_prompt_without_context": (
                    "ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è­°äº‹éŒ²ã‚’ç°¡æ½”ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€ç°¡æ½”æ ¡æ­£æŒ‡ç¤ºã€‘\n"
                    "1. æ˜ã‚‰ã‹ãªèª¤å­—è„±å­—ã®ã¿ä¿®æ­£\n"
                    "2. é‡å¤§ãªæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã®ã¿ä¿®æ­£\n"
                    "3. å…ƒã®æ–‡ç« ã‚’ã§ãã‚‹ã ã‘ç¶­æŒ\n\n"
                    "æœ€å°é™ã®ä¿®æ­£ã§èª­ã¿ã‚„ã™ã„è­°äº‹éŒ²ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚"
                ),
            },
            "formal": {
                "name": "ãƒ•ã‚©ãƒ¼ãƒãƒ«æ ¡æ­£",
                "description": "ã‚ˆã‚Šãƒ•ã‚©ãƒ¼ãƒãƒ«ã§ä¸å¯§ãªè¡¨ç¾ã«æ ¡æ­£",
                "system_prompt_with_context": (
                    "ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£è³‡æ–™ã‚’å‚ç…§ã—ã¦ã€è­°äº‹éŒ²ã‚’ã‚ˆã‚Šãƒ•ã‚©ãƒ¼ãƒãƒ«ãªè¡¨ç¾ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€å‚ç…§è³‡æ–™ã€‘\n"
                    "{context}\n\n"
                    "ã€ãƒ•ã‚©ãƒ¼ãƒãƒ«æ ¡æ­£æŒ‡ç¤ºã€‘\n"
                    "1. èª¤å­—è„±å­—ã®ä¿®æ­£\n"
                    "2. æ–‡æ³•ã®æ”¹å–„\n"
                    "3. ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªè¡¨ç¾ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒ«ãªè¡¨ç¾ã«å¤‰æ›\n"
                    "4. æ•¬èªè¡¨ç¾ã®çµ±ä¸€ã¨é©åˆ‡ãªä½¿ç”¨\n"
                    "5. ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã¨ã—ã¦é©åˆ‡ãªèªå½™ã®ä½¿ç”¨\n"
                    "6. å°‚é–€ç”¨èªã®æ­£ç¢ºæ€§ç¢ºèª\n\n"
                    "å‚ç…§è³‡æ–™ã‚’æ´»ç”¨ã—ãªãŒã‚‰ã€ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§ä¸å¯§ãªå°è±¡ã®è­°äº‹éŒ²ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚"
                ),
                "system_prompt_without_context": (
                    "ã‚ãªãŸã¯è­°äº‹éŒ²æ ¡æ­£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è­°äº‹éŒ²ã‚’ã‚ˆã‚Šãƒ•ã‚©ãƒ¼ãƒãƒ«ãªè¡¨ç¾ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€ãƒ•ã‚©ãƒ¼ãƒãƒ«æ ¡æ­£æŒ‡ç¤ºã€‘\n"
                    "1. èª¤å­—è„±å­—ã®ä¿®æ­£\n"
                    "2. æ–‡æ³•ã®æ”¹å–„\n"
                    "3. ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªè¡¨ç¾ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒ«ãªè¡¨ç¾ã«å¤‰æ›\n"
                    "4. æ•¬èªè¡¨ç¾ã®çµ±ä¸€ã¨é©åˆ‡ãªä½¿ç”¨\n"
                    "5. ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã¨ã—ã¦é©åˆ‡ãªèªå½™ã®ä½¿ç”¨\n\n"
                    "ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§ä¸å¯§ãªå°è±¡ã®è­°äº‹éŒ²ã«æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚"
                ),
            },
        },
    },
    "legacy": {
        "initial_transcription_prompt": (
            "\"ã“ã‚“ã«ã¡ã¯ã€‚\\n\\nã¯ã„ã€ã“ã‚“ã«ã¡ã¯ã€‚\\n\\nãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ\\n\\nã¯ã„ã€å…ƒæ°—ã§ã™ã€‚\\n\\nãã‚Œã¯ä½•ã‚ˆã‚Šã§ã™ã€‚ã§ã¯æ—©é€Ÿå§‹ã‚ã¾ã—ã‚‡ã†ã€‚\\n\\nã¯ã„ã€ã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚\""
        ),
        "summarizing_prompt1": (
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸¡ã•ã‚Œã¾ã™ã€‚å½“è©²ã®ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‚’èª­ã‚“ã ä¸Šã§ã€150æ–‡å­—ç¨‹åº¦ã®è¦ç´„ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        ),
    },
}

DEFAULT_MEETING_TYPES = [
    {
        "name": "çµŒå–¶ä¼šè­°",
        "id": "executive_meeting",
        "embeddings_folder": "speaker_embeddings/executive",
        "description": "æœˆä¾‹çµŒå–¶ä¼šè­°ï¼ˆå½¹å“¡ãƒ¡ãƒ³ãƒãƒ¼å›ºå®šï¼‰",
    },
    {
        "name": "é–‹ç™ºãƒãƒ¼ãƒ å®šä¾‹",
        "id": "dev_team_meeting",
        "embeddings_folder": "speaker_embeddings/dev_team",
        "description": "é€±æ¬¡é–‹ç™ºãƒãƒ¼ãƒ ä¼šè­°",
    },
    {
        "name": "å–¶æ¥­å®šä¾‹",
        "id": "sales_meeting",
        "embeddings_folder": "speaker_embeddings/sales",
        "description": "æœˆæ¬¡å–¶æ¥­ä¼šè­°",
    },
    {
        "name": "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆæ‰‹å‹•é¸æŠï¼‰",
        "id": "custom",
        "embeddings_folder": "",
        "description": "ä¼šè­°ã‚¿ã‚¤ãƒ—ã‚’æŒ‡å®šã›ãšã€æ‰‹å‹•ã§è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’é¸æŠ",
    },
]


class _InlinePromptLoader:
    def __init__(self, data: dict):
        self._cache = data

    def get_prompt(self, *keys: str) -> str:
        data = self._cache
        for key in keys:
            if not isinstance(data, dict) or key not in data:
                raise KeyError(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {' -> '.join(keys)}")
            data = data[key]
        if not isinstance(data, str):
            raise ValueError(f"æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ‘ã‚¹ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {' -> '.join(keys)}")
        return data

    def get_all_prompts(self) -> dict:
        return json.loads(json.dumps(self._cache))

    def get_presets(self, category: str) -> dict:
        category_data = self._cache.get(category, {})
        return category_data.get("presets", {}) if isinstance(category_data, dict) else {}

    def get_preset_list(self, category: str) -> list:
        presets = self.get_presets(category)
        return [
            {
                "id": preset_id,
                "name": preset_data.get("name", preset_id),
                "description": preset_data.get("description", ""),
            }
            for preset_id, preset_data in presets.items()
        ]

    def get_prompt_from_preset(self, category: str, preset_id: str, prompt_type: str) -> str:
        presets = self.get_presets(category)
        if preset_id not in presets:
            raise KeyError(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {category} -> {preset_id}")
        preset_data = presets[preset_id]
        if prompt_type not in preset_data:
            raise KeyError(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {category} -> {preset_id} -> {prompt_type}")
        value = preset_data[prompt_type]
        if not isinstance(value, str):
            raise ValueError(f"æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒªã‚»ãƒƒãƒˆå€¤ã¯æ–‡å­—åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {category} -> {preset_id} -> {prompt_type}")
        return value


_DEFAULT_PROMPT_LOADER: _InlinePromptLoader | None = None


def get_default_loader() -> _InlinePromptLoader:
    global _DEFAULT_PROMPT_LOADER
    if _DEFAULT_PROMPT_LOADER is None:
        _DEFAULT_PROMPT_LOADER = _InlinePromptLoader(PROMPTS_DATA)
    return _DEFAULT_PROMPT_LOADER


def get_prompt(*keys: str) -> str:
    return get_default_loader().get_prompt(*keys)

def _extract_pdf(file: BytesIO) -> str:
    file_bytes = file.read()
    file.seek(0)
    pdf_document = fitz.open(stream=file_bytes, filetype='pdf')
    text = "".join(page.get_text() for page in pdf_document)
    pdf_document.close()
    return text

def _extract_docx(file: BytesIO) -> str:
    doc = DocxDocument(file)
    text = "\n".join(p.text for p in doc.paragraphs)
    for table in doc.tables:
        text += "\n" + "\n".join(" ".join(cell.text for cell in row.cells) for row in table.rows)
    return text.strip()

def _extract_pptx(file: BytesIO) -> str:
    presentation = Presentation(file)
    text_parts = []
    for slide_num, slide in enumerate(presentation.slides, 1):
        text_parts.append(f"\n--- ã‚¹ãƒ©ã‚¤ãƒ‰ {slide_num} ---\n")
        for shape in slide.shapes:
            if hasattr(shape, "text") and shape.text:
                text_parts.append(shape.text + "\n")
            if shape.has_table:
                for row in shape.table.rows:
                    text_parts.append(" ".join(cell.text for cell in row.cells) + "\n")
    return "".join(text_parts).strip()

def _extract_msg(file: BytesIO) -> str:
    try:
        import extract_msg
    except ImportError:
        raise Exception("MSGãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«ã¯ extract-msg ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚pip install extract-msg ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".msg") as temp_file:
        temp_file.write(file.read())
        temp_path = temp_file.name

    try:
        msg = extract_msg.Message(temp_path)
        parts = []
        if msg.subject:
            parts.append(f"ä»¶å: {msg.subject}\n")
        if msg.sender:
            parts.append(f"é€ä¿¡è€…: {msg.sender}\n")
        if msg.to:
            parts.append(f"å®›å…ˆ: {msg.to}\n")
        if msg.body:
            parts.append(f"\n{msg.body}")
        msg.close()
        return "\n".join(parts).strip()
    finally:
        if os.path.exists(temp_path):
            os.unlink(temp_path)

def _extract_txt(file: BytesIO) -> str:
    file_content = file.read()
    for encoding in ['utf-8', 'cp932', 'shift_jis', 'utf-16', 'iso-2022-jp']:
        try:
            return file_content.decode(encoding).strip()
        except UnicodeDecodeError:
            continue
    raise Exception("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸ")

FILE_EXTRACTORS = {
    'pdf': _extract_pdf,
    'docx': _extract_docx,
    'pptx': _extract_pptx,
    'txt': _extract_txt,
    'msg': _extract_msg,
}

def extract_text_from_file(file, file_extension):
    """ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    extractor = FILE_EXTRACTORS.get(file_extension.lower())
    if not extractor:
        raise Exception(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file_extension}")
    try:
        return extractor(file)
    except Exception as e:
        raise Exception(f"{file_extension.upper()}èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def _create_azure_client():
    """Azure OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    return AzureOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=API_VERSION,
    )

def generate_summary(model, prompt, text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„"""
    client = _create_azure_client()
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": text},
        ],
    )
    print(f"Response: {response}")
    return response.choices[0].message.content

from contextlib import contextmanager

@contextmanager
def temp_file_path(data: bytes, suffix: str):
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ãƒ‘ã‚¹ã‚’è¿”ã™ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(data)
        tmp_path = tmp.name
    try:
        yield tmp_path
    finally:
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)


def trigger_auto_download(data: bytes, file_name: str, key: str | None, mime: str = "application/octet-stream"):
    """Streamlitã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ã£ã¦å³æ™‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹"""
    if not data:
        return

    encoded = base64.b64encode(data).decode()
    mime_js = json.dumps(mime)
    file_name_js = json.dumps(file_name)
    element_id_js = json.dumps(key or f"dl_{uuid.uuid4().hex}")

    components_html(
        f"""
        <div id={element_id_js}></div>
        <script>
            (function() {{
                const mimeType = {mime_js};
                const fileName = {file_name_js};
                const link = document.createElement('a');
                link.href = "data:" + mimeType + ";base64,{encoded}";
                link.download = fileName;
                link.style.display = 'none';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                const element = document.getElementById({element_id_js});
                if (element) {{
                    element.remove();
                }}
            }})();
        </script>
        """,
        height=0,
    )


def transcribe_audio_to_dataframe(uploaded_file: BytesIO, reference_file: BytesIO = None, model: str = "gpt-4o-transcribe-diarize"):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆãƒ¢ãƒ‡ãƒ«é¸æŠå¯èƒ½ã€25MBåˆ¶é™å¯¾å¿œï¼‰

    Args:
        uploaded_file: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        reference_file: å‚è€ƒè³‡æ–™ï¼ˆWhisperã®ã¿ã‚µãƒãƒ¼ãƒˆï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("gpt-4o-transcribe-diarize" ã¾ãŸã¯ "whisper")
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ25MB = 26,214,400 bytesï¼‰
    MAX_FILE_SIZE = 25 * 1024 * 1024
    uploaded_file.seek(0)
    file_size = len(uploaded_file.getvalue())
    uploaded_file.seek(0)

    # 25MBä»¥ä¸Šã®å ´åˆã¯åˆ†å‰²å‡¦ç†
    if file_size > MAX_FILE_SIZE:
        st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ {file_size / (1024*1024):.1f}MB ã§ã™ã€‚25MBåˆ¶é™ã®ãŸã‚ã€éŸ³å£°ã‚’åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")
        return _transcribe_large_audio_chunked(uploaded_file, reference_file, model)

    # 25MBæœªæº€ã®å ´åˆã¯é€šå¸¸å‡¦ç†
    return _transcribe_audio_single(uploaded_file, reference_file, model)

def _transcribe_large_audio_chunked(uploaded_file: BytesIO, reference_file: BytesIO = None, model: str = "gpt-4o-transcribe-diarize"):
    """å¤§ããªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦æ–‡å­—èµ·ã“ã—

    Args:
        uploaded_file: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        reference_file: å‚è€ƒè³‡æ–™
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«

    Returns:
        pd.DataFrame: æ–‡å­—èµ·ã“ã—çµæœ
    """
    try:
        suffix = f".{uploaded_file.name.split('.')[-1]}"

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        with temp_file_path(uploaded_file.getvalue(), suffix) as tmp_path:
            audio = AudioSegment.from_file(tmp_path)

        # éŸ³å£°ã®é•·ã•ï¼ˆãƒŸãƒªç§’ï¼‰
        total_duration_ms = len(audio)
        total_duration_sec = total_duration_ms / 1000

        # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’æ±ºå®šï¼ˆ10åˆ† = 600ç§’ = 600,000ãƒŸãƒªç§’ï¼‰
        CHUNK_DURATION_MS = 10 * 60 * 1000  # 10åˆ†

        # ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¨ˆç®—
        num_chunks = (total_duration_ms + CHUNK_DURATION_MS - 1) // CHUNK_DURATION_MS

        st.info(f"ğŸ“Š éŸ³å£°é•·: {total_duration_sec/60:.1f}åˆ†ã€{num_chunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™")

        # é€²æ—è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()

        all_segments = []

        for i in range(num_chunks):
            start_ms = i * CHUNK_DURATION_MS
            end_ms = min((i + 1) * CHUNK_DURATION_MS, total_duration_ms)

            status_text.write(f"ğŸ¤ ãƒãƒ£ãƒ³ã‚¯ {i+1}/{num_chunks} ã‚’å‡¦ç†ä¸­... ({start_ms/1000:.1f}ç§’ ï½ {end_ms/1000:.1f}ç§’)")

            # ãƒãƒ£ãƒ³ã‚¯ã‚’æŠ½å‡º
            chunk = audio[start_ms:end_ms]

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            chunk_io = BytesIO()
            chunk.export(chunk_io, format="mp3", bitrate="192k")
            chunk_io.seek(0)
            chunk_io.name = f"chunk_{i}.mp3"

            # ãƒãƒ£ãƒ³ã‚¯ã‚’æ–‡å­—èµ·ã“ã—
            try:
                chunk_df = _transcribe_audio_single(chunk_io, reference_file, model)

                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´
                if not chunk_df.empty and 'start' in chunk_df.columns and 'end' in chunk_df.columns:
                    offset_sec = start_ms / 1000
                    chunk_df['start'] = chunk_df['start'] + offset_sec
                    chunk_df['end'] = chunk_df['end'] + offset_sec

                all_segments.append(chunk_df)

            except Exception as e:
                st.error(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

            progress_bar.progress((i + 1) / num_chunks)

        # ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
        if all_segments:
            result_df = pd.concat(all_segments, ignore_index=True)
            status_text.write(f"âœ… åˆ†å‰²å‡¦ç†å®Œäº†ï¼åˆè¨ˆ {len(result_df)} å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
            return result_df
        else:
            st.error("âŒ ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pd.DataFrame(columns=["start", "end", "speaker", "text"])

    except Exception as e:
        st.error(f"âŒ åˆ†å‰²å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        st.error(traceback.format_exc())
        return pd.DataFrame(columns=["start", "end", "speaker", "text"])

def _transcribe_audio_single(uploaded_file: BytesIO, reference_file: BytesIO = None, model: str = "gpt-4o-transcribe-diarize"):
    """å˜ä¸€ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆå†…éƒ¨ç”¨ï¼‰

    Args:
        uploaded_file: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        reference_file: å‚è€ƒè³‡æ–™ï¼ˆWhisperã®ã¿ã‚µãƒãƒ¼ãƒˆï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("gpt-4o-transcribe-diarize" ã¾ãŸã¯ "whisper")
    """
    # ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ãŸAPIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’é¸æŠ
    if model == "whisper":
        api_version = "2024-06-01"  # Whisperç”¨ã®å®‰å®šç‰ˆAPIãƒãƒ¼ã‚¸ãƒ§ãƒ³
        st.info(f"ğŸ”§ Whisperãƒ¢ãƒ‡ãƒ«ç”¨ã«APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ {api_version} ã‚’ä½¿ç”¨ã—ã¾ã™")
    else:
        api_version = "2025-03-01-preview"  # gpt-4o-transcribe-diarizeç”¨

    # ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    client = AzureOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=api_version,
    )

    try:
        suffix = f".{uploaded_file.name.split('.')[-1]}"

        if model == "gpt-4o-transcribe-diarize":
            # gpt-4o-transcribe-diarizeãƒ¢ãƒ‡ãƒ«ï¼ˆè©±è€…è­˜åˆ¥ä»˜ãï¼‰
            if reference_file:
                st.warning("âš ï¸ gpt-4o-transcribe-diarizeãƒ¢ãƒ‡ãƒ«ã¯å‚è€ƒè³‡æ–™ï¼ˆpromptï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚å‚è€ƒè³‡æ–™ã¯ç„¡è¦–ã•ã‚Œã¾ã™ã€‚")

            st.info("æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆgpt-4o-transcribe-diarizeã€è©±è€…è­˜åˆ¥ä»˜ãï¼‰...")

            with temp_file_path(uploaded_file.getvalue(), suffix) as tmp_path:
                with open(tmp_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="gpt-4o-transcribe-diarize",
                        file=(uploaded_file.name, audio_file, f"audio/{uploaded_file.name.split('.')[-1]}"),
                        response_format="diarized_json",
                        chunking_strategy="auto"
                    )

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            transcript_dict = transcript.model_dump()
            segments = transcript_dict.get("segments", [])

            if segments:
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                seg_list = []
                for seg in segments:
                    seg_list.append({
                        "start": seg.get("start", 0),
                        "end": seg.get("end", 0),
                        "speaker": seg.get("speaker", ""),
                        "text": seg.get("text", "")
                    })

                st.success(f"æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆ{len(seg_list)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã€è©±è€…è­˜åˆ¥ä»˜ãï¼‰")
                seg_df = pd.DataFrame(seg_list)
                return seg_df
            else:
                # segmentsãŒãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’å–å¾—
                text = transcript_dict.get("text", "")
                if text:
                    st.warning("âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")
                    seg_df = pd.DataFrame([{
                        "start": 0,
                        "end": 0,
                        "speaker": "",
                        "text": text
                    }])
                    return seg_df
                else:
                    st.error("âŒ æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸ")
                    return pd.DataFrame(columns=["start", "end", "speaker", "text"])

        elif model == "whisper":
            # Whisperãƒ¢ãƒ‡ãƒ«ï¼ˆè©±è€…è­˜åˆ¥ãªã—ï¼‰
            st.info("æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆWhisperã€è©±è€…è­˜åˆ¥ãªã—ï¼‰...")

            with temp_file_path(uploaded_file.getvalue(), suffix) as tmp_path:
                with open(tmp_path, "rb") as audio_file:
                    # promptãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æº–å‚™
                    kwargs = {
                        "model": "whisper",
                        "file": (uploaded_file.name, audio_file, f"audio/{uploaded_file.name.split('.')[-1]}"),
                        "response_format": "verbose_json"
                    }

                    # å‚è€ƒè³‡æ–™ãŒã‚ã‚‹å ´åˆã¯promptã¨ã—ã¦ä½¿ç”¨
                    if reference_file:
                        try:
                            file_extension = reference_file.name.split(".")[-1].lower()
                            reference_text = extract_text_from_file(BytesIO(reference_file.read()), file_extension)
                            if reference_text:
                                # promptã¯æœ€å¤§224ãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ã«åˆ¶é™ï¼ˆç´„1000æ–‡å­—ï¼‰
                                kwargs["prompt"] = reference_text[:1000]
                                st.info("âœ… å‚è€ƒè³‡æ–™ã‚’promptã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™")
                        except Exception as e:
                            st.warning(f"âš ï¸ å‚è€ƒè³‡æ–™ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

                    transcript = client.audio.transcriptions.create(**kwargs)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            transcript_dict = transcript.model_dump()
            segments = transcript_dict.get("segments", [])

            if segments:
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ï¼ˆè©±è€…æƒ…å ±ã¯ç©ºï¼‰
                seg_list = []
                for seg in segments:
                    seg_list.append({
                        "start": seg.get("start", 0),
                        "end": seg.get("end", 0),
                        "speaker": "",  # Whisperã¯è©±è€…è­˜åˆ¥ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„
                        "text": seg.get("text", "")
                    })

                st.success(f"æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆ{len(seg_list)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã€Whisperä½¿ç”¨ï¼‰")
                seg_df = pd.DataFrame(seg_list)
                return seg_df
            else:
                # segmentsãŒãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’å–å¾—
                text = transcript_dict.get("text", "")
                if text:
                    st.warning("âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")
                    seg_df = pd.DataFrame([{
                        "start": 0,
                        "end": 0,
                        "speaker": "",
                        "text": text
                    }])
                    return seg_df
                else:
                    st.error("âŒ æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸ")
                    return pd.DataFrame(columns=["start", "end", "speaker", "text"])
        else:
            st.error(f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«: {model}")
            return pd.DataFrame(columns=["start", "end", "speaker", "text"])

    except Exception as e:
        st.error(f"âŒ æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        st.error(f"**ã‚¨ãƒ©ãƒ¼è©³ç´°**: {str(e)}")
        st.error(f"**ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: {model}")
        st.error(f"**APIãƒãƒ¼ã‚¸ãƒ§ãƒ³**: {api_version}")

        import traceback
        error_details = traceback.format_exc()

        with st.expander("ğŸ” è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"):
            st.code(error_details, language="python")

        # ã‚¨ãƒ©ãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        print(f"===== Transcription Error =====")
        print(f"Model: {model}")
        print(f"API Version: {api_version}")
        print(f"Error: {e}")
        print(error_details)
        print(f"==============================")

        return pd.DataFrame(columns=["start", "end", "speaker", "text"])

@st.cache_resource
def load_voice_encoder():
    """Caches the VoiceEncoder model."""
    return VoiceEncoder()

def extract_embedding(audio_content):
    """Extracts embedding from audio content."""
    with temp_file_path(audio_content.read(), ".wav") as wav_path:
        wav = preprocess_wav(wav_path)
        encoder = load_voice_encoder()
        return encoder.embed_utterance(wav)

def load_speaker_embeddings_from_files(uploaded_files):
    """Loads known speaker embeddings from uploaded files.

    Args:
        uploaded_files: ãƒªã‚¹ãƒˆã¾ãŸã¯ã‚¿ãƒ—ãƒ«ã€‚å„è¦ç´ ã¯ä»¥ä¸‹ã®ã„ãšã‚Œã‹ï¼š
            - Streamlit UploadedFile ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆfile_uploaderã‹ã‚‰ï¼‰
            - è¾æ›¸ {'name': filename, 'data': file_bytes}ï¼ˆãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å ´åˆï¼‰

    Returns:
        dict: {speaker_name: embedding_array}
    """
    if not uploaded_files:
        st.warning("è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return {}

    speaker_embeddings = {}
    for uploaded_file in uploaded_files:
        try:
            # è¾æ›¸å½¢å¼ï¼ˆãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å ´åˆï¼‰ã‹UploadedFileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚’åˆ¤å®š
            if isinstance(uploaded_file, dict):
                # è¾æ›¸å½¢å¼: {'name': filename, 'data': file_bytes}
                filename = uploaded_file['name']
                file_data = BytesIO(uploaded_file['data'])
            else:
                # UploadedFile ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
                filename = uploaded_file.name
                file_data = uploaded_file

            filename_stem = Path(filename).stem
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®åŒºåˆ‡ã‚Šæ–‡å­—ã§è©±è€…åã‚’æŠ½å‡º
            for delimiter in ['â€—', '_']:
                if delimiter in filename_stem:
                    filename_stem = filename_stem.split(delimiter)[0]
                    break
            speaker_name = filename_stem.strip()

            if not speaker_name:
                speaker_name = Path(filename).stem

            speaker_embeddings[speaker_name] = np.load(file_data)
        except Exception as e:
            filename_str = uploaded_file.get('name') if isinstance(uploaded_file, dict) else getattr(uploaded_file, 'name', 'unknown')
            st.error(f"åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ {filename_str}: {e}")
    return speaker_embeddings

def _calculate_similarity(embedding1, embedding2):
    """2ã¤ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))

def _identify_speaker(segment_embedding, known_embeddings, threshold):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŸ‹ã‚è¾¼ã¿ã‹ã‚‰è©±è€…ã‚’è­˜åˆ¥"""
    best_speaker, best_similarity = None, -1
    for speaker_name, known_embedding in known_embeddings.items():
        similarity = _calculate_similarity(segment_embedding, known_embedding)
        print(f"Comparing segment with {speaker_name}: similarity = {similarity:.4f}")
        if similarity > best_similarity:
            best_similarity, best_speaker = similarity, speaker_name
    return best_speaker if best_similarity >= threshold else ""

def identify_speakers_in_dataframe(audio_file, df: pd.DataFrame, uploaded_embedding_files, similarity_threshold: float) -> pd.DataFrame:
    known_embeddings = load_speaker_embeddings_from_files(uploaded_embedding_files)
    if not known_embeddings:
        st.warning("æ—¢çŸ¥ã®è©±è€…åŸ‹ã‚è¾¼ã¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è­˜åˆ¥ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
        df['speaker'] = None
        return df

    st.info(f"Loaded embeddings for speakers: {list(known_embeddings.keys())}")

    with temp_file_path(audio_file.getvalue(), ".wav") as audio_path:
        try:
            audio = AudioSegment.from_file(audio_path)
            df['speaker'] = None
            encoder = load_voice_encoder()
            progress_bar, status_text = st.progress(0), st.empty()

            for index, row in df.iterrows():
                segment = audio[row['start'] * 1000:row['end'] * 1000]

                with temp_file_path(segment.export(format="wav").read(), ".wav") as segment_path:
                    try:
                        wav = preprocess_wav(segment_path)
                        segment_embedding = encoder.embed_utterance(wav)
                        speaker = _identify_speaker(segment_embedding, known_embeddings, similarity_threshold)
                        df.at[index, 'speaker'] = speaker
                        status = f"Identified as {speaker}" if speaker else "Similarity below threshold"
                        status_text.text(f"Processed segment {index + 1}/{len(df)}: {status}")
                    except Exception as e:
                        st.error(f"Error processing segment {row['start']}-{row['end']}s: {e}")
                        df.at[index, 'speaker'] = "Error"

                progress_bar.progress((index + 1) / len(df))

            status_text.text("Speaker identification complete.")
            return df

        except Exception as e:
            st.error(f"Error loading or processing audio file: {e}")
            return df

def build_meeting_text_from_dataframe(df: pd.DataFrame) -> str:
    """Generate combined meeting text in (speaker) utterance format from transcription data."""
    if df is None or df.empty or 'text' not in df.columns:
        return ""

    if 'speaker' in df.columns:
        df_copy = df.copy()
        df_copy['speaker_filled'] = df_copy['speaker'].replace('', pd.NA)
        df_copy['speaker_filled'] = df_copy['speaker_filled'].ffill()
        df_copy['group_id'] = (df_copy['speaker_filled'] != df_copy['speaker_filled'].shift()).cumsum()
        df_merged = df_copy.groupby('group_id').agg(
            speaker=('speaker_filled', 'first'),
            text=('text', lambda values: ' '.join(map(str, values)))
        ).reset_index(drop=True)

        lines = []
        for _, row in df_merged.iterrows():
            speaker = row.get('speaker')
            text = row.get('text', '')
            speaker_str = speaker if isinstance(speaker, str) and speaker else 'ä¸æ˜'
            lines.append(f"ï¼ˆ{speaker_str}ï¼‰{text}")
        return "\n".join(lines)

    # speakeråˆ—ãŒãªã„å ´åˆã¯ä¸æ˜è©±è€…ã¨ã—ã¦æ‰±ã†
    lines = []
    for text in df['text'].astype(str):
        lines.append(f"ï¼ˆä¸æ˜ï¼‰{text}")
    return "\n".join(lines)

def format_time(seconds):
    """Formats seconds into HH:MM:SS."""
    td = timedelta(seconds=seconds)
    hours, remainder = divmod(td.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{hours:02}:{minutes:02}:{seconds:02}"

def parse_time_to_seconds(time_str):
    """Converts HH:MM:SS or seconds string to total seconds."""
    if ':' in time_str:
        parts = list(map(int, time_str.split(':')))
        if len(parts) == 3:
            return parts[0] * 3600 + parts[1] * 60 + parts[2]
        elif len(parts) == 2:
            return parts[0] * 60 + parts[1]
        else:
            raise ValueError("Invalid time format. Use HH:MM:SS or MM:SS.")
    else:
        return int(time_str)

def split_text_by_lines(text, n_parts):
    """æ–‡å­—åˆ—ã‚’æ”¹è¡Œä½ç½®ã§é©åˆ‡ã«nåˆ†å‰²"""
    if n_parts <= 0:
        raise ValueError("åˆ†å‰²æ•°ã¯1ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
    if n_parts == 1:
        return [text]

    lines = text.split('\n')
    total_lines = len(lines)

    if total_lines <= n_parts:
        return lines + [""] * (n_parts - total_lines)

    lines_per_part = total_lines // n_parts
    remainder = total_lines % n_parts

    result, start = [], 0
    for i in range(n_parts):
        count = lines_per_part + (1 if i < remainder else 0)
        result.append('\n'.join(lines[start:start + count]))
        start += count

    return result

class RAGProofreadingSystem:
    """LangChainãƒ™ãƒ¼ã‚¹ã®RAGæ ¡æ­£ã‚·ã‚¹ãƒ†ãƒ """

    # å®šæ•°å®šç¾©
    DEFAULT_CHUNK_SIZE = 500
    DEFAULT_CHUNK_OVERLAP = 100
    DEFAULT_TOP_K = 6
    DEFAULT_TEMPERATURE = 0.3
    EMBEDDING_MODEL = "text-embedding-3-large"

    def __init__(self, azure_endpoint, azure_api_key, api_version):
        self.azure_endpoint = azure_endpoint
        self.azure_api_key = azure_api_key
        self.api_version = api_version
        self.client = AzureOpenAI(
            azure_endpoint=azure_endpoint,
            api_key=azure_api_key,
            api_version=api_version
        )

        # LangChain embedding åˆæœŸåŒ–
        self.embeddings = AzureOpenAIEmbeddings(
            azure_deployment=self.EMBEDDING_MODEL,
            openai_api_version=api_version,
            azure_endpoint=azure_endpoint,
            api_key=azure_api_key
        )

        self.vectorstore = None
        self.documents = []
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.DEFAULT_CHUNK_SIZE,
            chunk_overlap=self.DEFAULT_CHUNK_OVERLAP,
            length_function=len,
        )

    def create_knowledge_base(self, documents_text_list, mode="add", documents_metadata=None):
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ï¼ˆLangChainä½¿ç”¨ï¼‰

        Args:
            documents_text_list: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
            mode: "new" (æ–°è¦ä½œæˆ) ã¾ãŸã¯ "add" (è¿½åŠ æ§‹ç¯‰)
            documents_metadata: å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸ã®ãƒªã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’LangChain Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            langchain_docs = []
            for i, text in enumerate(documents_text_list):
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
                if documents_metadata and i < len(documents_metadata):
                    # ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                    metadata = documents_metadata[i].copy()
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                    metadata = {"source": f"document_{i+1}"}

                doc = Document(
                    page_content=text,
                    metadata=metadata
                )
                langchain_docs.append(doc)

            # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
            split_docs = self.text_splitter.split_documents(langchain_docs)

            # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å‡¦ç†
            if mode == "new" or self.vectorstore is None:
                # æ–°è¦ä½œæˆï¼ˆã¾ãŸã¯æ—¢å­˜ãŒãªã„å ´åˆï¼‰
                self.vectorstore = FAISS.from_documents(split_docs, self.embeddings)
                self.documents = documents_text_list
            else:
                # è¿½åŠ æ§‹ç¯‰
                self.vectorstore.add_documents(split_docs)
                self.documents.extend(documents_text_list)

            return True
        except Exception as e:
            st.error(f"ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def retrieve_relevant_context(self, query, search_type="similarity", top_k=None):
        """é–¢é€£æ–‡è„ˆã‚’æ¤œç´¢ï¼ˆLangChainä½¿ç”¨ï¼‰"""
        if not self.vectorstore:
            return ""

        if top_k is None:
            top_k = self.DEFAULT_TOP_K

        try:
            if search_type == "similarity":
                # é¡ä¼¼åº¦æ¤œç´¢
                docs = self.vectorstore.similarity_search(query, k=top_k)
            elif search_type == "mmr":
                # MMRæ¤œç´¢ï¼ˆå¤šæ§˜æ€§ã‚’è€ƒæ…®ï¼‰
                docs = self.vectorstore.max_marginal_relevance_search(query, k=top_k)
            else:
                docs = self.vectorstore.similarity_search(query, k=top_k)

            # æ¤œç´¢çµæœã‚’çµåˆ
            context = "\n\n".join([doc.page_content for doc in docs])
            return context
        except Exception as e:
            st.error(f"æ–‡è„ˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    def rag_enhanced_proofread(self, text, model="gpt-4o", search_type="similarity", top_k=None, prompt_preset="standard"):
        """
        RAGæ‹¡å¼µæ ¡æ­£ï¼ˆLangChainä½¿ç”¨ï¼‰

        Args:
            text: æ ¡æ­£å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
            model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
            search_type: æ¤œç´¢ã‚¿ã‚¤ãƒ—
            top_k: æ¤œç´¢çµæœã®ä¸Šä½Kä»¶
            prompt_preset: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆIDï¼ˆä¾‹: 'standard', 'detailed', 'simple', 'formal'ï¼‰
        """
        try:
            if top_k is None:
                top_k = self.DEFAULT_TOP_K

            # é–¢é€£æ–‡è„ˆã‚’æ¤œç´¢
            relevant_context = self.retrieve_relevant_context(text, search_type=search_type, top_k=top_k)

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆå¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            loader = get_default_loader()
            if relevant_context:
                system_prompt = loader.get_prompt_from_preset(
                    "rag_proofreading",
                    prompt_preset,
                    "system_prompt_with_context"
                ).format(context=relevant_context)
            else:
                system_prompt = loader.get_prompt_from_preset(
                    "rag_proofreading",
                    prompt_preset,
                    "system_prompt_without_context"
                )

            # Azure OpenAI APIã§æ ¡æ­£å®Ÿè¡Œ
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                temperature=self.DEFAULT_TEMPERATURE,
            )

            return response.choices[0].message.content

        except Exception as e:
            st.error(f"æ ¡æ­£å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def save_knowledge_base(self, output_path):
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ä¿å­˜ï¼ˆLangChain FAISSä½¿ç”¨ï¼‰"""
        try:
            if not self.vectorstore:
                return False, "ä¿å­˜ã™ã‚‹ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“"

            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            with tempfile.TemporaryDirectory() as tmpdir:
                # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
                faiss_path = os.path.join(tmpdir, "faiss_index")
                self.vectorstore.save_local(faiss_path)

                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                metadata = {
                    "documents_count": len(self.documents),
                    "timestamp": datetime.now().isoformat()
                }
                metadata_path = os.path.join(tmpdir, "metadata.json")
                with open(metadata_path, "w", encoding="utf-8") as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)

                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã«åœ§ç¸®
                with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    # FAISSãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
                    for root, dirs, files in os.walk(faiss_path):
                        for file in files:
                            file_path = os.path.join(root, file)
                            arcname = os.path.join("faiss_index", file)
                            zipf.write(file_path, arcname)

                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    zipf.write(metadata_path, "metadata.json")

            return True, "ä¿å­˜æˆåŠŸ"

        except Exception as e:
            return False, f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"

    def load_knowledge_base(self, input_path):
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ï¼ˆLangChain FAISSä½¿ç”¨ï¼‰"""
        try:
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            with tempfile.TemporaryDirectory() as tmpdir:
                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
                with zipfile.ZipFile(input_path, 'r') as zipf:
                    zipf.extractall(tmpdir)

                # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
                faiss_path = os.path.join(tmpdir, "faiss_index")
                self.vectorstore = FAISS.load_local(
                    faiss_path,
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )

                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
                metadata_path = os.path.join(tmpdir, "metadata.json")
                if os.path.exists(metadata_path):
                    with open(metadata_path, "r", encoding="utf-8") as f:
                        metadata = json.load(f)
                else:
                    metadata = {}

            return True, "èª­ã¿è¾¼ã¿æˆåŠŸ", metadata

        except Exception as e:
            return False, f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", {}

    def get_database_info(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—"""
        has_data = self.vectorstore is not None
        return {
            "has_data": has_data,
            "documents_count": len(self.documents),
            "is_indexed": has_data,
            "total_chunks": self.vectorstore.index.ntotal if has_data else 0,
            "vector_files": 1 if has_data else 0,
            "output_files": 1 if has_data else 0,
            "search_types": ["similarity", "mmr"] if has_data else []
        }

    def get_chunks_detail(self):
        """ãƒãƒ£ãƒ³ã‚¯ã®è©³ç´°æƒ…å ±ã‚’å–å¾—

        Returns:
            list: ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯è¾æ›¸ï¼‰
        """
        if not self.vectorstore:
            return []

        try:
            chunks_info = []
            # FAISSã®docstoreã‹ã‚‰å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            docstore = self.vectorstore.docstore
            index_to_docstore_id = self.vectorstore.index_to_docstore_id

            for i in range(self.vectorstore.index.ntotal):
                doc_id = index_to_docstore_id[i]
                doc = docstore.search(doc_id)

                if doc:
                    chunks_info.append({
                        "chunk_id": i,
                        "doc_id": doc_id,
                        "content": doc.page_content,
                        "content_length": len(doc.page_content),
                        "source": doc.metadata.get("source", "ä¸æ˜"),
                        "metadata": doc.metadata
                    })

            return chunks_info
        except Exception as e:
            st.error(f"ãƒãƒ£ãƒ³ã‚¯è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def clear_knowledge_base(self):
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢"""
        self.vectorstore = None
        self.documents = []

# ========================================
# å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ========================================

def _init_rag_system():
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆå…±é€šå‡¦ç†ï¼‰"""
    if 'global_rag_system' not in st.session_state:
        st.session_state.global_rag_system = RAGProofreadingSystem(
            azure_endpoint=AZURE_OPENAI_ENDPOINT,
            azure_api_key=AZURE_OPENAI_API_KEY,
            api_version=API_VERSION
        )

    if 'global_db_info' not in st.session_state:
        st.session_state.global_db_info = st.session_state.global_rag_system.get_database_info()

    return st.session_state.global_rag_system

def _render_database_status(db_status, show_output_files=False):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹è¡¨ç¤ºï¼ˆå…±é€šå‡¦ç†ï¼‰"""
    metrics = [
        ("ãƒãƒ£ãƒ³ã‚¯æ•°", db_status.get('total_chunks', 0)),
        ("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹", "âœ… æ§‹ç¯‰æ¸ˆã¿" if db_status.get('is_indexed', False) else "âŒ æœªæ§‹ç¯‰")
    ]

    if show_output_files:
        metrics.insert(1, ("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•°", db_status.get('output_files', 0)))

    for col, (label, value) in zip(st.columns(len(metrics)), metrics):
        with col:
            st.metric(label, value)

def _render_database_operations(rag_system, key_prefix="", show_save=True):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œUIï¼ˆå…±é€šå‡¦ç†ï¼‰"""
    st.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ")

    has_data = st.session_state.global_db_info.get('has_data', False)
    cols = st.columns(3)

    # === ä¿å­˜ã‚°ãƒ«ãƒ¼ãƒ— ===
    with cols[0]:
        with st.container():
            st.markdown("##### ğŸ’¾ ä¿å­˜")
            st.markdown("---")

            if show_save and has_data:
                st.caption("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜")

                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã¨ã—ã¦ä¿å­˜
                if st.button("ğŸ“Œ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã«ä¿å­˜", key=f"{key_prefix}_save_default_db", use_container_width=True, type="primary"):
                    output_path = get_default_ragdb_path()
                    success, message = rag_system.save_knowledge_base(output_path)
                    if success:
                        st.success(f"âœ… ä¿å­˜å®Œäº†")
                    else:
                        st.error(f"âŒ {message}")

                st.markdown("")  # ã‚¹ãƒšãƒ¼ã‚µãƒ¼

                # åˆ¥åã§ä¿å­˜
                with st.expander("ğŸ“¥ åˆ¥åã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", expanded=False):
                    custom_filename = st.text_input(
                        "ãƒ•ã‚¡ã‚¤ãƒ«å",
                        value="custom_knowledge_base",
                        key=f"{key_prefix}_custom_filename",
                        placeholder="ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›"
                    )
                    if st.button("ä½œæˆ", key=f"{key_prefix}_save_custom_db", use_container_width=True):
                        # æ‹¡å¼µå­ã‚’è¿½åŠ 
                        filename_with_ext = custom_filename if custom_filename.endswith('.ragdb') else f"{custom_filename}.ragdb"

                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.ragdb') as tmp_file:
                            tmp_path = tmp_file.name

                        try:
                            success, message = rag_system.save_knowledge_base(tmp_path)
                            if success:
                                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³è¡¨ç¤º
                                with open(tmp_path, 'rb') as f:
                                    db_bytes = f.read()

                                st.success(f"âœ… ä½œæˆå®Œäº†")
                                st.download_button(
                                    label="ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                    data=db_bytes,
                                    file_name=filename_with_ext,
                                    mime="application/octet-stream",
                                    key=f"{key_prefix}_download_custom_db",
                                    use_container_width=True
                                )
                            else:
                                st.error(f"âŒ {message}")
                        finally:
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                            if os.path.exists(tmp_path):
                                os.remove(tmp_path)
            else:
                st.caption("ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                st.markdown("<br>", unsafe_allow_html=True)
                st.button("ğŸ“Œ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã«ä¿å­˜", key=f"{key_prefix}_save_default_db_disabled", use_container_width=True, disabled=True)

    # === èª­ã¿è¾¼ã¿ã‚°ãƒ«ãƒ¼ãƒ— ===
    with cols[1]:
        with st.container():
            st.markdown("##### ğŸ“‚ èª­ã¿è¾¼ã¿")
            st.markdown("---")
            st.caption("ä¿å­˜æ¸ˆã¿ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿")

            uploaded_db = st.file_uploader(
                "RAGDBãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                type=['ragdb'],
                key=f"{key_prefix}_load_db",
                label_visibility="collapsed"
            )
            if st.button("ğŸ“‚ èª­ã¿è¾¼ã¿å®Ÿè¡Œ", key=f"{key_prefix}_load_btn", use_container_width=True, type="primary", disabled=uploaded_db is None):
                with temp_file_path(uploaded_db.getvalue(), '.ragdb') as tmp_path:
                    success, message, metadata = rag_system.load_knowledge_base(tmp_path)
                    if success:
                        st.success("âœ… èª­ã¿è¾¼ã¿å®Œäº†")
                        st.session_state.global_db_info = rag_system.get_database_info()
                        st.rerun()
                    else:
                        st.error(message)

    # === ã‚¯ãƒªã‚¢ã‚°ãƒ«ãƒ¼ãƒ— ===
    with cols[2]:
        with st.container():
            st.markdown("##### ğŸ—‘ï¸ ã‚¯ãƒªã‚¢")
            st.markdown("---")

            if has_data:
                st.caption("ç¾åœ¨ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤")
                st.markdown("<br>", unsafe_allow_html=True)
                if st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢", key=f"{key_prefix}_clear_btn", use_container_width=True, type="primary"):
                    rag_system.clear_knowledge_base()
                    st.session_state.global_db_info = rag_system.get_database_info()
                    st.success("âœ… ã‚¯ãƒªã‚¢å®Œäº†")
                    st.rerun()
            else:
                st.caption("ã‚¯ãƒªã‚¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                st.markdown("<br>", unsafe_allow_html=True)
                st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢", key=f"{key_prefix}_clear_btn_disabled", use_container_width=True, disabled=True)

# ========================================
# ãƒšãƒ¼ã‚¸é–¢æ•°
# ========================================

def knowledge_base_management():
    st.title("ğŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†")
    st.write("è­°äº‹éŒ²æ ¡æ­£ç”¨ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ãƒ»ç®¡ç†ã—ã¾ã™ã€‚")

    st.sidebar.markdown("""
    ### ğŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†

    **æ¦‚è¦**
    LangChainã¨FAISSã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªRAGã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

    **ä¸»ãªæ©Ÿèƒ½**
    - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ : PDFã€Wordã€PowerPointå¯¾å¿œ
    - ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢: é«˜é€Ÿã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
    - DBä¿å­˜: .ragdbå½¢å¼ã§ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿
    - æ¤œç´¢ã‚¿ã‚¤ãƒ—: similarityã€mmrå¯¾å¿œ

    ğŸ’¡ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ ã§æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨è‡ªå‹•ãƒãƒ¼ã‚¸
    """)

    # RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    rag_system = _init_rag_system()

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®RAGDBãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã®ã¿ï¼‰
    if 'kb_default_db_loaded' not in st.session_state:
        default_ragdb_path = get_default_ragdb_path()
        if os.path.exists(default_ragdb_path):
            try:
                success, message, metadata = rag_system.load_knowledge_base(default_ragdb_path)
                if success:
                    st.success(f"âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ '{default_ragdb_path}' ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ")
                    st.session_state.global_db_info = rag_system.get_database_info()
                else:
                    st.warning(f"âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {message}")
            except Exception as e:
                st.warning(f"âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.session_state.kb_default_db_loaded = True

    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹è¡¨ç¤º
    st.subheader("ğŸ“Š ç¾åœ¨ã®çŠ¶æ…‹")
    _render_database_status(st.session_state.global_db_info)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
    _render_database_operations(rag_system, key_prefix="kb", show_save=True)

    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹è©³ç´°è¡¨ç¤º
    if st.session_state.global_db_info.get("has_data", False):
        with st.expander("ğŸ” ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹è©³ç´°", expanded=False):
            # ãƒãƒ£ãƒ³ã‚¯è©³ç´°ã‚’å–å¾—
            chunks_detail = rag_system.get_chunks_detail()

            if chunks_detail:
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                filter_col1, filter_col2 = st.columns([2, 1])
                with filter_col1:
                    search_text = st.text_input(
                        "ğŸ” ãƒãƒ£ãƒ³ã‚¯å†…å®¹ã§æ¤œç´¢",
                        key="chunk_search",
                        placeholder="æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›..."
                    )
                with filter_col2:
                    unique_sources = sorted(set(chunk["source"] for chunk in chunks_detail))
                    selected_source = st.selectbox(
                        "ğŸ“ ã‚½ãƒ¼ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿",
                        options=["ã™ã¹ã¦"] + unique_sources,
                        key="chunk_source_filter"
                    )

                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
                filtered_chunks = chunks_detail
                if search_text:
                    filtered_chunks = [
                        chunk for chunk in filtered_chunks
                        if search_text.lower() in chunk["content"].lower()
                    ]
                if selected_source != "ã™ã¹ã¦":
                    filtered_chunks = [
                        chunk for chunk in filtered_chunks
                        if chunk["source"] == selected_source
                    ]

                st.caption(f"è¡¨ç¤ºä¸­: {len(filtered_chunks)} / {len(chunks_detail)} ãƒãƒ£ãƒ³ã‚¯")

                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼ã§è¡¨ç¤º
                if filtered_chunks:
                    display_data = []
                    for chunk in filtered_chunks:
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
                        metadata = chunk["metadata"]
                        upload_datetime = metadata.get("upload_datetime", "-")
                        file_type = metadata.get("file_type", "-")

                        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é©åº¦ã«è¡¨ç¤º
                        content_preview = chunk["content"][:200] + "..." if len(chunk["content"]) > 200 else chunk["content"]

                        display_data.append({
                            "ã‚½ãƒ¼ã‚¹": chunk["source"],
                            "æŠ•å…¥æ—¥æ™‚": upload_datetime,
                            "å½¢å¼": file_type,
                            "æ–‡å­—æ•°": chunk["content_length"],
                            "å†…å®¹": content_preview
                        })

                    # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
                    st.dataframe(
                        display_data,
                        use_container_width=True,
                        hide_index=True,
                        height=400
                    )
                else:
                    st.warning("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.warning("ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
    st.subheader("ğŸ—ï¸ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰")

    # æ§‹ç¯‰ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    build_mode = st.radio(
        "æ§‹ç¯‰ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=["è¿½åŠ æ§‹ç¯‰", "æ–°è¦æ§‹ç¯‰"],
        index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: è¿½åŠ æ§‹ç¯‰
        horizontal=True,
        help="è¿½åŠ æ§‹ç¯‰: æ—¢å­˜ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ  | æ–°è¦æ§‹ç¯‰: æ—¢å­˜ã‚’å‰Šé™¤ã—ã¦æ–°è¦ä½œæˆ"
    )

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    doc_files = st.file_uploader(
        "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
        type=["pdf", "txt", "docx", "pptx"],
        accept_multiple_files=True,
        key="kb_doc_files",
        help="é¸æŠã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã™"
    )

    if doc_files and st.button("ğŸš€ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰", key="kb_build_btn", type="primary"):
        try:
            from datetime import datetime

            documents = []
            documents_metadata = []
            processed_files = []
            upload_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            with st.spinner("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ä¸­..."):
                for doc_file in doc_files:
                    try:
                        file_extension = doc_file.name.split(".")[-1].lower()
                        doc_content = extract_text_from_file(BytesIO(doc_file.read()), file_extension)

                        if doc_content.strip():
                            documents.append(doc_content)
                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                            documents_metadata.append({
                                'source': doc_file.name,  # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ä¿å­˜
                                'upload_datetime': upload_datetime,  # æŠ•å…¥æ—¥æ™‚
                                'file_type': file_extension.upper(),
                                'content_length': len(doc_content)
                            })
                            processed_files.append({
                                'name': doc_file.name,
                                'type': file_extension.upper(),
                                'size': len(doc_content),
                                'status': 'success'
                            })
                            st.success(f"âœ… {doc_file.name} ({file_extension.upper()}) - {len(doc_content):,}æ–‡å­—")
                        else:
                            processed_files.append({
                                'name': doc_file.name,
                                'type': file_extension.upper(),
                                'size': 0,
                                'status': 'empty'
                            })
                            st.warning(f"âš ï¸ {doc_file.name} - ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    except Exception as e:
                        processed_files.append({
                            'name': doc_file.name,
                            'type': 'ERROR',
                            'size': 0,
                            'status': 'error',
                            'error': str(e)
                        })
                        st.error(f"âŒ {doc_file.name} ã®å‡¦ç†ã«å¤±æ•—: {e}")

            if documents:
                with st.spinner("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ä¸­..."):
                    # æ§‹ç¯‰ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰æ›
                    mode = "add" if build_mode == "è¿½åŠ æ§‹ç¯‰" else "new"

                    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
                    if mode == "new":
                        st.info("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦æ–°è¦æ§‹ç¯‰ã—ã¾ã™")
                    else:
                        st.info("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ æ§‹ç¯‰ã—ã¾ã™")

                    success = st.session_state.global_rag_system.create_knowledge_base(
                        documents,
                        mode=mode,
                        documents_metadata=documents_metadata
                    )

                    if success:
                        st.session_state.global_db_info = st.session_state.global_rag_system.get_database_info()
                    else:
                        raise Exception("ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ")

                    # æ§‹ç¯‰çµæœè¡¨ç¤º
                    st.success(f"âœ… ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                    # è©³ç´°çµ±è¨ˆ
                    with st.expander("ğŸ“ˆ æ§‹ç¯‰çµæœè©³ç´°"):
                        new_total_chars = sum(len(doc) for doc in documents)
                        st.metric("æ–°è¦è¿½åŠ æ–‡å­—æ•°", f"{new_total_chars:,}")
                        st.metric("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°", st.session_state.global_db_info['documents_count'])
                        st.metric("ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«æ•°", st.session_state.global_db_info.get('vector_files', 0))
                        st.metric("æ¤œç´¢ã‚¿ã‚¤ãƒ—æ•°", len(st.session_state.global_db_info.get('search_types', [])))

                        # åˆ©ç”¨å¯èƒ½ãªæ¤œç´¢ã‚¿ã‚¤ãƒ—ã‚’è¡¨ç¤º
                        search_types = st.session_state.global_db_info.get('search_types', [])
                        if search_types:
                            st.write(f"**åˆ©ç”¨å¯èƒ½ãªæ¤œç´¢ã‚¿ã‚¤ãƒ—**: {', '.join(search_types)}")

                        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†çµæœãƒ†ãƒ¼ãƒ–ãƒ«
                        st.write("**ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†çµæœ**")
                        for file_info in processed_files:
                            status_icon = {
                                'success': 'âœ…',
                                'empty': 'âš ï¸',
                                'error': 'âŒ'
                            }.get(file_info['status'], 'â“')

                            st.write(f"{status_icon} **{file_info['name']}** ({file_info['type']}) - {file_info['size']:,}æ–‡å­—")

                    st.rerun()
            else:
                st.error("å‡¦ç†å¯èƒ½ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        except Exception as e:
            st.error(f"ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def proofread_meeting_minutes():
    st.title("ğŸ“ è­°äº‹éŒ²æ ¡æ­£")
    st.write("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ´»ç”¨ã—ãŸé«˜ç²¾åº¦ãªè­°äº‹éŒ²æ ¡æ­£ã‚’è¡Œã„ã¾ã™ã€‚")

    st.sidebar.markdown("""
    ### ğŸ“ è­°äº‹éŒ²æ ¡æ­£ã‚·ã‚¹ãƒ†ãƒ 

    **æ¦‚è¦**
    ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ´»ç”¨ã—ãŸé«˜ç²¾åº¦ãªè­°äº‹éŒ²æ ¡æ­£ã‚’æä¾›ã—ã¾ã™ã€‚

    **ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´**
    - é¡ä¼¼åº¦æ¤œç´¢: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
    - ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²: æœ€é©ã‚µã‚¤ã‚ºã§å‡¦ç†
    - é«˜é€Ÿæ¤œç´¢: åŠ¹ç‡çš„ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
    - ã‚·ãƒ³ãƒ—ãƒ«è¨­è¨ˆ: ä¿å®ˆã—ã‚„ã™ã„æ§‹æˆ

    **ä½¿ç”¨æ‰‹é †**
    1. ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ç¢ºèª
    2. è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›
    3. æ¤œç´¢ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ
    4. æ ¡æ­£ã‚’å®Ÿè¡Œ

    ğŸ’¡ æœªæ§‹ç¯‰ã®å ´åˆã¯ã€ŒãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†ã€ã‹ã‚‰
    """)

    # RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    rag_system = _init_rag_system()

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®RAGDBãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã®ã¿ï¼‰
    if 'default_db_loaded' not in st.session_state:
        default_ragdb_path = get_default_ragdb_path()
        if os.path.exists(default_ragdb_path):
            try:
                success, message, metadata = rag_system.load_knowledge_base(default_ragdb_path)
                if success:
                    st.success(f"âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ '{default_ragdb_path}' ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ")
                    st.session_state.global_db_info = rag_system.get_database_info()
                else:
                    st.warning(f"âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {message}")
            except Exception as e:
                st.warning(f"âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.session_state.default_db_loaded = True

    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹è¡¨ç¤º
    st.subheader("ğŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹")
    db_status = st.session_state.global_db_info
    _render_database_status(db_status, show_output_files=True)

    has_data = db_status.get('has_data', False)
    if not has_data:
        st.warning("âš ï¸ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€ŒãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†ã€ã§äº‹å‰ã«æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚")
        st.info("ğŸ“– ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãªã—ã§ã‚‚åŸºæœ¬çš„ãªæ ¡æ­£ã¯å®Ÿè¡Œã§ãã¾ã™ãŒã€é«˜åº¦ãªæ–‡è„ˆå‚ç…§æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
    with st.expander("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ"):
        _render_database_operations(rag_system, key_prefix="proofreading", show_save=False)

    # æ¤œç´¢çµæœæ•°ã®è¨­å®š
    top_k = st.selectbox(
        "æ¤œç´¢ã™ã‚‹é–¢é€£æ–‡è„ˆã®æ•°",
        options=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
        index=5,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 6
        help="ã‚ˆã‚Šå¤šãã®æ–‡è„ˆã‚’æ¤œç´¢ã™ã‚‹ã¨ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ãŒã€å‡¦ç†æ™‚é–“ãŒå¢—åŠ ã—ã¾ã™"
    )

    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ–¹æ³•ã®é¸æŠ
    input_method = st.radio(
        "è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆã®å…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«(.txt/.docx)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«ç›´æ¥å…¥åŠ›"],
        key="rag_input_method_selector"
    )

    transcript_text = ""

    if input_method == "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«(.txt/.docx)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        uploaded_text_file = st.file_uploader(
            "è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            type=["txt", "docx"],
            key="rag_upload_text_file"
        )

        if uploaded_text_file is not None:
            try:
                file_extension = uploaded_text_file.name.lower().split('.')[-1]

                if file_extension == 'txt':
                    transcript_text = uploaded_text_file.read().decode('utf-8')
                elif file_extension == 'docx':
                    # Wordæ–‡æ›¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                    transcript_text = get_text_from_docx(BytesIO(uploaded_text_file.read()))

                st.success(f"{file_extension.upper()}ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚")
                st.text_area("èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰",
                           transcript_text[:500] + "..." if len(transcript_text) > 500 else transcript_text,
                           height=150, key="rag_text_preview")
            except Exception as e:
                st.error(f"ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    else:  # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«ç›´æ¥å…¥åŠ›
        transcript_text = st.text_area(
            "è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            height=300,
            key="rag_direct_text_input",
            placeholder="ã“ã“ã«è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„..."
        )

    # æ ¡æ­£è¨­å®š
    st.subheader("ğŸ›ï¸ LangChainæ ¡æ­£è¨­å®š")

    config_col1, config_col2 = st.columns(2)

    with config_col1:
        # æ¤œç´¢ã‚¿ã‚¤ãƒ—é¸æŠ
        search_types = st.session_state.global_db_info.get('search_types', [])
        if search_types:
            search_type = st.selectbox(
                "æ¤œç´¢ã‚¿ã‚¤ãƒ—",
                search_types,
                key="search_type_selection",
                help="similarity: ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢ã€mmr: å¤šæ§˜æ€§ã‚’è€ƒæ…®ã—ãŸæ¤œç´¢"
            )

            if search_type == 'similarity':
                st.info("ğŸ¯ **é¡ä¼¼åº¦æ¤œç´¢**: ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã«ã‚ˆã‚‹æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æ–‡æ›¸æ¤œç´¢")
            elif search_type == 'mmr':
                st.info("ğŸ”„ **MMRæ¤œç´¢**: é–¢é€£æ€§ã¨å¤šæ§˜æ€§ã‚’ä¸¡ç«‹ã—ãŸæ–‡æ›¸æ¤œç´¢")
        else:
            search_type = "similarity"
            st.warning("ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é¡ä¼¼åº¦æ¤œç´¢ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

    with config_col2:
        # æ ¡æ­£ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_choice = st.selectbox(
            "LLMãƒ¢ãƒ‡ãƒ«",
            ["gpt-4o", "gpt-4o-mini"],
            key="proofreading_model",
            help="æ ¡æ­£ã«ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"
        )

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ
    st.markdown("### ğŸ¨ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆ")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆä¸€è¦§ã‚’å–å¾—
    loader = get_default_loader()
    presets = loader.get_preset_list("rag_proofreading")

    if presets:
        # ãƒ—ãƒªã‚»ãƒƒãƒˆã®é¸æŠè‚¢ã‚’ä½œæˆ
        preset_options = {f"{p['name']} - {p['description']}": p['id'] for p in presets}

        # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã§è¡¨ç¤º
        selected_preset_label = st.selectbox(
            "æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠ",
            options=list(preset_options.keys()),
            index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€åˆã®ãƒ—ãƒªã‚»ãƒƒãƒˆï¼ˆstandardï¼‰
            key="prompt_preset_selection",
            help="æ ¡æ­£ã®æ–¹é‡ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )

        # é¸æŠã•ã‚ŒãŸãƒ—ãƒªã‚»ãƒƒãƒˆã®IDã‚’å–å¾—
        selected_preset = preset_options[selected_preset_label]

        # é¸æŠã•ã‚ŒãŸãƒ—ãƒªã‚»ãƒƒãƒˆã®è©³ç´°ã‚’è¡¨ç¤º
        selected_preset_info = next((p for p in presets if p['id'] == selected_preset), None)
        if selected_preset_info:
            st.info(f"ğŸ“ **{selected_preset_info['name']}**: {selected_preset_info['description']}")
    else:
        selected_preset = "standard"
        st.warning("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    ##2025.9.8 ä¿®æ­£ï¼šåˆ†å‰²å‡¦ç†ã®è¿½åŠ 
    # åˆ†å‰²å‡¦ç†è¨­å®šã®è¿½åŠ 
    st.subheader("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²è¨­å®š")

    split_col1, split_col2 = st.columns(2)

    with split_col1:
        n_length = st.number_input(
            "åˆ†å‰²é–¾å€¤ (æ–‡å­—æ•°)",
            min_value=100,
            max_value=10000,
            value=1000,
            step=100,
            key="text_split_threshold",
            help="ã“ã®æ–‡å­—æ•°ã‚’è¶…ãˆã‚‹å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™"
        )

    with split_col2:
        if transcript_text.strip():
            current_length = len(transcript_text)
            estimated_parts = max(1, (current_length // n_length) + (1 if current_length % n_length > 0 else 0))
            st.metric("ç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆé•·", f"{current_length:,}æ–‡å­—")
            st.metric("æ¨å®šåˆ†å‰²æ•°", f"{estimated_parts}éƒ¨åˆ†")

    # LangChainæ ¡æ­£å®Ÿè¡Œ
    if transcript_text.strip() and st.button("ğŸ“ RAGæ ¡æ­£ã‚’å®Ÿè¡Œ", key="execute_rag_proofreading", type="primary"):
        if not transcript_text.strip():
            st.error("è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return

        try:
            ##2025.9.8 ä¿®æ­£ï¼šåˆ†å‰²å‡¦ç†ã®è¿½åŠ 
            # ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†å‰²åˆ¤å®šã¨å‡¦ç†
            current_length = len(transcript_text)

            if current_length > n_length:
                # åˆ†å‰²ãŒå¿…è¦ãªå ´åˆ
                n_parts = max(1, (current_length // n_length) + (1 if current_length % n_length > 0 else 0))
                st.info(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã„ãŸã‚ã€{n_parts}éƒ¨åˆ†ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™ï¼ˆé–¾å€¤: {n_length:,}æ–‡å­—ã€å®Ÿéš›: {current_length:,}æ–‡å­—ï¼‰")

                # ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
                text_parts = split_text_by_lines(transcript_text, n_parts)

                # å„ãƒ‘ãƒ¼ãƒˆã‚’é †æ¬¡å‡¦ç†
                proofread_parts = []
                progress_bar = st.progress(0)
                status_text = st.empty()

                with st.spinner(f"LangChainãƒ™ãƒ¼ã‚¹æ ¡æ­£ã‚’å®Ÿè¡Œä¸­ï¼ˆåˆ†å‰²å‡¦ç†: {n_parts}éƒ¨åˆ†ï¼‰..."):
                    current_db_status = st.session_state.global_rag_system.get_database_info()
                    if current_db_status['has_data']:
                        st.info(f"ğŸ” RAGãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä½¿ç”¨ä¸­ï¼ˆæ–‡æ›¸æ•°: {current_db_status['documents_count']}, æ¤œç´¢ã‚¿ã‚¤ãƒ—: {search_type}ï¼‰")
                    else:
                        st.info("ğŸ“– RAGãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãªã—ã§åŸºæœ¬æ ¡æ­£ã‚’å®Ÿè¡Œã—ã¾ã™")

                    for i, part in enumerate(text_parts, 1):
                        print("æ–‡å­—åˆ—:", part)
                        if part.strip():  # ç©ºã®ãƒ‘ãƒ¼ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
                            status_text.text(f"Part {i}/{n_parts} ã‚’å‡¦ç†ä¸­... ({len(part)}æ–‡å­—)")

                            # å„ãƒ‘ãƒ¼ãƒˆã‚’æ ¡æ­£
                            part_result = st.session_state.global_rag_system.rag_enhanced_proofread(
                                part,
                                model=model_choice,
                                search_type=search_type if current_db_status['has_data'] else "similarity",
                                top_k=top_k,
                                prompt_preset=selected_preset
                            )

                            if part_result:
                                proofread_parts.append(part_result)

                        progress_bar.progress(i / n_parts)

                    # çµæœã‚’é€£çµ
                    proofread_result = "\n\n".join(proofread_parts) if proofread_parts else ""
                    status_text.empty()
                    progress_bar.empty()

            else:
                # åˆ†å‰²ä¸è¦ãªå ´åˆï¼ˆå¾“æ¥ã®å‡¦ç†ï¼‰
                with st.spinner(f"LangChainãƒ™ãƒ¼ã‚¹æ ¡æ­£ã‚’å®Ÿè¡Œä¸­ ({search_type}æ¤œç´¢ä½¿ç”¨)..."):
                    # ç¾åœ¨ã®LangChain RAGãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çŠ¶æ³ã‚’è¡¨ç¤º
                    current_db_status = st.session_state.global_rag_system.get_database_info()
                    if current_db_status['has_data']:
                        st.info(f"ğŸ” RAGãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä½¿ç”¨ä¸­ï¼ˆæ–‡æ›¸æ•°: {current_db_status['documents_count']}, æ¤œç´¢ã‚¿ã‚¤ãƒ—: {search_type}ï¼‰")
                    else:
                        st.info("ğŸ“– RAGãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãªã—ã§åŸºæœ¬æ ¡æ­£ã‚’å®Ÿè¡Œã—ã¾ã™")

                    # LangChainæ ¡æ­£ã®å®Ÿè¡Œ
                    proofread_result = st.session_state.global_rag_system.rag_enhanced_proofread(
                        transcript_text,
                        model=model_choice,
                        search_type=search_type if current_db_status['has_data'] else "similarity",
                        top_k=top_k,
                        prompt_preset=selected_preset
                    )

                if proofread_result:
                    st.success(f"âœ… RAGæ ¡æ­£ãŒå®Œäº†ã—ã¾ã—ãŸï¼ ({search_type}æ¤œç´¢ä½¿ç”¨)")

                    # çµæœè¡¨ç¤º
                    st.subheader("ğŸ“„ æ ¡æ­£çµæœ")
                    st.text_area("æ ¡æ­£ã•ã‚ŒãŸè­°äº‹éŒ²", proofread_result, height=400, key="final_rag_result")

                    # ä½¿ç”¨ã•ã‚ŒãŸLangChain RAGæ–‡è„ˆã®è¡¨ç¤º
                    if current_db_status['has_data']:
                        with st.expander(f"ğŸ” RAGæ¤œç´¢çµæœ ({search_type}æ¤œç´¢)"):
                            relevant_context = st.session_state.global_rag_system.retrieve_relevant_context(
                                transcript_text,
                                search_type=search_type,
                                top_k=top_k
                            )
                            if relevant_context:
                                st.text_area("RAGæ¤œç´¢çµæœ", relevant_context, height=200, key="final_context_display")

                                # æ¤œç´¢ã‚¿ã‚¤ãƒ—ã®è©³ç´°èª¬æ˜
                                if search_type == 'similarity':
                                    st.info("ğŸ¯ é¡ä¼¼åº¦æ¤œç´¢: ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã«ã‚ˆã‚‹é–¢é€£æ–‡æ›¸ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º")
                                elif search_type == 'mmr':
                                    st.info("ğŸ”„ MMRæ¤œç´¢: é–¢é€£æ€§ã¨å¤šæ§˜æ€§ã‚’è€ƒæ…®ã—ãŸæ–‡æ›¸ã‹ã‚‰æ–‡è„ˆã‚’å–å¾—")
                            else:
                                st.write("é–¢é€£æ–‡è„ˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨çµ±è¨ˆ
                    col_dl, col_stats = st.columns([1, 1])

                    with col_dl:
                        # Wordæ–‡æ›¸ã¨ã—ã¦ä¿å­˜
                        doc = DocxDocument()
                        doc.add_heading('RAGæ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²', 0)

                        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½ã«åˆ†å‰²ã—ã¦è¿½åŠ 
                        for line in proofread_result.split('\n'):
                            if line.strip():
                                doc.add_paragraph(line)
                            else:
                                doc.add_paragraph('')  # ç©ºè¡Œã‚’ä¿æŒ

                        docx_buffer = BytesIO()
                        doc.save(docx_buffer)
                        docx_buffer.seek(0)

                        st.download_button(
                            label="ğŸ“¥ RAGæ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=docx_buffer.getvalue(),
                            file_name=f"rag_proofread_{search_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                            mime='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                            key="download_final_rag_result"
                        )

                    with col_stats:
                        # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
                        with st.expander("ğŸ“Š æ ¡æ­£çµ±è¨ˆ"):
                            original_length = len(transcript_text)
                            proofread_length = len(proofread_result)
                            change_ratio = ((proofread_length - original_length) / original_length * 100) if original_length > 0 else 0

                            st.metric("å…ƒã®æ–‡å­—æ•°", f"{original_length:,}")
                            st.metric("æ ¡æ­£å¾Œæ–‡å­—æ•°", f"{proofread_length:,}")
                            st.metric("å¤‰åŒ–ç‡", f"{change_ratio:.1f}%")

                            if current_db_status['has_data']:
                                st.metric("å‚ç…§ãƒãƒ£ãƒ³ã‚¯æ•°", current_db_status['total_chunks'])
                                st.metric("æ¤œç´¢ç¯„å›²", f"ä¸Šä½{top_k}ä»¶")

                else:
                    st.error("âŒ æ ¡æ­£å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚Azure OpenAIã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        except Exception as e:
            st.error(f"âŒ RAGæ ¡æ­£å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("ğŸ’¡ Azure OpenAIã®è¨­å®šã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    elif not transcript_text.strip():
        st.info("ğŸ’­ è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰RAGæ ¡æ­£ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

def batch_processing_pipeline():
    """ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: 1æœ¬ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰è¤‡æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ®µéšçš„ã«å‡¦ç†"""
    st.title("ğŸš€ ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå‹•ç”»/éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒºé–“ã”ã¨ã«åˆ‡ã‚Šå‡ºã—ã€æ–‡å­—èµ·ã“ã—ã‹ã‚‰æ ¡æ­£ã¾ã§ã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œã—ã¾ã™ã€‚")
    st.write("æ–‡å­—èµ·ã“ã— â†’ å€‹åˆ¥è©±è€…è­˜åˆ¥ â†’ RAGæ ¡æ­£ â†’ å‡ºåŠ›ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é †ç•ªã«é€²ã‚ã‚‹ã ã‘ã§å®Œäº†ã—ã¾ã™ã€‚")

    st.sidebar.markdown("""
    ### ğŸš€ ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    **æ¦‚è¦**
    å‹•ç”»ãƒ»éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¿…è¦ãªåŒºé–“ã‚’åˆ‡ã‚Šå‡ºã—ã€ä¸€æ‹¬ã§æ–‡å­—èµ·ã“ã—ãƒ»è©±è€…è­˜åˆ¥ãƒ»RAGæ ¡æ­£ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

    **å‡¦ç†ãƒ•ãƒ­ãƒ¼**
    1. ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨åŒºé–“è¨­å®š
    2. ãƒ¢ãƒ‡ãƒ«é¸æŠã¨æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
    3. å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®è©±è€…è­˜åˆ¥ï¼ˆå€‹åˆ¥è¨­å®šå¯èƒ½ï¼‰
    4. RAGæ ¡æ­£å®Ÿè¡Œ
    5. å‡¦ç†çµæœã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

    **å¯¾å¿œå½¢å¼:** MP4, MOV, AVI, MKV, WebM, MP3, WAV, M4Aç­‰
    """)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    _init_session_state({
        'batch_uploaded_video': None,
        'batch_extracted_files': [],
        'batch_processing_results': {},
        'batch_processing_status': {},
        'batch_current_step': 1,
        'batch_rag_system': None,
        'batch_transcribe_model': 'whisper',
        'batch_reference_file': None,
        'batch_current_speaker_file_index': 0,
        'batch_db_info': None,
        'batch_meeting_type': None,
        'batch_default_embeddings': [],
        'batch_file_embeddings': {},  # å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®åŸ‹ã‚è¾¼ã¿è¨­å®š
        'batch_embedding_states': {},  # è©±è€…åŸ‹ã‚è¾¼ã¿ä½œæˆUIç”¨ã®çŠ¶æ…‹
        'batch_temp_dir': None,  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        'batch_cut_settings_df': None  # åˆ‡ã‚Šå‡ºã—è¨­å®šDataFrame
    })

    # Step 1: å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨éŸ³å£°åˆ‡ã‚Šå‡ºã—è¨­å®š
    st.subheader("Step 1: ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨éŸ³å£°åˆ‡ã‚Šå‡ºã—")
    st.write("å‹•ç”»ãƒ»éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€å‡¦ç†ã—ãŸã„åŒºé–“ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚è¤‡æ•°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŒ‡å®šã§ãã¾ã™ã€‚")
    st.caption("â€» åˆ‡ã‚Šå‡ºã—ã¯ä»»æ„ã§ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’ä½¿ã†å ´åˆã¯ãã®ã¾ã¾æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸é€²ã‚ã¾ã™ã€‚")

    uploaded_video = st.file_uploader(
        "ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=["wav", "mp3", "mp4", "mov", "avi", "mkv", "webm", "m4a"],
        key="batch_video_upload"
    )

    if uploaded_video is not None:
        st.success(f"âœ… ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ« '{uploaded_video.name}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

        # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        video_ext = os.path.splitext(uploaded_video.name)[1].lower()
        if video_ext in ['.mp4', '.mov', '.webm', '.avi', '.mkv']:
            st.video(uploaded_video)
        elif video_ext in ['.mp3', '.wav', '.m4a']:
            st.audio(uploaded_video)

        st.subheader("åˆ‡ã‚Šå‡ºã—åŒºé–“ã®è¨­å®š")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®data_editorãƒ‡ãƒ¼ã‚¿
        if st.session_state.batch_cut_settings_df is None:
            default_data = pd.DataFrame([
                {"é–‹å§‹æ™‚é–“": "00:00:00", "çµ‚äº†æ™‚é–“": "00:00:30", "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å": f"{os.path.splitext(uploaded_video.name)[0]}_"}
            ])
        else:
            default_data = st.session_state.batch_cut_settings_df

        edited_df = st.data_editor(
            default_data,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "é–‹å§‹æ™‚é–“": st.column_config.TextColumn(
                    "é–‹å§‹æ™‚é–“ (HH:MM:SS or seconds)",
                    help="åˆ‡ã‚Šå‡ºã—é–‹å§‹æ™‚é–“ (ä¾‹: 00:00:10 ã¾ãŸã¯ 10)",
                    default="00:00:00"
                ),
                "çµ‚äº†æ™‚é–“": st.column_config.TextColumn(
                    "çµ‚äº†æ™‚é–“ (HH:MM:SS or seconds)",
                    help="åˆ‡ã‚Šå‡ºã—çµ‚äº†æ™‚é–“ (ä¾‹: 00:00:30 ã¾ãŸã¯ 30)",
                    default="00:00:30"
                ),
                "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å": st.column_config.TextColumn(
                    "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å (.mp3)",
                    help="ã“ã®åŒºé–“ã®MP3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: meeting1.mp3)ã€‚ç©ºæ¬„ã®å ´åˆã€è‡ªå‹•ã§é€£ç•ªãŒæŒ¯ã‚‰ã‚Œã¾ã™ã€‚",
                    default=f"{os.path.splitext(uploaded_video.name)[0]}_"
                )
            },
            key="batch_cut_settings_editor"
        )

        # è¨­å®šã‚’ä¿å­˜
        st.session_state.batch_cut_settings_df = edited_df

        # éŸ³å£°åˆ‡ã‚Šå‡ºã—å®Ÿè¡Œ
        if st.button("ğŸµ éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—ã¦Step 2ã¸é€²ã‚€", key="batch_execute_cut", type="primary"):
            if edited_df.empty:
                st.warning("åˆ‡ã‚Šå‡ºã—åŒºé–“ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            else:
                with st.spinner("éŸ³å£°ã®åˆ‡ã‚Šå‡ºã—ã¨MP3ã¸ã®å¤‰æ›ä¸­..."):
                    try:
                        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                        if st.session_state.batch_temp_dir is None:
                            st.session_state.batch_temp_dir = tempfile.mkdtemp()

                        temp_dir = st.session_state.batch_temp_dir
                        temp_video_path = None
                        extracted_files = []

                        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
                        uploaded_video.seek(0)
                        temp_video_path = os.path.join(temp_dir, f"source_video{os.path.splitext(uploaded_video.name)[1]}")
                        with open(temp_video_path, 'wb') as f:
                            f.write(uploaded_video.read())

                        # å„åŒºé–“ã‚’åˆ‡ã‚Šå‡ºã—
                        for index, row in edited_df.iterrows():
                            start_time_str = str(row["é–‹å§‹æ™‚é–“"])
                            end_time_str = str(row["çµ‚äº†æ™‚é–“"])
                            output_filename_raw = str(row["å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å"]).strip()

                            try:
                                start_seconds = parse_time_to_seconds(start_time_str)
                                end_seconds = parse_time_to_seconds(end_time_str)

                                if start_seconds >= end_seconds:
                                    st.error(f"åŒºé–“ {index+1}: é–‹å§‹æ™‚é–“ ({start_time_str}) ã¯çµ‚äº†æ™‚é–“ ({end_time_str}) ã‚ˆã‚Šå‰ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚ã“ã®åŒºé–“ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
                                    continue

                                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
                                base_name_from_video = os.path.splitext(uploaded_video.name)[0]
                                if not output_filename_raw or output_filename_raw.upper() == "AUTO_GENERATE":
                                    output_filename = f"{base_name_from_video}_segment_{index+1}.mp3"
                                else:
                                    output_filename = output_filename_raw

                                # .mp3æ‹¡å¼µå­ã‚’ç¢ºä¿
                                if not output_filename.lower().endswith(".mp3"):
                                    output_filename += ".mp3"

                                output_audio_path = os.path.join(temp_dir, output_filename)

                                # FFmpegã§åˆ‡ã‚Šå‡ºã—
                                command = [
                                    "ffmpeg",
                                    "-i", temp_video_path,
                                    "-ss", format_time(start_seconds),
                                    "-to", format_time(end_seconds),
                                    "-vn",  # No video
                                    "-ab", "192k",  # Audio bitrate
                                    "-map_metadata", "-1",  # Remove metadata
                                    "-y",  # Overwrite output files without asking
                                    output_audio_path
                                ]

                                process = subprocess.run(command, capture_output=True, text=True, encoding="utf-8", check=True)

                                # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿
                                with open(output_audio_path, 'rb') as f:
                                    file_data = f.read()
                                    file_io = BytesIO(file_data)
                                    file_io.name = output_filename
                                    extracted_files.append({
                                        'name': output_filename,
                                        'data': file_io,
                                        'size': len(file_data)
                                    })

                                st.success(f"âœ… åŒºé–“ {index+1}: {output_filename} ã®åˆ‡ã‚Šå‡ºã—ãŒå®Œäº†ã—ã¾ã—ãŸ")

                            except subprocess.CalledProcessError as e:
                                st.error(f"âŒ åŒºé–“ {index+1}: FFmpegã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                                st.code(e.stderr)
                            except ValueError as e:
                                st.error(f"âŒ åŒºé–“ {index+1}: æ™‚é–“å½¢å¼ã‚¨ãƒ©ãƒ¼: {e}")
                            except Exception as e:
                                st.error(f"âŒ åŒºé–“ {index+1}: å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

                        if extracted_files:
                            # æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’session stateã«ä¿å­˜
                            st.session_state.batch_extracted_files = extracted_files
                            st.session_state.batch_current_step = 2

                            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çŠ¶æ…‹ã‚’åˆæœŸåŒ–
                            for file_info in extracted_files:
                                st.session_state.batch_processing_status[file_info['name']] = {
                                    'transcription': 'pending',
                                    'speaker_id': 'pending',
                                    'rag_proofread': 'pending'
                                }
                                st.session_state.batch_processing_results[file_info['name']] = {}

                            st.success(f"âœ… {len(extracted_files)} å€‹ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ‡ã‚Šå‡ºã—ãŒå®Œäº†ã—ã¾ã—ãŸ")
                            st.rerun()
                        else:
                            st.warning("âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒ1ã¤ã‚‚ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

                    except Exception as e:
                        st.error(f"âŒ éŸ³å£°åˆ‡ã‚Šå‡ºã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        import traceback
                        st.error(traceback.format_exc())

        if st.button("â­ åˆ‡ã‚Šå‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦Step 2ã¸é€²ã‚€", key="batch_skip_cut"):
            uploaded_video.seek(0)
            file_bytes = uploaded_video.read()

            if not file_bytes:
                st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                file_buffer = BytesIO(file_bytes)
                file_buffer.name = uploaded_video.name

                st.session_state.batch_extracted_files = [{
                    'name': uploaded_video.name,
                    'data': file_buffer,
                    'size': len(file_bytes)
                }]

                st.session_state.batch_processing_status = {
                    uploaded_video.name: {
                        'transcription': 'pending',
                        'speaker_id': 'pending',
                        'rag_proofread': 'pending'
                    }
                }
                st.session_state.batch_processing_results = {
                    uploaded_video.name: {}
                }
                st.session_state.batch_current_step = 2
                st.success("âœ… åˆ‡ã‚Šå‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚å…ƒã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Step 2ã§ãã®ã¾ã¾æ–‡å­—èµ·ã“ã—ã—ã¾ã™ã€‚")
                st.rerun()

    # Step 2: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨æ–‡å­—èµ·ã“ã—
    if st.session_state.batch_current_step >= 2 and len(st.session_state.batch_extracted_files) > 0:
        st.subheader("Step 2: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨æ–‡å­—èµ·ã“ã—")

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
        st.write(f"**æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(st.session_state.batch_extracted_files)}")

        file_df = pd.DataFrame([
            {
                'ãƒ•ã‚¡ã‚¤ãƒ«å': f['name'],
                'ã‚µã‚¤ã‚º (KB)': f'{f["size"] / 1024:.1f}'
            }
            for f in st.session_state.batch_extracted_files
        ])
        st.dataframe(file_df, use_container_width=True, hide_index=True)

        st.divider()

        reference_file = None
        meeting_types = load_meeting_type_config()
        col_settings, col_meeting = st.columns(2, gap="large")

        with col_settings:
            st.write("**æ–‡å­—èµ·ã“ã—è¨­å®š**")

            transcribe_model = st.selectbox(
                "æ–‡å­—èµ·ã“ã—ãƒ¢ãƒ‡ãƒ«",
                options=["whisper", "gpt-4o-transcribe-diarize"],
                index=0,
                key="batch_transcribe_model_select",
                help="whisper: å‚è€ƒè³‡æ–™å¯¾å¿œ | gpt-4o-transcribe-diarize: è‡ªå‹•è©±è€…è­˜åˆ¥ä»˜ã"
            )

            if transcribe_model == "whisper":
                reference_file = st.file_uploader(
                    "å‚è€ƒè³‡æ–™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
                    type=["pdf", "docx", "pptx", "txt", "msg"],
                    key="batch_reference_file_upload",
                    help="å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ç²¾åº¦å‘ä¸Šã«ä½¿ç”¨"
                )

        with col_meeting:
            st.write("**ä¼šè­°ã‚¿ã‚¤ãƒ—è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**")
            st.write("ä¼šè­°ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã™ã‚‹ã¨ã€äº‹å‰ã«è¨­å®šã•ã‚ŒãŸè©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«èª­ã¿è¾¼ã¿ã¾ã™ã€‚")

            if meeting_types:
                meeting_type_options = {mt['id']: f"{mt['name']} - {mt['description']}" for mt in meeting_types}

                selected_meeting_type_id = st.selectbox(
                    "ä¼šè­°ã‚¿ã‚¤ãƒ—",
                    options=list(meeting_type_options.keys()),
                    format_func=lambda x: meeting_type_options[x],
                    key="batch_meeting_type_select"
                )

                selected_meeting_type = next((mt for mt in meeting_types if mt['id'] == selected_meeting_type_id), None)

                if selected_meeting_type and selected_meeting_type['embeddings_folder']:
                    if st.session_state.batch_meeting_type != selected_meeting_type_id:
                        st.session_state.batch_meeting_type = selected_meeting_type_id
                        st.session_state.batch_default_embeddings = load_embeddings_from_folder(
                            selected_meeting_type['embeddings_folder']
                        )

                        if st.session_state.batch_default_embeddings:
                            st.success(f"âœ… {len(st.session_state.batch_default_embeddings)}å€‹ã®è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                            embedding_names = [emb['name'] for emb in st.session_state.batch_default_embeddings]
                            st.info(f"ğŸ“ èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(embedding_names)}")
                elif selected_meeting_type_id == 'custom':
                    st.session_state.batch_meeting_type = 'custom'
                    st.session_state.batch_default_embeddings = []
                    st.info("ğŸ’¡ ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ¼ãƒ‰: Step 3ã§å€‹åˆ¥ã«è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            else:
                st.warning("âš ï¸ ä¼šè­°ã‚¿ã‚¤ãƒ—ã®ãƒ—ãƒªã‚»ãƒƒãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æ‰‹å‹•ã§è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

        st.divider()

        # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
        if st.button("ğŸ“ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹", key="batch_start_transcription", type="primary"):
            # é€²æ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()

            total_files = len(st.session_state.batch_extracted_files)

            for idx, file_info in enumerate(st.session_state.batch_extracted_files):
                file_name = file_info['name']
                file_data = file_info['data']

                status_text.write(f"**æ–‡å­—èµ·ã“ã—ä¸­: {file_name}** ({idx + 1}/{total_files})")

                try:
                    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                    st.session_state.batch_processing_status[file_name]['transcription'] = 'processing'

                    file_data.seek(0)
                    seg_df = transcribe_audio_to_dataframe(
                        file_data,
                        reference_file=reference_file,
                        model=transcribe_model
                    )

                    st.session_state.batch_processing_results[file_name]['transcription_df'] = seg_df
                    st.session_state.batch_processing_status[file_name]['transcription'] = 'completed'
                    st.success(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {file_name} ({len(seg_df)}è¡Œ)")

                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {file_name} - {e}")
                    st.session_state.batch_processing_status[file_name]['transcription'] = 'error'
                    import traceback
                    st.error(traceback.format_exc())

                # é€²æ—ãƒãƒ¼æ›´æ–°
                progress_bar.progress((idx + 1) / total_files)

            status_text.write("âœ… **ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼**")
            st.session_state.batch_current_step = 3
            st.balloons()
            st.rerun()

    # Step 3: å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®è©±è€…è­˜åˆ¥
    if st.session_state.batch_current_step >= 3 and len(st.session_state.batch_extracted_files) > 0:
        st.subheader("Step 3: å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®è©±è€…è­˜åˆ¥")
        st.write("å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«è©±è€…è­˜åˆ¥ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ç•°ãªã‚‹è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚")

        # å‡¦ç†çŠ¶æ³ã‚µãƒãƒªãƒ¼
        transcription_completed = sum(1 for status in st.session_state.batch_processing_status.values() if status.get('transcription') == 'completed')
        speaker_id_completed = sum(1 for status in st.session_state.batch_processing_status.values() if status.get('speaker_id') == 'completed')

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ–‡å­—èµ·ã“ã—å®Œäº†", f"{transcription_completed}/{len(st.session_state.batch_extracted_files)}")
        with col2:
            st.metric("è©±è€…è­˜åˆ¥å®Œäº†", f"{speaker_id_completed}/{len(st.session_state.batch_extracted_files)}")
        with col3:
            if st.button("ğŸ”„ è©±è€…è­˜åˆ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã¸", key="skip_speaker_id"):
                st.session_state.batch_current_step = 4
                st.rerun()

        st.divider()

        # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚¿ãƒ–ã‚’ä½œæˆ
        file_names = [f['name'] for f in st.session_state.batch_extracted_files]
        file_tabs = st.tabs(file_names)

        for tab_idx, (file_tab, file_info) in enumerate(zip(file_tabs, st.session_state.batch_extracted_files)):
            with file_tab:
                selected_file_name = file_info['name']
                selected_file_info = file_info

                if selected_file_name in st.session_state.batch_processing_results:
                    result = st.session_state.batch_processing_results[selected_file_name]

                    # æ–‡å­—èµ·ã“ã—çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    if 'transcription_df' in result:
                        transcription_df = result['transcription_df']
                        with st.expander("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
                            if 'speaker' in transcription_df.columns:
                                disabled_columns = [col for col in transcription_df.columns if col != 'speaker']
                                edited_transcription = st.data_editor(
                                    transcription_df,
                                    hide_index=True,
                                    use_container_width=True,
                                    num_rows="dynamic",
                                    disabled=disabled_columns,
                                    column_config={
                                        "speaker": st.column_config.TextColumn(
                                            "è©±è€…",
                                            help="å¿…è¦ã«å¿œã˜ã¦è©±è€…åã‚’ç›´æ¥ç·¨é›†ã—ã¦ãã ã•ã„"
                                        )
                                    },
                                    key=f"transcription_editor_{selected_file_name}_{tab_idx}"
                                )

                                if isinstance(edited_transcription, pd.DataFrame):
                                    updated_transcription_df = edited_transcription.copy()
                                else:
                                    updated_transcription_df = pd.DataFrame(edited_transcription)

                                updated_transcription_df = updated_transcription_df.reset_index(drop=True)
                                transcription_df_normalized = transcription_df.reset_index(drop=True)

                                # Ensure original columns exist in editor output
                                for column in transcription_df_normalized.columns:
                                    if column not in updated_transcription_df.columns:
                                        updated_transcription_df[column] = transcription_df_normalized[column]
                                updated_transcription_df = updated_transcription_df[transcription_df_normalized.columns]

                                original_speaker = transcription_df_normalized['speaker'].astype(str).fillna("")
                                updated_speaker = updated_transcription_df['speaker'].astype(str).fillna("")

                                if not updated_speaker.equals(original_speaker):
                                    st.session_state.batch_processing_results[selected_file_name]['transcription_df'] = updated_transcription_df
                                    transcription_df = updated_transcription_df
                                    st.session_state.batch_processing_results[selected_file_name].pop('identified_df', None)
                                    st.session_state.batch_processing_results[selected_file_name].pop('meeting_text', None)
                                    st.session_state.batch_processing_results[selected_file_name].pop('proofread_text', None)

                                    status_entry = st.session_state.batch_processing_status.get(selected_file_name, {})
                                    status_entry['speaker_id'] = 'pending'
                                    status_entry['rag_proofread'] = 'pending'
                                    st.session_state.batch_processing_status[selected_file_name] = status_entry

                                    st.success("âœï¸ è©±è€…åˆ—ã®å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚å†åº¦è©±è€…è­˜åˆ¥ã‚„RAGæ ¡æ­£ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                            else:
                                st.dataframe(transcription_df.head(10), use_container_width=True)

                        tab_identify, tab_embed = st.tabs(["è©±è€…è­˜åˆ¥", "è©±è€…åŸ‹ã‚è¾¼ã¿ä½œæˆ"])

                        with tab_identify:
                            st.write("**è©±è€…è­˜åˆ¥è¨­å®š**")

                            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°è¡¨ç¤º
                            if st.session_state.batch_default_embeddings:
                                st.info(f"âœ… ä¼šè­°ã‚¿ã‚¤ãƒ—ã‹ã‚‰{len(st.session_state.batch_default_embeddings)}å€‹ã®è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’èª­ã¿è¾¼ã¿æ¸ˆã¿")
                                default_names = [emb['name'] for emb in st.session_state.batch_default_embeddings]
                                with st.expander("èª­ã¿è¾¼ã¿æ¸ˆã¿è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«", expanded=True):
                                    st.write(", ".join(default_names))

                            col1, col2 = st.columns(2)

                            with col1:
                                # è¿½åŠ ã®åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                                additional_embeddings = st.file_uploader(
                                    "è¿½åŠ ã®è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.npyï¼‰",
                                    type=["npy"],
                                    accept_multiple_files=True,
                                    key=f"batch_additional_embeddings_{selected_file_name}_{tab_idx}",
                                    help="ä¼šè­°ã‚¿ã‚¤ãƒ—ã§èª­ã¿è¾¼ã‚“ã ãƒ•ã‚¡ã‚¤ãƒ«ã«åŠ ãˆã¦ã€è¿½åŠ ã§åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã§ãã¾ã™"
                                )

                            with col2:
                                similarity_threshold = st.slider(
                                    "é¡ä¼¼åº¦é–¾å€¤",
                                    min_value=0.0,
                                    max_value=1.0,
                                    value=0.7,
                                    step=0.01,
                                    key=f"batch_similarity_threshold_{selected_file_name}_{tab_idx}"
                                )

                            # ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
                            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåŸ‹ã‚è¾¼ã¿ + è¿½åŠ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                            all_embeddings = list(st.session_state.batch_default_embeddings)
                            if additional_embeddings:
                                all_embeddings.extend(additional_embeddings)

                            # åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’è¡¨ç¤º
                            total_embeddings = len(all_embeddings)
                            if total_embeddings > 0:
                                st.success(f"ğŸ“Š åˆè¨ˆ {total_embeddings}å€‹ã®è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
                            else:
                                st.warning("âš ï¸ è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Step 2ã§ä¼šè­°ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã™ã‚‹ã‹ã€ä¸Šè¨˜ã§è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

                            # è©±è€…è­˜åˆ¥å®Ÿè¡Œ
                            if all_embeddings and st.button(f"ğŸ¤ {selected_file_name} ã®è©±è€…è­˜åˆ¥ã‚’å®Ÿè¡Œ", key=f"execute_speaker_id_{selected_file_name}_{tab_idx}", type="primary"):
                                with st.spinner(f"ğŸ¤ è©±è€…è­˜åˆ¥ä¸­: {selected_file_name}"):
                                    try:
                                        file_data = selected_file_info['data']
                                        file_data.seek(0)

                                        identified_df = identify_speakers_in_dataframe(
                                            file_data,
                                            transcription_df,
                                            all_embeddings,
                                            similarity_threshold
                                        )

                                        st.session_state.batch_processing_results[selected_file_name]['identified_df'] = identified_df
                                        st.session_state.batch_processing_status[selected_file_name]['speaker_id'] = 'completed'
                                        st.success(f"âœ… è©±è€…è­˜åˆ¥å®Œäº†: {selected_file_name}")
                                        st.rerun()

                                    except Exception as e:
                                        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
                                        st.session_state.batch_processing_status[selected_file_name]['speaker_id'] = 'error'
                                        import traceback
                                        st.error(traceback.format_exc())

                            if 'identified_df' in result and not result['identified_df'].empty:
                                st.divider()
                                st.write("**è©±è€…è­˜åˆ¥çµæœã®æ‰‹å‹•ä¿®æ­£**")
                                st.caption("è©±è€…åˆ—ã‚’ç›´æ¥ç·¨é›†ã—ã¦ãƒ©ãƒ™ãƒ«ã‚’èª¿æ•´ã§ãã¾ã™ã€‚ä¿®æ­£å¾Œã¯RAGæ ¡æ­£ã‚„ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

                                current_identified_df = result['identified_df'].copy()
                                if 'speaker' not in current_identified_df.columns:
                                    st.warning("è©±è€…åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è­˜åˆ¥çµæœã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                                else:
                                    disabled_cols = [col for col in current_identified_df.columns if col != 'speaker']
                                    edited_df = st.data_editor(
                                        current_identified_df,
                                        column_config={
                                            "speaker": st.column_config.TextColumn(
                                                "è©±è€…",
                                                help="å¿…è¦ã«å¿œã˜ã¦è©±è€…åã‚’ç›´æ¥å…¥åŠ›ã—ã¦ãã ã•ã„"
                                            )
                                        },
                                        disabled=disabled_cols,
                                        hide_index=True,
                                        use_container_width=True,
                                        key=f"identified_editor_{selected_file_name}_{tab_idx}"
                                    )

                                    if isinstance(edited_df, pd.DataFrame):
                                        updated_df = edited_df.copy()
                                    else:
                                        updated_df = pd.DataFrame(edited_df)

                                    updated_df = updated_df.reset_index(drop=True)
                                    current_normalized = current_identified_df.reset_index(drop=True)

                                    # Ensure column order matches original
                                    updated_df = updated_df[current_normalized.columns]

                                    if not updated_df.equals(current_normalized):
                                        st.session_state.batch_processing_results[selected_file_name]['identified_df'] = updated_df
                                        st.session_state.batch_processing_results[selected_file_name].pop('meeting_text', None)
                                        st.session_state.batch_processing_results[selected_file_name].pop('proofread_text', None)

                                        status_entry = st.session_state.batch_processing_status.get(selected_file_name, {})
                                        status_entry['speaker_id'] = 'completed'
                                        status_entry['rag_proofread'] = 'pending'
                                        st.session_state.batch_processing_status[selected_file_name] = status_entry

                                        st.success("âœï¸ è©±è€…ãƒ©ãƒ™ãƒ«ã®å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                                        st.info("å¤‰æ›´å†…å®¹ã‚’åæ˜ ã™ã‚‹ã«ã¯ã€å¿…è¦ã«å¿œã˜ã¦Step 4ä»¥é™ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

                        with tab_embed:
                            st.write("éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã—ã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç¢ºèªã—ã¦ã‹ã‚‰è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã§ãã¾ã™ã€‚")

                            target_df = result.get('identified_df', transcription_df).copy()

                            if len(target_df) == 0:
                                st.warning("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                            else:
                                embedding_states = st.session_state.batch_embedding_states
                                if selected_file_name not in embedding_states:
                                    embedding_states[selected_file_name] = {
                                        'selected_rows': set(),
                                        'preview_audio': None,
                                        'show_preview': False
                                    }
                                embedding_state = embedding_states[selected_file_name]

                                selection_mode = st.radio(
                                    "é¸æŠæ–¹å¼ã‚’é¸ã‚“ã§ãã ã•ã„",
                                    options=["ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰", "ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ¼ãƒ‰"],
                                    horizontal=True,
                                    help="ç¯„å›²æŒ‡å®š: é€£ç¶šã—ãŸè¡Œã‚’ç´ æ—©ãé¸æŠ | ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹: é£›ã³é£›ã³ã®è¡Œã‚’è‡ªç”±ã«é¸æŠ",
                                    key=f"batch_embedding_selection_mode_{selected_file_name}_{tab_idx}"
                                )

                                st.divider()

                                st.subheader("1ï¸âƒ£ éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠ")

                                if selection_mode == "ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰":
                                    embedding_row_labels = _create_row_labels(target_df)
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        start_row = st.selectbox(
                                            "é–‹å§‹è¡Œã‚’é¸æŠ",
                                            options=range(len(target_df)),
                                            format_func=lambda x: embedding_row_labels[x],
                                            key=f"batch_embedding_start_row_{selected_file_name}_{tab_idx}"
                                        )
                                    with col2:
                                        end_row = st.selectbox(
                                            "çµ‚äº†è¡Œã‚’é¸æŠ",
                                            options=range(len(target_df)),
                                            format_func=lambda x: embedding_row_labels[x],
                                            index=len(target_df) - 1 if len(target_df) > 0 else 0,
                                            key=f"batch_embedding_end_row_{selected_file_name}_{tab_idx}"
                                        )

                                    if start_row > end_row:
                                        st.error("âš ï¸ é–‹å§‹è¡Œã¯çµ‚äº†è¡Œä»¥å‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
                                        embedding_state['selected_rows'] = set()
                                    else:
                                        embedding_state['selected_rows'] = set(range(start_row, end_row + 1))
                                        st.success(f"âœ… è¡Œ {start_row} ï½ {end_row} ã‚’é¸æŠã—ã¾ã—ãŸ")
                                else:
                                    display_df = target_df.copy()
                                    display_df.insert(0, "é¸æŠ", False)

                                    if embedding_state['selected_rows']:
                                        for idx in embedding_state['selected_rows']:
                                            if idx in display_df.index:
                                                display_df.at[idx, "é¸æŠ"] = True

                                    disabled_columns = [col for col in ["start", "end", "speaker", "text"] if col in display_df.columns]

                                    edited_display = st.data_editor(
                                        display_df,
                                        column_config={
                                            "é¸æŠ": st.column_config.CheckboxColumn(
                                                "é¸æŠ",
                                                help="åŸ‹ã‚è¾¼ã¿ä½œæˆå¯¾è±¡ã®è¡Œã‚’ãƒã‚§ãƒƒã‚¯",
                                                default=False
                                            )
                                        },
                                        disabled=disabled_columns,
                                        use_container_width=True,
                                        hide_index=True,
                                        key=f"batch_embedding_data_editor_{selected_file_name}_{tab_idx}"
                                    )

                                    embedding_state['selected_rows'] = set(
                                        edited_display[edited_display["é¸æŠ"] == True].index.tolist()
                                    )

                                selected_rows = embedding_state['selected_rows']

                                if selected_rows:
                                    st.subheader("2ï¸âƒ£ é¸æŠæƒ…å ±ã®ç¢ºèª")

                                    selection_summary = get_selection_summary(target_df, selected_rows)

                                    info_cols = st.columns(4)
                                    with info_cols[0]:
                                        st.metric("é¸æŠè¡Œæ•°", selection_summary['count'])
                                    with info_cols[1]:
                                        st.metric("é–‹å§‹æ™‚åˆ»", format_time(selection_summary['start_time']))
                                    with info_cols[2]:
                                        st.metric("çµ‚äº†æ™‚åˆ»", format_time(selection_summary['end_time']))
                                    with info_cols[3]:
                                        st.metric("éŸ³å£°é•·", f"{selection_summary['duration']:.1f}ç§’")

                                    if selection_summary['speakers']:
                                        speakers_text = "ã€".join([s if s else "ä¸æ˜" for s in selection_summary['speakers']])
                                        st.info(f"ğŸ¤ é¸æŠç¯„å›²ã«å«ã¾ã‚Œã‚‹è©±è€…: {speakers_text}")

                                    st.subheader("3ï¸âƒ£ éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

                                    col_preview, col_clear = st.columns([3, 1])

                                    with col_preview:
                                        if st.button("ğŸ”Š ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆ", key=f"batch_generate_preview_{selected_file_name}_{tab_idx}"):
                                            try:
                                                with st.spinner("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                                                    audio_io = BytesIO(selected_file_info['data'].getvalue())
                                                    preview_bytes, duration = prepare_embedding_preview_audio(
                                                        audio_io,
                                                        target_df,
                                                        sorted(selected_rows)
                                                    )
                                                    embedding_state['preview_audio'] = preview_bytes
                                                    embedding_state['show_preview'] = True
                                                st.success(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆ{duration:.1f}ç§’ï¼‰")
                                            except Exception as e:
                                                st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

                                    with col_clear:
                                        if embedding_state.get('show_preview'):
                                            if st.button("âŒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢", key=f"batch_clear_preview_{selected_file_name}_{tab_idx}"):
                                                embedding_state['preview_audio'] = None
                                                embedding_state['show_preview'] = False
                                                st.rerun()

                                    if embedding_state.get('show_preview') and embedding_state.get('preview_audio'):
                                        st.audio(embedding_state['preview_audio'], format="audio/wav")

                                    st.subheader("4ï¸âƒ£ ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š")

                                    embedding_filename = st.text_input(
                                        "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ.npyæ‹¡å¼µå­ã¯è‡ªå‹•è¿½åŠ ï¼‰",
                                        value="speaker_embedding",
                                        key=f"batch_embedding_filename_{selected_file_name}_{tab_idx}",
                                        help="ä½œæˆã™ã‚‹è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
                                    )

                                    st.subheader("5ï¸âƒ£ åŸ‹ã‚è¾¼ã¿ä½œæˆ")

                                    if st.button("âœ¨ è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key=f"batch_create_embedding_{selected_file_name}_{tab_idx}", type="primary"):
                                        with st.spinner("è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆä¸­..."):
                                            try:
                                                audio_io = BytesIO(selected_file_info['data'].getvalue())
                                                embedding, duration = extract_audio_segment_for_embedding(
                                                    audio_io,
                                                    target_df,
                                                    sorted(selected_rows)
                                                )

                                                filename_with_ext = embedding_filename if embedding_filename.endswith('.npy') else f"{embedding_filename}.npy"

                                                embedding_io = BytesIO()
                                                np.save(embedding_io, embedding)
                                                embedding_io.seek(0)

                                                embedding_bytes = embedding_io.getvalue()

                                                st.success(f"âœ… è©±è€…åŸ‹ã‚è¾¼ã¿ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆéŸ³å£°é•·: {duration:.1f}ç§’ï¼‰")
                                                trigger_auto_download(
                                                    embedding_bytes,
                                                    filename_with_ext,
                                                    key=f"batch_download_embedding_{selected_file_name}_{tab_idx}",
                                                    mime="application/octet-stream"
                                                )

                                            except Exception as e:
                                                st.error(f"âŒ è©±è€…åŸ‹ã‚è¾¼ã¿ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                                                import traceback
                                                with st.expander("ğŸ” è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                                                    st.code(traceback.format_exc())
                                else:
                                    if selection_mode == "ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰":
                                        st.info("ğŸ’¡ ä¸Šè¨˜ã®selectboxã§é–‹å§‹è¡Œã¨çµ‚äº†è¡Œã‚’é¸æŠã—ã¦ãã ã•ã„")
                                    else:
                                        st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§åŸ‹ã‚è¾¼ã¿ä½œæˆå¯¾è±¡ã®è¡Œã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„")

                    # è©±è€…è­˜åˆ¥çµæœã®ç¢ºèª
                    if 'identified_df' in result:
                        st.success("âœ… ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®è©±è€…è­˜åˆ¥ã¯å®Œäº†ã—ã¦ã„ã¾ã™")
                else:
                    st.warning("âš ï¸ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã¾ã æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“")

        st.divider()

        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çŠ¶æ³ä¸€è¦§
        st.write("**å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çŠ¶æ³**")
        status_df = pd.DataFrame([
            {
                'ãƒ•ã‚¡ã‚¤ãƒ«å': f['name'],
                'æ–‡å­—èµ·ã“ã—': 'âœ…' if st.session_state.batch_processing_status.get(f['name'], {}).get('transcription') == 'completed' else 'âŒ',
                'è©±è€…è­˜åˆ¥': 'âœ…' if st.session_state.batch_processing_status.get(f['name'], {}).get('speaker_id') == 'completed' else 'â­ï¸'
            }
            for f in st.session_state.batch_extracted_files
        ])
        st.dataframe(status_df, use_container_width=True, hide_index=True)

        st.divider()

        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸
        if st.button("â¡ï¸ RAGæ ¡æ­£ã¸é€²ã‚€", key="proceed_to_rag", type="primary"):
            st.session_state.batch_current_step = 4
            st.rerun()

    # Step 4: RAGæ ¡æ­£
    if st.session_state.batch_current_step >= 4:
        st.subheader("Step 4: RAGæ ¡æ­£")
        st.write("å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—çµæœï¼ˆã¾ãŸã¯è©±è€…è­˜åˆ¥çµæœï¼‰ã«å¯¾ã—ã¦RAGæ ¡æ­£ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")

        # RAGæ ¡æ­£è¨­å®š
        col1, col2 = st.columns(2)

        with col1:
            # RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
            if st.session_state.batch_rag_system is None:
                st.session_state.batch_rag_system = _init_rag_system()

            rag_system = st.session_state.batch_rag_system

            # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿
            st.write("**ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹è¨­å®š**")

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã®è‡ªå‹•èª­ã¿è¾¼ã¿
            default_ragdb_path = get_default_ragdb_path()
            if os.path.exists(default_ragdb_path) and rag_system.vectorstore is None:
                with st.spinner("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                    try:
                        rag_system.load_knowledge_base(str(default_ragdb_path))
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã‚’æ›´æ–°
                        st.session_state.batch_db_info = rag_system.get_database_info()
                        st.success(f"âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                    except Exception as e:
                        st.warning(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆDBã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã‚’å¸¸ã«æœ€æ–°ã®çŠ¶æ…‹ã«æ›´æ–°
            st.session_state.batch_db_info = rag_system.get_database_info()

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹è¡¨ç¤º
            _render_database_status(st.session_state.batch_db_info)

            # åˆ¥ã®RAGDBãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
            uploaded_ragdb = st.file_uploader(
                "ã¾ãŸã¯åˆ¥ã®.ragdbãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿",
                type=["ragdb"],
                key="batch_ragdb_upload_step4"
            )

            if uploaded_ragdb and st.button("RAGDBã‚’èª­ã¿è¾¼ã‚€", key="batch_load_ragdb_step4"):
                with st.spinner("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                    try:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".ragdb") as temp_file:
                            temp_file.write(uploaded_ragdb.read())
                            temp_ragdb_path = temp_file.name

                        rag_system.load_knowledge_base(temp_ragdb_path)
                        os.unlink(temp_ragdb_path)
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã‚’æ›´æ–°
                        st.session_state.batch_db_info = rag_system.get_database_info()
                        st.success("âœ… ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

        with col2:
            # RAGæ ¡æ­£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            st.write("**RAGæ ¡æ­£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**")

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ
            prompt_loader = get_default_loader()
            presets = prompt_loader.get_preset_list('rag_proofreading')
            preset_options = {p['id']: f"{p['name']} - {p['description']}" for p in presets}

            selected_preset = st.selectbox(
                "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆ",
                options=list(preset_options.keys()),
                format_func=lambda x: preset_options[x],
                index=0,
                key="batch_rag_preset_step4"
            )

            search_type = st.selectbox(
                "æ¤œç´¢ã‚¿ã‚¤ãƒ—",
                options=["similarity", "mmr"],
                index=0,
                key="batch_search_type_step4",
                help="similarity: é¡ä¼¼åº¦æ¤œç´¢ | mmr: å¤šæ§˜æ€§è€ƒæ…®æ¤œç´¢"
            )

            llm_model = st.selectbox(
                "LLMãƒ¢ãƒ‡ãƒ«",
                options=["gpt-4o", "gpt-4o-mini"],
                index=1,
                key="batch_llm_model_step4"
            )

            top_k = st.slider(
                "æ¤œç´¢ã™ã‚‹é–¢é€£æ–‡è„ˆã®æ•°",
                min_value=1,
                max_value=10,
                value=6,
                key="batch_top_k_step4"
            )

        st.divider()

        # RAGæ ¡æ­£å®Ÿè¡Œ
        if rag_system.vectorstore is not None:
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ“š RAGæ ¡æ­£ã‚’é–‹å§‹", key="batch_start_rag", type="primary"):
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    total_files = len(st.session_state.batch_extracted_files)
                    processed = 0
                    errors = 0

                    for idx, file_info in enumerate(st.session_state.batch_extracted_files):
                        file_name = file_info['name']
                        result = st.session_state.batch_processing_results.get(file_name, {})

                        status_text.write(f"**RAGæ ¡æ­£ä¸­: {file_name}** ({idx + 1}/{total_files})")

                        try:
                            # è©±è€…è­˜åˆ¥æ¸ˆã¿ãªã‚‰ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°æ–‡å­—èµ·ã“ã—çµæœã‚’ä½¿ç”¨
                            if 'identified_df' in result:
                                df = result['identified_df']
                            elif 'transcription_df' in result:
                                df = result['transcription_df']
                            else:
                                st.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {file_name}ï¼ˆæ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
                                continue

                            meeting_text = build_meeting_text_from_dataframe(df)
                            st.session_state.batch_processing_results.setdefault(file_name, {})['meeting_text'] = meeting_text

                            # RAGæ ¡æ­£å®Ÿè¡Œ
                            st.session_state.batch_processing_status[file_name]['rag_proofread'] = 'processing'

                            proofread_result = rag_system.rag_enhanced_proofread(
                                meeting_text,
                                search_type=search_type,
                                top_k=top_k,
                                model=llm_model,
                                prompt_preset=selected_preset
                            )

                            st.session_state.batch_processing_results[file_name]['proofread_text'] = proofread_result
                            st.session_state.batch_processing_status[file_name]['rag_proofread'] = 'completed'
                            st.success(f"âœ… RAGæ ¡æ­£å®Œäº†: {file_name}")
                            processed += 1

                        except Exception as e:
                            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {file_name} - {e}")
                            st.session_state.batch_processing_status[file_name]['rag_proofread'] = 'error'
                            errors += 1
                            import traceback
                            st.error(traceback.format_exc())

                        progress_bar.progress((idx + 1) / total_files)

                    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    if errors == 0:
                        status_text.write(f"âœ… **RAGæ ¡æ­£å®Œäº†ï¼ ({processed}/{total_files}ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†)**")
                        st.session_state.batch_current_step = 5
                        st.balloons()
                        st.rerun()
                    else:
                        status_text.write(f"âš ï¸ **RAGæ ¡æ­£å®Œäº†ï¼ˆã‚¨ãƒ©ãƒ¼ã‚ã‚Šï¼‰: æˆåŠŸ {processed}ä»¶ / ã‚¨ãƒ©ãƒ¼ {errors}ä»¶**")
                        st.warning("âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚ä¸Šè¨˜ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        st.info("ğŸ’¡ ä¿®æ­£å¾Œã€å†åº¦ã€ŒRAGæ ¡æ­£ã‚’é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã‹ã€ã€ŒRAGæ ¡æ­£ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã¸ã€ã§é€²ã‚“ã§ãã ã•ã„ã€‚")

            with col2:
                if st.button("ğŸ”„ RAGæ ¡æ­£ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã¸", key="skip_rag"):
                    st.session_state.batch_current_step = 5
                    st.rerun()
        else:
            st.warning("âš ï¸ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚RAGæ ¡æ­£ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å ´åˆã¯ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
            if st.button("ğŸ”„ RAGæ ¡æ­£ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã¸", key="skip_rag_no_kb"):
                st.session_state.batch_current_step = 5
                st.rerun()

    # Step 5: å‡¦ç†çµæœã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if st.session_state.batch_current_step >= 5:
        st.subheader("Step 5: å‡¦ç†çµæœã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

        # å‡¦ç†çŠ¶æ…‹ã‚µãƒãƒªãƒ¼
        st.write("**å‡¦ç†çŠ¶æ…‹ã‚µãƒãƒªãƒ¼**")
        status_summary = []
        for file_name, status in st.session_state.batch_processing_status.items():
            status_summary.append({
                'ãƒ•ã‚¡ã‚¤ãƒ«å': file_name,
                'æ–‡å­—èµ·ã“ã—': 'âœ…' if status['transcription'] == 'completed' else 'âŒ' if status['transcription'] == 'error' else 'â­ï¸',
                'è©±è€…è­˜åˆ¥': 'âœ…' if status['speaker_id'] == 'completed' else 'âŒ' if status['speaker_id'] == 'error' else 'â­ï¸',
                'RAGæ ¡æ­£': 'âœ…' if status['rag_proofread'] == 'completed' else 'âŒ' if status['rag_proofread'] == 'error' else 'â­ï¸'
            })

        st.dataframe(pd.DataFrame(status_summary), use_container_width=True, hide_index=True)

        st.divider()

        # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœè¡¨ç¤º
        st.write("**å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœ**")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚¿ãƒ–ã‚’ä½œæˆ
        file_names = [f['name'] for f in st.session_state.batch_extracted_files]
        file_tabs = st.tabs(file_names)

        for tab_idx, (file_tab, file_info) in enumerate(zip(file_tabs, st.session_state.batch_extracted_files)):
            with file_tab:
                selected_file = file_info['name']

                if selected_file in st.session_state.batch_processing_results:
                    result = st.session_state.batch_processing_results[selected_file]

                    content_tab1, content_tab2, content_tab3 = st.tabs(["ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ", "ğŸ¤ è©±è€…è­˜åˆ¥çµæœ", "ğŸ“š RAGæ ¡æ­£çµæœ"])

                    with content_tab1:
                        if 'transcription_df' in result:
                            st.dataframe(result['transcription_df'], use_container_width=True)

                            # Excelå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            excel_buffer = BytesIO()
                            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                result['transcription_df'].to_excel(writer, index=False, sheet_name='æ–‡å­—èµ·ã“ã—')
                            excel_buffer.seek(0)

                            st.download_button(
                                label="ğŸ“¥ Excelå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=excel_buffer,
                                file_name=f"{os.path.splitext(selected_file)[0]}_transcription.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key=f"download_excel_{selected_file}_{tab_idx}"
                            )
                        else:
                            st.info("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“")

                    with content_tab2:
                        meeting_text = result.get('meeting_text')
                        if not meeting_text:
                            source_df = result.get('identified_df') or result.get('transcription_df')
                            meeting_text = build_meeting_text_from_dataframe(source_df) if source_df is not None else ""
                            if meeting_text:
                                st.session_state.batch_processing_results[selected_file]['meeting_text'] = meeting_text

                        if meeting_text:
                            st.text_area(
                                "è­°äº‹éŒ²å½¢å¼ãƒ†ã‚­ã‚¹ãƒˆ",
                                meeting_text,
                                height=400,
                                key=f"meeting_text_view_{selected_file}_{tab_idx}"
                            )

                            doc = DocxDocument()
                            doc.add_heading(f'è­°äº‹éŒ²: {selected_file}', level=1)
                            for line in meeting_text.splitlines():
                                doc.add_paragraph(line)

                            docx_buffer = BytesIO()
                            doc.save(docx_buffer)
                            docx_buffer.seek(0)

                            st.download_button(
                                label="ğŸ“¥ è­°äº‹éŒ²ï¼ˆWordï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=docx_buffer,
                                file_name=f"{os.path.splitext(selected_file)[0]}_minutes.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                key=f"download_docx_{selected_file}_{tab_idx}"
                            )
                        else:
                            st.info("è­°äº‹éŒ²å½¢å¼ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆè©±è€…è­˜åˆ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå ´åˆã¯Step 2ã®çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")

                    with content_tab3:
                        if 'proofread_text' in result:
                            st.text_area(
                                "æ ¡æ­£å¾Œãƒ†ã‚­ã‚¹ãƒˆ",
                                value=result['proofread_text'],
                                height=400,
                                key=f"proofread_view_{selected_file}_{tab_idx}"
                            )

                            # Wordå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            doc = DocxDocument()
                            doc.add_heading(f'æ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²: {selected_file}', level=1)
                            doc.add_paragraph(result['proofread_text'])

                            docx_buffer = BytesIO()
                            doc.save(docx_buffer)
                            docx_buffer.seek(0)

                            st.download_button(
                                label="ğŸ“¥ æ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²ï¼ˆWordï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=docx_buffer,
                                file_name=f"{os.path.splitext(selected_file)[0]}_proofread.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                key=f"download_proofread_{selected_file}_{tab_idx}"
                            )
                        else:
                            st.info("RAGæ ¡æ­£çµæœãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰")
                else:
                    st.info("ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“")

        st.divider()

        # ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
        st.write("**ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**")
        st.write("ã™ã¹ã¦ã®å‡¦ç†çµæœã‚’ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")

        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("ğŸ“¦ ZIPã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="batch_download_all", use_container_width=True):
                with st.spinner("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                    try:
                        zip_buffer = BytesIO()

                        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                            for file_name, result in st.session_state.batch_processing_results.items():
                                base_name = os.path.splitext(file_name)[0]

                                # æ–‡å­—èµ·ã“ã—çµæœï¼ˆExcelï¼‰
                                if 'transcription_df' in result:
                                    excel_buffer = BytesIO()
                                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                        result['transcription_df'].to_excel(writer, index=False, sheet_name='æ–‡å­—èµ·ã“ã—')
                                    excel_buffer.seek(0)
                                    zip_file.writestr(f"{base_name}_transcription.xlsx", excel_buffer.read())

                                # è©±è€…è­˜åˆ¥çµæœï¼ˆWordï¼‰
                                if 'identified_df' in result:
                                    doc = DocxDocument()
                                    doc.add_heading(f'è­°äº‹éŒ²: {file_name}', level=1)

                                    # é€£ç¶šã™ã‚‹åŒã˜è©±è€…ã®ç™ºè¨€ã‚’çµåˆ
                                    df = result['identified_df'].copy()
                                    df['speaker_filled'] = df['speaker'].replace('', pd.NA)
                                    df['speaker_filled'] = df['speaker_filled'].ffill()
                                    df['group_id'] = (df['speaker_filled'] != df['speaker_filled'].shift()).cumsum()
                                    df_merged = df.groupby('group_id').agg(
                                        speaker=('speaker_filled', 'first'),
                                        text=('text', ' '.join)
                                    ).reset_index(drop=True)

                                    for _, row in df_merged.iterrows():
                                        speaker = row.get('speaker', 'ä¸æ˜')
                                        text = row.get('text', '')
                                        speaker_str = speaker if speaker else 'ä¸æ˜'
                                        doc.add_paragraph(f"ï¼ˆ{speaker_str}ï¼‰{text}")

                                    docx_buffer = BytesIO()
                                    doc.save(docx_buffer)
                                    docx_buffer.seek(0)
                                    zip_file.writestr(f"{base_name}_minutes.docx", docx_buffer.read())

                                # RAGæ ¡æ­£çµæœï¼ˆWordï¼‰
                                if 'proofread_text' in result:
                                    doc = DocxDocument()
                                    doc.add_heading(f'æ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²: {file_name}', level=1)
                                    doc.add_paragraph(result['proofread_text'])
                                    docx_buffer = BytesIO()
                                    doc.save(docx_buffer)
                                    docx_buffer.seek(0)
                                    zip_file.writestr(f"{base_name}_proofread.docx", docx_buffer.read())

                        zip_buffer.seek(0)

                        trigger_auto_download(
                            zip_buffer.getvalue(),
                            file_name=f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                            key="batch_final_download",
                            mime="application/zip"
                        )

                        st.success("âœ… ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                    except Exception as e:
                        st.error(f"âŒ ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        import traceback
                        st.error(traceback.format_exc())

        with col2:
            if st.button("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœWordã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="batch_download_transcription_word", use_container_width=True):
                with st.spinner("Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                    try:
                        # 1ã¤ã®Wordãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
                        doc = DocxDocument()
                        doc.add_heading('æ–‡å­—èµ·ã“ã—çµæœï¼ˆä¸€æ‹¬ï¼‰', level=0)
                        doc.add_paragraph(f'ä½œæˆæ—¥æ™‚: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}')
                        doc.add_paragraph('')

                        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœã‚’è¿½åŠ 
                        for idx, (file_name, result) in enumerate(st.session_state.batch_processing_results.items(), 1):
                            # ãƒ•ã‚¡ã‚¤ãƒ«è¦‹å‡ºã—
                            doc.add_heading(f'{idx}. {file_name}', level=1)
                            doc.add_paragraph('')

                            base_df = result.get('identified_df')
                            if base_df is None or base_df.empty:
                                fallback_df = result.get('transcription_df')
                                base_df = fallback_df if fallback_df is not None else None
                            meeting_text = result.get('meeting_text')
                            if meeting_text is None and base_df is not None and not base_df.empty:
                                meeting_text = build_meeting_text_from_dataframe(base_df)
                                if meeting_text:
                                    st.session_state.batch_processing_results[file_name]['meeting_text'] = meeting_text

                            if meeting_text:
                                doc.add_heading('è­°äº‹éŒ²ï¼ˆè©±è€…è­˜åˆ¥çµæœï¼‰', level=2)
                                for line in meeting_text.splitlines():
                                    if line.strip():
                                        doc.add_paragraph(line)
                            else:
                                doc.add_paragraph('ï¼ˆæ–‡å­—èµ·ã“ã—çµæœãªã—ï¼‰')

                            doc.add_paragraph('')

                            # ãƒ•ã‚¡ã‚¤ãƒ«é–“ã®åŒºåˆ‡ã‚Š
                            if idx < len(st.session_state.batch_processing_results):
                                doc.add_page_break()

                        # Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                        docx_buffer = BytesIO()
                        doc.save(docx_buffer)
                        docx_buffer.seek(0)

                        trigger_auto_download(
                            docx_buffer.getvalue(),
                            file_name=f"batch_transcription_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                            key="batch_final_download_transcription_word",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )

                        st.success("âœ… Wordãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                    except Exception as e:
                        st.error(f"âŒ Wordãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        import traceback
                        st.error(traceback.format_exc())

        with col3:
            if st.button("ğŸ“š RAGæ ¡æ­£çµæœWordã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="batch_download_rag_word", use_container_width=True):
                with st.spinner("Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                    try:
                        # 1ã¤ã®Wordãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
                        doc = DocxDocument()
                        doc.add_heading('RAGæ ¡æ­£çµæœï¼ˆä¸€æ‹¬ï¼‰', level=0)
                        doc.add_paragraph(f'ä½œæˆæ—¥æ™‚: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}')
                        doc.add_paragraph('')

                        # RAGæ ¡æ­£çµæœãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
                        rag_count = 0
                        for idx, (file_name, result) in enumerate(st.session_state.batch_processing_results.items(), 1):
                            if 'proofread_text' in result:
                                rag_count += 1
                                # ãƒ•ã‚¡ã‚¤ãƒ«è¦‹å‡ºã—
                                doc.add_heading(f'{rag_count}. {file_name}', level=1)
                                doc.add_paragraph('')

                                # RAGæ ¡æ­£çµæœ
                                doc.add_heading('æ ¡æ­£æ¸ˆã¿è­°äº‹éŒ²', level=2)
                                # æ®µè½ã”ã¨ã«åˆ†å‰²ã—ã¦è¿½åŠ 
                                for paragraph in result['proofread_text'].split('\n'):
                                    if paragraph.strip():
                                        doc.add_paragraph(paragraph)
                                doc.add_paragraph('')

                                # ãƒ•ã‚¡ã‚¤ãƒ«é–“ã®åŒºåˆ‡ã‚Šï¼ˆæœ€å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ä»¥å¤–ï¼‰
                                if rag_count < sum(1 for r in st.session_state.batch_processing_results.values() if 'proofread_text' in r):
                                    doc.add_page_break()

                        if rag_count == 0:
                            doc.add_paragraph('ï¼ˆRAGæ ¡æ­£çµæœãŒã‚ã‚Šã¾ã›ã‚“ï¼‰')

                        # Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                        docx_buffer = BytesIO()
                        doc.save(docx_buffer)
                        docx_buffer.seek(0)

                        trigger_auto_download(
                            docx_buffer.getvalue(),
                            file_name=f"batch_rag_proofread_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                            key="batch_final_download_rag_word",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )

                        st.success("âœ… Wordãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                    except Exception as e:
                        st.error(f"âŒ Wordãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        import traceback
                        st.error(traceback.format_exc())


def video_to_audio_cutter_app():
    st.title("å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—MP3ã§ä¿å­˜")
    st.write("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ‡ã‚Šå‡ºã—ãŸã„é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚è¤‡æ•°ã®åŒºé–“ã‚’åˆ‡ã‚Šå‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚")

    uploaded_video = st.file_uploader("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["wav","mp3","mp4", "mov", "avi", "mkv", "webm"])

    if uploaded_video is not None:
        st.video(uploaded_video)

        st.subheader("åˆ‡ã‚Šå‡ºã—åŒºé–“ã®è¨­å®š")
        # Use st.data_editor for multiple time range inputs
        # Default for the first row includes segment_1
        default_data = pd.DataFrame([
            {"é–‹å§‹æ™‚é–“": "00:00:00", "çµ‚äº†æ™‚é–“": "00:00:30", "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å": f"{os.path.splitext(uploaded_video.name)[0]}_"}
        ])
        edited_df = st.data_editor(
            default_data,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "é–‹å§‹æ™‚é–“": st.column_config.TextColumn(
                    "é–‹å§‹æ™‚é–“ (HH:MM:SS or seconds)",
                    help="åˆ‡ã‚Šå‡ºã—é–‹å§‹æ™‚é–“ (ä¾‹: 00:00:10 ã¾ãŸã¯ 10)",
                    default="00:00:00"
                ),
                "çµ‚äº†æ™‚é–“": st.column_config.TextColumn(
                    "çµ‚äº†æ™‚é–“ (HH:MM:SS or seconds)",
                    help="åˆ‡ã‚Šå‡ºã—çµ‚äº†æ™‚é–“ (ä¾‹: 00:00:30 ã¾ãŸã¯ 30)",
                    default="00:00:30"
                ),
                "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å": st.column_config.TextColumn(
                    "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å (.mp3)",
                    help="ã“ã®åŒºé–“ã®MP3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: my_audio_segment.mp3)ã€‚'AUTO_GENERATE'ã¨å…¥åŠ›ã™ã‚‹ã‹ç©ºæ¬„ã®å ´åˆã€è‡ªå‹•ã§é€£ç•ªãŒæŒ¯ã‚‰ã‚Œã¾ã™ã€‚",
                    default=f"{os.path.splitext(uploaded_video.name)[0]}_" # Explicit placeholder for new rows
                )
            }
        )

        if st.button("éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—ã¦MP3ã§ä¿å­˜"):
            if edited_df.empty:
                st.warning("åˆ‡ã‚Šå‡ºã—åŒºé–“ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return

            temp_video_path = ""
            output_audio_paths = [] # List to store paths of all generated MP3s
            zip_buffer = BytesIO()

            try:
                # Save uploaded video to a temporary file
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_video.name.split('.')[-1]}") as temp_video_file:
                    temp_video_file.write(uploaded_video.read())
                    temp_video_path = temp_video_file.name

                with st.spinner("éŸ³å£°ã®åˆ‡ã‚Šå‡ºã—ã¨MP3ã¸ã®å¤‰æ›ä¸­..."):
                    for index, row in edited_df.iterrows():
                        start_time_str = str(row["é–‹å§‹æ™‚é–“"])
                        end_time_str = str(row["çµ‚äº†æ™‚é–“"])
                        output_filename_raw = str(row["å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å"]).strip()

                        try:
                            start_seconds = parse_time_to_seconds(start_time_str)
                            end_seconds = parse_time_to_seconds(end_time_str)

                            if start_seconds >= end_seconds:
                                st.error(f"åŒºé–“ {index+1}: é–‹å§‹æ™‚é–“ ({start_time_str}) ã¯çµ‚äº†æ™‚é–“ ({end_time_str}) ã‚ˆã‚Šå‰ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚ã“ã®åŒºé–“ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
                                continue

                            # If output filename is empty or matches the explicit placeholder, generate one with index
                            base_name_from_video = os.path.splitext(uploaded_video.name)[0]

                            if not output_filename_raw or output_filename_raw.upper() == "AUTO_GENERATE":
                                output_filename_to_use = f"{base_name_from_video}_segment_{index+1}.mp3"
                            else:
                                output_filename_to_use = output_filename_raw

                            # Ensure the output filename ends with .mp3
                            if not output_filename_to_use.lower().endswith(".mp3"):
                                output_filename_to_use += ".mp3"

                            output_audio_path = os.path.join(tempfile.gettempdir(), output_filename_to_use)

                            command = [
                                "ffmpeg",
                                "-i", temp_video_path,
                                "-ss", format_time(start_seconds),
                                "-to", format_time(end_seconds),
                                "-vn",  # No video
                                "-ab", "192k", # Audio bitrate
                                "-map_metadata", "-1", # Remove metadata
                                "-y", # Overwrite output files without asking
                                output_audio_path
                            ]

                            st.info(f"åŒºé–“ {index+1} FFmpegã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œä¸­: {' '.join(command)}")

                            process = subprocess.run(command, capture_output=True, text=True, encoding="utf-8", check=True)
                            st.success(f"åŒºé–“ {index+1} ã®éŸ³å£°åˆ‡ã‚Šå‡ºã—ã¨MP3ã¸ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            st.code(process.stdout)
                            st.code(process.stderr)
                            output_audio_paths.append(output_audio_path)

                        except subprocess.CalledProcessError as e:
                            st.error(f"åŒºé–“ {index+1} FFmpegã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                            st.code(e.stdout)
                            st.code(e.stderr)
                            st.warning("FFmpegãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã€PATHãŒé€šã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        except ValueError as e:
                            st.error(f"åŒºé–“ {index+1} æ™‚é–“å½¢å¼ã‚¨ãƒ©ãƒ¼: {e}")
                        except Exception as e:
                            st.error(f"åŒºé–“ {index+1} å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

                if output_audio_paths:
                    st.subheader("ç”Ÿæˆã•ã‚ŒãŸMP3ãƒ•ã‚¡ã‚¤ãƒ«")
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                        for audio_path in output_audio_paths:
                            if os.path.exists(audio_path):
                                zf.write(audio_path, os.path.basename(audio_path))
                                st.write(f"- {os.path.basename(audio_path)}")
                    zip_buffer.seek(0)

                    st.download_button(
                        label="å…¨ã¦ã®MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)",
                        data=zip_buffer,
                        file_name=f"{os.path.splitext(uploaded_video.name)[0]}_cut_audios.zip",
                        mime="application/zip"
                    )
                else:
                    st.warning("åˆ‡ã‚Šå‡ºã•ã‚ŒãŸMP3ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

            except Exception as e:
                st.error(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            finally:
                # Clean up temporary files
                if os.path.exists(temp_video_path):
                    os.remove(temp_video_path)
                for audio_path in output_audio_paths:
                    if os.path.exists(audio_path):
                        os.remove(audio_path)

def _init_session_state(defaults):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def _create_row_labels(df):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰è¡Œé¸æŠç”¨ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆ"""
    labels = []
    for idx, row in df.iterrows():
        text = row.get('text', '')
        text_display = text[:30] + "..." if len(text) > 30 else text
        label = f"{idx}: {row.get('start', '')} | {row.get('end', '')} | {row.get('speaker', '')} | {text_display}"
        labels.append(label)
    return labels

def prepare_embedding_preview_audio(audio_io, df, selected_indices):
    """ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®éŸ³å£°ã‚’æº–å‚™

    Args:
        audio_io: BytesIO - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        df: DataFrame - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å«ã‚€
        selected_indices: list - é¸æŠè¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ

    Returns:
        preview_bytes: bytes - WAVå½¢å¼ã®éŸ³å£°ãƒã‚¤ãƒˆåˆ—
        duration: float - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰
    """
    if not selected_indices:
        raise ValueError("é¸æŠè¡ŒãŒã‚ã‚Šã¾ã›ã‚“")

    selected_rows = df.iloc[sorted(selected_indices)]
    start_sec = selected_rows['start'].min()
    end_sec = selected_rows['end'].max()

    audio_io.seek(0)
    with temp_file_path(audio_io.getvalue(), ".mp3") as audio_path:
        audio = AudioSegment.from_file(audio_path)

        start_ms = int(start_sec * 1000)
        end_ms = int(end_sec * 1000)
        audio_segment = audio[start_ms:end_ms]

        preview_bytes = audio_segment.export(format="wav").read()

    return preview_bytes, (end_sec - start_sec)

def extract_audio_segment_for_embedding(audio_io, df, selected_indices):
    """é¸æŠè¡Œã‹ã‚‰éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡ºã—ã¦åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆ

    Args:
        audio_io: BytesIO - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        df: DataFrame - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å«ã‚€
        selected_indices: list - é¸æŠè¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ

    Returns:
        embedding: np.ndarray - ç”Ÿæˆã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
        duration: float - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰
    """
    if not selected_indices:
        raise ValueError("é¸æŠè¡ŒãŒã‚ã‚Šã¾ã›ã‚“")

    selected_rows = df.iloc[sorted(selected_indices)]
    start_sec = selected_rows['start'].min()
    end_sec = selected_rows['end'].max()

    audio_io.seek(0)
    with temp_file_path(audio_io.getvalue(), ".mp3") as audio_path:
        audio = AudioSegment.from_file(audio_path)

        start_ms = int(start_sec * 1000)
        end_ms = int(end_sec * 1000)
        audio_segment = audio[start_ms:end_ms]

        wav_bytes = audio_segment.export(format="wav").read()

    with temp_file_path(wav_bytes, ".wav") as segment_path:
        wav = preprocess_wav(segment_path)
        encoder = load_voice_encoder()
        embedding = encoder.embed_utterance(wav)

    return embedding, (end_sec - start_sec)

def get_selection_summary(df, selected_indices):
    """é¸æŠè¡Œã®æ¦‚è¦æƒ…å ±ã‚’å–å¾—

    Args:
        df: DataFrame
        selected_indices: set or list - é¸æŠè¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

    Returns:
        dict - æ¦‚è¦æƒ…å ±
    """
    if not selected_indices:
        return {
            'count': 0,
            'start_time': None,
            'end_time': None,
            'duration': 0,
            'speakers': []
        }

    sorted_indices = sorted(selected_indices)
    selected_rows = df.iloc[sorted_indices]

    start_time = selected_rows['start'].min()
    end_time = selected_rows['end'].max()
    duration = end_time - start_time
    speakers = selected_rows['speaker'].dropna().unique().tolist() if 'speaker' in selected_rows.columns else []

    return {
        'count': len(sorted_indices),
        'start_time': start_time,
        'end_time': end_time,
        'duration': duration,
        'speakers': speakers
    }

def get_default_ragdb_path():
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆRAGDBãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—

    Returns:
        str - RAGDBãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹
    """
    if DEFAULT_RAGDB_FOLDER:
        # ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        os.makedirs(DEFAULT_RAGDB_FOLDER, exist_ok=True)
        return os.path.join(DEFAULT_RAGDB_FOLDER, "default_knowledge_base.ragdb")
    else:
        return "default_knowledge_base.ragdb"

def load_meeting_type_config():
    """ä¼šè­°ã‚¿ã‚¤ãƒ—è¨­å®šã‚’å–å¾—

    Returns:
        list - ä¼šè­°ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ
    """
    try:
        return [dict(item) for item in DEFAULT_MEETING_TYPES]
    except Exception as e:
        st.error(f"âŒ ä¼šè­°ã‚¿ã‚¤ãƒ—è¨­å®šã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def load_embeddings_from_folder(folder_path):
    """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.npyï¼‰ã‚’ä¸€æ‹¬èª­ã¿è¾¼ã¿

    Args:
        folder_path (str): è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹

    Returns:
        list - ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ãƒªã‚¹ãƒˆ [{'name': filename, 'data': file_content_bytes}, ...]
                èª­ã¿è¾¼ã‚ãªã„å ´åˆã¯ç©ºãƒªã‚¹ãƒˆ
    """
    embeddings = []

    try:
        # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
        if not os.path.isabs(folder_path):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            folder_path = os.path.join(script_dir, folder_path)

        if not os.path.exists(folder_path):
            st.warning(f"âš ï¸ è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {folder_path}")
            return []

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®.npyãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        npy_files = [f for f in os.listdir(folder_path) if f.endswith('.npy')]

        if not npy_files:
            st.info(f"ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€å†…ã«.npyãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {folder_path}")
            return []

        # å„.npyãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        for filename in npy_files:
            file_path = os.path.join(folder_path, filename)
            with open(file_path, 'rb') as f:
                file_bytes = f.read()
                embeddings.append({
                    'name': filename,
                    'data': file_bytes
                })

        return embeddings

    except Exception as e:
        st.error(f"âŒ è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def video_transcribe_and_identify():
    st.title("æ–‡å­—èµ·ã“ã—")
    st.write("éŸ³å£°ãƒ»å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã€è­°äº‹éŒ²ã‚’ä½œæˆã—ã¾ã™ã€‚")

    st.sidebar.markdown("""
    ### ğŸ“ æ–‡å­—èµ·ã“ã—

    **æ¦‚è¦**
    æ–‡å­—èµ·ã“ã—ã¨è©±è€…è­˜åˆ¥ã«å¯¾å¿œã€‚ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠå¯èƒ½ã€‚

    **ä¸»ãªæ©Ÿèƒ½**
    - AIæ–‡å­—èµ·ã“ã—: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã
    - ãƒ¢ãƒ‡ãƒ«é¸æŠå¯èƒ½:
      - gpt-4o-transcribe-diarizeï¼ˆè‡ªå‹•è©±è€…è­˜åˆ¥ä»˜ãï¼‰
      - Whisperï¼ˆå‚è€ƒè³‡æ–™å¯¾å¿œã€å¾Œã‹ã‚‰è©±è€…è­˜åˆ¥å¯èƒ½ï¼‰
    - è­°äº‹éŒ²å‡ºåŠ›: Wordãƒ»Excelå½¢å¼

    **å¯¾å¿œå½¢å¼:** MP3, WAV, M4A, MP4, WebM, OGG, MOV, AVI, MKV
    """)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    _init_session_state({
        'video_combined_step': 1,
        'video_combined_audio_io': None,
        'video_combined_df': None,
        'video_combined_identified_df': pd.DataFrame(),
        'video_combined_uploaded_file_name': "",
        # è©±è€…åŸ‹ã‚è¾¼ã¿ä½œæˆç”¨ã®çŠ¶æ…‹å¤‰æ•°
        'embedding_selected_rows': set(),
        'embedding_preview_audio': None,
        'embedding_show_preview': False
    })

    # Step 1: ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.subheader("Step 1: ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_media = st.file_uploader(
        "ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=["mp3", "wav", "m4a", "mp4", "webm", "ogg", "mov", "avi", "mkv"],
        key="video_combined_media_upload"
    )

    if uploaded_media is not None:
        st.session_state.video_combined_uploaded_file_name = uploaded_media.name
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ« '{uploaded_media.name}' ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")

        # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå‹•ç”»ã¾ãŸã¯éŸ³å£°ï¼‰
        file_extension = uploaded_media.name.split(".")[-1].lower()
        if file_extension in ["mp4", "webm", "ogg", "mov", "avi", "mkv"]:
            st.video(uploaded_media)
        else:
            st.audio(uploaded_media)

        # Step 2: æ–‡å­—èµ·ã“ã—
        st.subheader("Step 2: æ–‡å­—èµ·ã“ã—")

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        transcribe_model = st.selectbox(
            "æ–‡å­—èµ·ã“ã—ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            options=["gpt-4o-transcribe-diarize", "whisper"],
            index=1,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: whisper
            key="video_combined_model_selection",
            help="gpt-4o-transcribe-diarize: è©±è€…è­˜åˆ¥ä»˜ãï¼ˆå‚è€ƒè³‡æ–™éå¯¾å¿œï¼‰\nwhisper: è©±è€…è­˜åˆ¥ãªã—ï¼ˆå‚è€ƒè³‡æ–™å¯¾å¿œï¼‰"
        )

        # ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜
        if transcribe_model == "gpt-4o-transcribe-diarize":
            st.info("ğŸ¯ **gpt-4o-transcribe-diarize**: è‡ªå‹•è©±è€…è­˜åˆ¥ä»˜ãæ–‡å­—èµ·ã“ã—ã€‚å‚è€ƒè³‡æ–™ï¼ˆpromptï¼‰ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
        else:
            st.info("ğŸ¤ **Whisper**: æ±ç”¨éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã€‚å‚è€ƒè³‡æ–™ã‚’ä½¿ç”¨å¯èƒ½ã€‚Step 4ã§è©±è€…è­˜åˆ¥ã‚’å¾Œã‹ã‚‰å®Ÿè¡Œã§ãã¾ã™ã€‚")

        # å‚è€ƒè³‡æ–™ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        reference_file = st.file_uploader(
            "å‚è€ƒè³‡æ–™ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
            type=["pdf", "docx", "pptx", "txt", "msg"],
            key="video_combined_reference_file",
            help="æ–‡å­—èµ·ã“ã—ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®å‚è€ƒè³‡æ–™ï¼ˆWhisperã®ã¿ã‚µãƒãƒ¼ãƒˆï¼‰"
        )

        if st.button("æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ", key="video_combined_transcribe"):
            with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­..."):
                try:
                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ç”¨
                    uploaded_media.seek(0)
                    audio_file_io = BytesIO(uploaded_media.read())
                    audio_file_io.name = uploaded_media.name

                    seg_df = transcribe_audio_to_dataframe(audio_file_io, reference_file=reference_file, model=transcribe_model)

                    st.session_state.video_combined_df = seg_df
                    st.session_state.video_combined_step = 3

                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆè©±è€…è­˜åˆ¥ç”¨ï¼‰
                    uploaded_media.seek(0)
                    st.session_state.video_combined_audio_io = BytesIO(uploaded_media.read())
                    st.session_state.video_combined_audio_io.name = uploaded_media.name

                    st.success(f"æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆ{len(seg_df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ï¼‰")
                    st.rerun()
                except Exception as e:
                    st.error(f"æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    import traceback
                    st.error(traceback.format_exc())

        # Step 3: çµæœã®ç¢ºèªã¨ç·¨é›†
        if st.session_state.video_combined_step >= 3 and st.session_state.video_combined_df is not None:
            st.subheader("Step 3: çµæœã®ç¢ºèªã¨ç·¨é›†")

            if len(st.session_state.video_combined_df) > 0:
                st.write("æ–‡å­—èµ·ã“ã—çµæœã‚’ç¢ºèªãƒ»ç·¨é›†ã—ã¦ãã ã•ã„:")
                base_df = st.session_state.video_combined_df.copy()
                editable_columns = [col for col in base_df.columns if col in ("speaker",)]
                disabled_cols = [col for col in base_df.columns if col not in editable_columns]

                edited_df = st.data_editor(
                    base_df,
                    num_rows="dynamic",
                    use_container_width=True,
                    disabled=disabled_cols,
                    column_config={
                        "speaker": st.column_config.TextColumn(
                            "è©±è€…",
                            help="å¿…è¦ã«å¿œã˜ã¦è©±è€…åã‚’æ‰‹å‹•ã§èª¿æ•´ã—ã¦ãã ã•ã„"
                        )
                    },
                    key="video_combined_editor"
                )

                if isinstance(edited_df, pd.DataFrame):
                    updated_df = edited_df.copy()
                else:
                    updated_df = pd.DataFrame(edited_df)

                updated_df = updated_df.reset_index(drop=True)
                base_df = base_df.reset_index(drop=True)

                # Ensure all original columns remain
                for column in base_df.columns:
                    if column not in updated_df.columns:
                        updated_df[column] = base_df[column]
                updated_df = updated_df[base_df.columns]

                original_speaker = base_df['speaker'].astype(str).fillna("") if 'speaker' in base_df.columns else None
                updated_speaker = updated_df['speaker'].astype(str).fillna("") if 'speaker' in updated_df.columns else None

                if original_speaker is None or not updated_speaker.equals(original_speaker):
                    st.session_state.video_combined_df = updated_df
                    st.session_state.video_combined_identified_df = updated_df.copy()
                    st.info("âœï¸ è©±è€…ãƒ©ãƒ™ãƒ«ã®å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚å¿…è¦ã«å¿œã˜ã¦Step 4ä»¥é™ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã§ã™ã€‚æ–‡å­—èµ·ã“ã—å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        # Step 4: è©±è€…è­˜åˆ¥
        if st.session_state.video_combined_step >= 3 and st.session_state.video_combined_df is not None:
            st.subheader("Step 4: è©±è€…è­˜åˆ¥")

            # ã‚¿ãƒ–ã§è©±è€…è­˜åˆ¥ã¨åŸ‹ã‚è¾¼ã¿ä½œæˆã‚’åˆ†é›¢
            tab1, tab2 = st.tabs(["è©±è€…è­˜åˆ¥", "è©±è€…åŸ‹ã‚è¾¼ã¿ä½œæˆ"])

            with tab1:
                st.write("è©±è€…è­˜åˆ¥ã‚’è¡Œã†ç¯„å›²ã‚’é¸æŠã—ã¦ãã ã•ã„:")

                # æœ€æ–°ã®ç·¨é›†å†…å®¹ã‚’ä½¿ç”¨
                edited_df = st.session_state.video_combined_df.copy()

                # è­˜åˆ¥æ¸ˆã¿ã®è©±è€…æƒ…å ±ã‚’åæ˜ 
                display_df = edited_df.copy()
                if not st.session_state.video_combined_identified_df.empty:
                    if 'speaker' in st.session_state.video_combined_identified_df.columns:
                        display_df['speaker'] = st.session_state.video_combined_identified_df['speaker']

                if len(display_df) == 0:
                    st.warning("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                else:
                    row_labels = _create_row_labels(display_df)

                    col1, col2, col3 = st.columns([2, 2, 1])
                    with col1:
                        start_row = st.selectbox(
                            "é–‹å§‹è¡Œã‚’é¸æŠ",
                            options=range(len(display_df)),
                            format_func=lambda x: row_labels[x],
                            key="video_combined_start_row"
                        )
                    with col2:
                        end_row = st.selectbox(
                            "çµ‚äº†è¡Œã‚’é¸æŠ",
                            options=range(len(display_df)),
                            format_func=lambda x: row_labels[x],
                            index=len(display_df)-1 if len(display_df) > 0 else 0,
                            key="video_combined_end_row"
                        )
                    with col3:
                        similarity_threshold = st.number_input(
                            "é¡ä¼¼åº¦é–¾å€¤",
                            min_value=0.0,
                            max_value=1.0,
                            value=0.7,
                            step=0.01,
                            key="video_combined_similarity_threshold"
                        )

                    if start_row > end_row:
                        st.error("é–‹å§‹è¡Œã¯çµ‚äº†è¡Œä»¥å‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    else:
                        # è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                        uploaded_embeddings = st.file_uploader(
                            "è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                            type=["npy"],
                            accept_multiple_files=True,
                            key="video_combined_embeddings"
                        )

                        if st.button("è©±è€…è­˜åˆ¥ã‚’å®Ÿè¡Œ", key="video_combined_identify"):
                            if not uploaded_embeddings:
                                st.error("è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                            else:
                                with st.spinner("è©±è€…è­˜åˆ¥ä¸­..."):
                                    try:
                                        # é¸æŠç¯„å›²ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
                                        df_to_identify = edited_df.iloc[start_row:end_row+1].copy()

                                        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ¼ã‚¯ä½ç½®ã‚’ãƒªã‚»ãƒƒãƒˆ
                                        st.session_state.video_combined_audio_io.seek(0)

                                        # è©±è€…è­˜åˆ¥å®Ÿè¡Œ
                                        identified_df = identify_speakers_in_dataframe(
                                            st.session_state.video_combined_audio_io,
                                            df_to_identify,
                                            uploaded_embeddings,
                                            similarity_threshold
                                        )

                                        # é¸æŠç¯„å›²ã®ã¿æ›´æ–°
                                        full_identified_df = edited_df.copy()
                                        for col in identified_df.columns:
                                            full_identified_df.loc[start_row:end_row, col] = identified_df[col].values

                                        st.session_state.video_combined_identified_df = full_identified_df
                                        st.session_state.video_combined_df = full_identified_df
                                        st.session_state.video_combined_step = 5
                                        st.success("è©±è€…è­˜åˆ¥ãŒå®Œäº†ã—ã¾ã—ãŸ")
                                        st.rerun()

                                    except Exception as e:
                                        st.error(f"è©±è€…è­˜åˆ¥ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                                        import traceback
                                        st.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:")
                                        st.code(traceback.format_exc())

            with tab2:
                st.write("éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã—ã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç¢ºèªã—ã¦ã‹ã‚‰è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã§ãã¾ã™ã€‚")

                if len(edited_df) == 0:
                    st.warning("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                else:
                    # === é¸æŠæ–¹å¼ã®åˆ‡ã‚Šæ›¿ãˆ ===
                    selection_mode = st.radio(
                        "é¸æŠæ–¹å¼ã‚’é¸ã‚“ã§ãã ã•ã„",
                        options=["ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰", "ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ¼ãƒ‰"],
                        horizontal=True,
                        help="ç¯„å›²æŒ‡å®š: é€£ç¶šã—ãŸè¡Œã‚’ç´ æ—©ãé¸æŠ | ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹: é£›ã³é£›ã³ã®è¡Œã‚’è‡ªç”±ã«é¸æŠ"
                    )

                    st.divider()

                    # === Part 1: é¸æŠUIï¼ˆæ–¹å¼ã«å¿œã˜ã¦å¤‰æ›´ï¼‰ ===
                    st.subheader("1ï¸âƒ£ éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠ")

                    if selection_mode == "ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰":
                        # æ–¹å¼A: selectboxã«ã‚ˆã‚‹ç¯„å›²æŒ‡å®š
                        embedding_row_labels = _create_row_labels(edited_df)

                        col1, col2 = st.columns(2)
                        with col1:
                            embedding_start_row = st.selectbox(
                                "é–‹å§‹è¡Œã‚’é¸æŠ",
                                options=range(len(edited_df)),
                                format_func=lambda x: embedding_row_labels[x],
                                key="video_combined_embedding_start_row"
                            )
                        with col2:
                            embedding_end_row = st.selectbox(
                                "çµ‚äº†è¡Œã‚’é¸æŠ",
                                options=range(len(edited_df)),
                                format_func=lambda x: embedding_row_labels[x],
                                index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0è¡Œç›®
                                key="video_combined_embedding_end_row"
                            )

                        # ç¯„å›²æŒ‡å®šã®æ¤œè¨¼ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã¸ã®åæ˜ 
                        if embedding_start_row > embedding_end_row:
                            st.error("âš ï¸ é–‹å§‹è¡Œã¯çµ‚äº†è¡Œä»¥å‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
                            st.session_state.embedding_selected_rows = set()
                        else:
                            # ç¯„å›²ã‚’setã«å¤‰æ›
                            st.session_state.embedding_selected_rows = set(range(embedding_start_row, embedding_end_row + 1))
                            st.success(f"âœ… è¡Œ {embedding_start_row} ï½ {embedding_end_row} ã‚’é¸æŠã—ã¾ã—ãŸ")

                    else:
                        # æ–¹å¼B: data_editorã«ã‚ˆã‚‹ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹é¸æŠ
                        display_df = edited_df.copy()
                        display_df.insert(0, "é¸æŠ", False)

                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹é¸æŠè¡Œã‚’åæ˜ 
                        if st.session_state.embedding_selected_rows:
                            for idx in st.session_state.embedding_selected_rows:
                                if idx < len(display_df):
                                    display_df.at[idx, "é¸æŠ"] = True

                        edited_display = st.data_editor(
                            display_df,
                            column_config={
                                "é¸æŠ": st.column_config.CheckboxColumn(
                                    "é¸æŠ",
                                    help="åŸ‹ã‚è¾¼ã¿ä½œæˆå¯¾è±¡ã®è¡Œã‚’ãƒã‚§ãƒƒã‚¯",
                                    default=False
                                )
                            },
                            disabled=["start", "end", "speaker", "text"],
                            use_container_width=True,
                            hide_index=True,
                            key="embedding_data_editor"
                        )

                        # é¸æŠçŠ¶æ…‹ã‚’æ›´æ–°
                        st.session_state.embedding_selected_rows = set(
                            edited_display[edited_display["é¸æŠ"] == True].index.tolist()
                        )

                    # === Part 2ä»¥é™: å…±é€šå‡¦ç†ï¼ˆé¸æŠãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤ºï¼‰ ===
                    if st.session_state.embedding_selected_rows:
                        st.subheader("2ï¸âƒ£ é¸æŠæƒ…å ±ã®ç¢ºèª")

                        selection_summary = get_selection_summary(edited_df, st.session_state.embedding_selected_rows)

                        # æƒ…å ±è¡¨ç¤º
                        info_cols = st.columns(4)
                        with info_cols[0]:
                            st.metric("é¸æŠè¡Œæ•°", selection_summary['count'])
                        with info_cols[1]:
                            st.metric("é–‹å§‹æ™‚åˆ»", format_time(selection_summary['start_time']))
                        with info_cols[2]:
                            st.metric("çµ‚äº†æ™‚åˆ»", format_time(selection_summary['end_time']))
                        with info_cols[3]:
                            st.metric("éŸ³å£°é•·", f"{selection_summary['duration']:.1f}ç§’")

                        # è©±è€…æƒ…å ±ã®è¡¨ç¤º
                        if selection_summary['speakers']:
                            speakers_text = "ã€".join([s if s else "ä¸æ˜" for s in selection_summary['speakers']])
                            st.info(f"ğŸ¤ é¸æŠç¯„å›²ã«å«ã¾ã‚Œã‚‹è©±è€…: {speakers_text}")

                        # === Part 3: éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ===
                        st.subheader("3ï¸âƒ£ éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

                        col_preview, col_clear = st.columns([3, 1])

                        with col_preview:
                            if st.button("ğŸ”Š ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆ", key="generate_preview"):
                                try:
                                    with st.spinner("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                                        preview_bytes, duration = prepare_embedding_preview_audio(
                                            st.session_state.video_combined_audio_io,
                                            edited_df,
                                            list(st.session_state.embedding_selected_rows)
                                        )
                                        st.session_state.embedding_preview_audio = preview_bytes
                                        st.session_state.embedding_show_preview = True
                                    st.success(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆ{duration:.1f}ç§’ï¼‰")
                                except Exception as e:
                                    st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

                        with col_clear:
                            if st.session_state.embedding_show_preview:
                                if st.button("âŒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢", key="clear_preview"):
                                    st.session_state.embedding_preview_audio = None
                                    st.session_state.embedding_show_preview = False
                                    st.rerun()

                        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å†ç”Ÿ
                        if st.session_state.embedding_show_preview and st.session_state.embedding_preview_audio:
                            st.audio(st.session_state.embedding_preview_audio, format="audio/wav")

                        # === Part 4: ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š ===
                        st.subheader("4ï¸âƒ£ ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š")

                        embedding_filename = st.text_input(
                            "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ.npyæ‹¡å¼µå­ã¯è‡ªå‹•è¿½åŠ ï¼‰",
                            value="speaker_embedding",
                            key="video_combined_embedding_filename",
                            help="ä½œæˆã™ã‚‹è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
                        )

                        # === Part 5: ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ä½œæˆ ===
                        st.subheader("5ï¸âƒ£ åŸ‹ã‚è¾¼ã¿ä½œæˆ")

                        if st.button("âœ¨ è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="create_embedding_oneclick", type="primary"):
                            with st.spinner("è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆä¸­..."):
                                try:
                                    selected_indices = sorted(list(st.session_state.embedding_selected_rows))

                                    # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
                                    embedding, duration = extract_audio_segment_for_embedding(
                                        st.session_state.video_combined_audio_io,
                                        edited_df,
                                        selected_indices
                                    )

                                    # ãƒ•ã‚¡ã‚¤ãƒ«åå‡¦ç†
                                    filename_with_ext = embedding_filename if embedding_filename.endswith('.npy') else f"{embedding_filename}.npy"

                                    # åŸ‹ã‚è¾¼ã¿ã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›
                                    embedding_io = BytesIO()
                                    np.save(embedding_io, embedding)
                                    embedding_io.seek(0)

                                    embedding_bytes = embedding_io.getvalue()

                                    st.success(f"âœ… è©±è€…åŸ‹ã‚è¾¼ã¿ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆéŸ³å£°é•·: {duration:.1f}ç§’ï¼‰")
                                    trigger_auto_download(
                                        embedding_bytes,
                                        filename_with_ext,
                                        key="video_combined_download_embedding",
                                        mime="application/octet-stream"
                                    )

                                except Exception as e:
                                    st.error(f"âŒ è©±è€…åŸ‹ã‚è¾¼ã¿ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                                    import traceback
                                    with st.expander("ğŸ” è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                                        st.code(traceback.format_exc())

                    else:
                        if selection_mode == "ç¯„å›²æŒ‡å®šãƒ¢ãƒ¼ãƒ‰":
                            st.info("ğŸ’¡ ä¸Šè¨˜ã®selectboxã§é–‹å§‹è¡Œã¨çµ‚äº†è¡Œã‚’é¸æŠã—ã¦ãã ã•ã„")
                        else:
                            st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§åŸ‹ã‚è¾¼ã¿ä½œæˆå¯¾è±¡ã®è¡Œã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„")

        # Step 5: çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if st.session_state.video_combined_step >= 5 and not st.session_state.video_combined_identified_df.empty:
            st.subheader("Step 5: çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

            # è­°äº‹éŒ²å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆé€£ç¶šã™ã‚‹åŒã˜è©±è€…ã®ç™ºè¨€ã‚’çµåˆï¼‰
            df_for_transcript = st.session_state.video_combined_identified_df.copy()

            # è©±è€…åˆ—ã®å‰å‡¦ç†: ç©ºæ¬„ã‚’å‰å¾Œã®è©±è€…ã§åŸ‹ã‚ã‚‹
            df_for_transcript['speaker_filled'] = df_for_transcript['speaker'].replace('', pd.NA)
            df_for_transcript['speaker_filled'] = df_for_transcript['speaker_filled'].ffill()

            # è©±è€…ãŒå¤‰ã‚ã‚‹ã”ã¨ã«æ–°ã—ã„ã‚°ãƒ«ãƒ¼ãƒ—IDã‚’å‰²ã‚Šå½“ã¦ã‚‹
            df_for_transcript['group_id'] = (df_for_transcript['speaker_filled'] != df_for_transcript['speaker_filled'].shift()).cumsum()

            # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
            df_merged = df_for_transcript.groupby('group_id').agg(
                speaker=('speaker_filled', 'first'),
                text=('text', ' '.join)
            ).reset_index(drop=True)

            # è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            transcript_lines = []
            for idx, row in df_merged.iterrows():
                speaker = row.get('speaker', '')
                text = row.get('text', '')

                # Format: ï¼ˆè©±è€…ï¼‰ãƒ†ã‚­ã‚¹ãƒˆ
                speaker_str = speaker if speaker else 'ä¸æ˜'
                transcript_lines.append(f"ï¼ˆ{speaker_str}ï¼‰{text}")

            transcript_text = "\n".join(transcript_lines)

            # Wordæ–‡æ›¸ã¨ã—ã¦ç”Ÿæˆ
            doc = DocxDocument()
            doc.add_heading('è­°äº‹éŒ²', 0)

            for line in transcript_text.split('\n'):
                if line.strip():
                    doc.add_paragraph(line)
                else:
                    doc.add_paragraph('')  # ç©ºè¡Œã‚’ä¿æŒ

            docx_buffer = BytesIO()
            doc.save(docx_buffer)
            docx_buffer.seek(0)

            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label="è­°äº‹éŒ²ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=docx_buffer.getvalue(),
                    file_name=f"transcript_{st.session_state.video_combined_uploaded_file_name.split('.')[0]}.docx",
                    mime='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                    key="video_combined_download_transcript"
                )

            with col2:
                # Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ç”Ÿæˆ
                excel_buffer = BytesIO()
                with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                    st.session_state.video_combined_identified_df.to_excel(writer, index=False, sheet_name='æ–‡å­—èµ·ã“ã—')
                excel_buffer.seek(0)

                st.download_button(
                    label="Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=excel_buffer.getvalue(),
                    file_name=f"transcript_{st.session_state.video_combined_uploaded_file_name.split('.')[0]}.xlsx",
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    key="video_combined_download_excel"
                )

def main():
    st.set_page_config(
        page_title="æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒª",
        layout="wide",
        page_icon="ğŸ™ï¸",
        initial_sidebar_state="expanded"
    )

    # ã‚«ã‚¹ã‚¿ãƒ CSSã‚¹ã‚¿ã‚¤ãƒ«
    st.markdown("""
        <style>
        /* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒŠã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .main {
            background-color: #f8f9fa;
        }

        /* ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ã®èƒŒæ™¯ */
        .block-container {
            background: white;
            border-radius: 8px;
            padding: 2rem 3rem;
            margin-top: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.08);
        }

        /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        section[data-testid="stSidebar"] {
            background-color: #f8f9fa;
            border-right: 1px solid #e9ecef;
        }

        /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stButton > button {
            background-color: #4a5568;
            color: white;
            border: none;
            border-radius: 6px;
            padding: 0.5rem 1.5rem;
            font-weight: 500;
            font-size: 0.95rem;
            transition: background-color 0.2s ease;
        }

        .stButton > button:hover {
            background-color: #2d3748;
        }

        /* ãƒ—ãƒ©ã‚¤ãƒãƒªãƒœã‚¿ãƒ³ */
        .stButton > button[kind="primary"] {
            background-color: #3182ce;
        }

        .stButton > button[kind="primary"]:hover {
            background-color: #2c5282;
        }

        /* ã‚¿ã‚¤ãƒˆãƒ«ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        h1 {
            color: #1a202c;
            font-weight: 700;
            font-size: 2rem;
            padding: 0.5rem 0;
            margin-bottom: 1rem;
            border-bottom: 2px solid #e2e8f0;
        }

        /* ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        h2, h3 {
            color: #2d3748;
            font-weight: 600;
            margin-top: 1.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid #e2e8f0;
        }

        /* å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stTextInput > div > div > input,
        .stNumberInput > div > div > input,
        .stTextArea > div > div > textarea {
            border-radius: 6px;
            border: 1px solid #cbd5e0;
            padding: 0.5rem;
            transition: border-color 0.2s ease;
        }

        .stTextInput > div > div > input:focus,
        .stNumberInput > div > div > input:focus,
        .stTextArea > div > div > textarea:focus {
            border-color: #3182ce;
            box-shadow: 0 0 0 3px rgba(49, 130, 206, 0.1);
        }

        /* ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stSelectbox > div > div {
            border-radius: 6px;
            border: 1px solid #cbd5e0;
        }

        /* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stFileUploader {
            background-color: #f7fafc;
            border-radius: 8px;
            padding: 1.5rem;
            border: 2px dashed #cbd5e0;
        }

        /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
        .stDataFrame {
            border-radius: 6px;
            overflow: hidden;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.08);
        }

        /* ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ */
        .stDownloadButton > button {
            background-color: #38a169;
            color: white;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.2s ease;
        }

        .stDownloadButton > button:hover {
            background-color: #2f855a;
        }

        /* ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ */
        .stProgress > div > div > div {
            background-color: #3182ce;
        }

        /* ã‚«ãƒ©ãƒ ã®é–“éš”èª¿æ•´ */
        [data-testid="column"] {
            padding: 0.5rem;
        }

        /* ã‚¨ã‚¯ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ */
        .streamlit-expanderHeader {
            background-color: #f7fafc;
            border-radius: 6px;
            font-weight: 500;
            color: #2d3748;
        }

        /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ */
        .stSlider > div > div > div {
            background-color: #3182ce;
        }

        /* ã‚¿ãƒ– */
        .stTabs [data-baseweb="tab-list"] {
            gap: 4px;
        }

        .stTabs [data-baseweb="tab"] {
            background-color: #f7fafc;
            border-radius: 6px 6px 0 0;
            padding: 8px 16px;
            font-weight: 500;
            color: #4a5568;
        }

        .stTabs [aria-selected="true"] {
            background-color: #3182ce;
            color: white;
        }
        </style>
    """, unsafe_allow_html=True)

    st.sidebar.title("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    menu_options = [
        "æ–‡å­—èµ·ã“ã—",
        "ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†",
        "è­°äº‹éŒ²æ ¡æ­£ï¼ˆRAGï¼‰",
        "ğŸš€ ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³",
        "å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—MP3ã§ä¿å­˜"
    ]
    choice = st.sidebar.selectbox("æ©Ÿèƒ½ã‚’é¸æŠã—ã¦ãã ã•ã„", menu_options)

    if choice == "æ–‡å­—èµ·ã“ã—":
        video_transcribe_and_identify()
    elif choice == "ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†":
        knowledge_base_management()
    elif choice == "è­°äº‹éŒ²æ ¡æ­£ï¼ˆRAGï¼‰":
        proofread_meeting_minutes()
    elif choice == "ğŸš€ ä¸€æ‹¬å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³":
        batch_processing_pipeline()
    elif choice == "å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—MP3ã§ä¿å­˜":
        video_to_audio_cutter_app()

if __name__ == "__main__":
    main()
