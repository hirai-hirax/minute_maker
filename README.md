# Minute Maker

Minute Maker is an automated meeting minutes application built with FastAPI and Vite + React + TypeScript. Upload an audio or video file to transcribe, identify speakers, summarize, and download the minutes in Word or Excel format.

## Concept

Minute Maker is designed with **security as the top priority**. It is intended for deployment in private clouds or on-premises environments to satisfy strict enterprise security requirements.

### Core Design Principles

#### ğŸ”’ Secure by Design
- **No persistent meeting data**: Transcription and summary results are not stored on the server.
- **Minimized blast radius**: Reduces the risk of confidential information leakage even under cyberattacks.
- **Automatic cleanup**: Uploaded audio files can be deleted after processing.
- **Closed-network ready**: Operates even in environments isolated from the internet.

#### ğŸ¯ Reflect Organizational Know-how
- **Flexible prompt design**: Supports organization-specific minute formats and terminology.
- **Customizable summaries**: Prompt templates reflect industry practices and internal rules.
- **Extensibility**: Add or edit prompts to meet department-specific requirements.

#### ğŸ¢ Operable in Private Environments
- **On-premises friendly**: Runs entirely on self-hosted servers or dedicated clouds.
- **Selectable LLM providers**: Works with Azure OpenAI, Ollama (local LLM), and more.
- **Whisper implementation options**: Choose cloud or OSS (faster-whisper) based on your environment.

## App Overview

### Key Features
- **Audio/Video Transcription**:
  - High-accuracy transcription and speaker identification with Azure OpenAI (GPT-4o / Whisper)
  - High-speed transcription with OSS Whisper (faster-whisper)
- **Speaker Identification**: Automatic identification and speaker registration powered by SpeechBrain
- **Summary Generation**: Automatic minutes summarization using Azure OpenAI GPT-4o
- **Minutes Export**: Downloadable in Word / Excel formats
- **Speaker Management**:
  - Register and delete speakers
  - Generate and download speaker embedding files (.npy) from audio files
- **Navigation**:
  - Seamlessly switch between Minute Creation, Speaker Management, Prompt Management, and Settings
  - Preserve work when switching tabs

### Workflow
1. **File Upload**: Drag & drop MP3/WAV/MP4/M4A files
2. **Transcription**: Convert audio to text using the selected model (GPT-4o / Whisper)
3. **Speaker Identification**: Automatically identify registered speakers
4. **Review & Edit**: View/edit in table format (start/end time, speaker, text)
5. **Summarize & Format**: Select a summary prompt to generate the minutes
6. **Download**: Export as Word / Excel

## Screenshots

### Home (Minute Creation)
A simple, intuitive file upload screen.
![Home](docs/images/home.png)

### Speaker Management
Manage registered speakers and generate/download embedding files.
![Speaker Manager](docs/images/speaker_manager.png)

### Settings
Adjust LLM providers and models, Whisper options, and more.
![Settings](docs/images/settings.png)

## Quickstart

### Requirements
- Python 3.12
- Node.js 18 or later
- uv (Python package manager)

See [INSTALLATION.md](INSTALLATION.md) for detailed installation steps.

### Simplified Setup

#### 1. Backend
```bash
# Install dependencies
uv sync

# Set environment variables (create a .env file)
# AZURE_OPENAI_ENDPOINT=your_endpoint_here
# AZURE_OPENAI_API_KEY=your_api_key_here

# Download SpeechBrain model (important!)
uv run python download_model.py

# Start the server
uv run uvicorn backend.app.main:app --reload
```

**Using OSS Whisper:**
```bash
# Add the following to .env (Azure OpenAI settings not required)
# WHISPER_PROVIDER=faster-whisper
# OSS_WHISPER_MODEL=base  # tiny/base/small/medium/large-v2/large-v3
# OSS_WHISPER_DEVICE=cpu  # or cuda (for GPU)

# Resync dependencies
uv sync

# Start the server
uv run uvicorn backend.app.main:app --reload
```

**Using Ollama (local LLM):**
```bash
# Ensure Ollama is running (default: http://localhost:11434)
ollama serve &

# Pull the required model (example: llama3.1)
ollama pull llama3.1

# Add the following to .env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3.1

# Start the server
uv run uvicorn backend.app.main:app --reload
```

Selecting **Ollama (on-premises)** in the Settings â€œProviderâ€ option overrides the .env values so each request uses the specified `ollama_base_url` and `ollama_model` (defaults: `http://localhost:11434/v1` / `llama3.1`).

#### 2. Frontend
```bash
cd frontend
npm install
npm run dev -- --host
```

The application is available at `http://localhost:5173`.

## Detailed Features

### 1. Transcription
- **Provider selection**:
  - **Azure OpenAI**: GPT-4o (with speaker identification) or Whisper (transcription only)
  - **OSS Whisper**: faster-whisper (transcription only; use SpeechBrain later for speaker identification)
- **Supported formats**: MP3, WAV, MP4, M4A
- **Timestamps**: Record start/end times for each segment

### 2. Speaker Management
- **Speaker registration**:
  - Register from transcription segments
  - Register directly from audio files
- **Speaker identification**:
  - Automatic detection of registered speakers
  - Cosine similarity matching (threshold: 0.65)
- **Embedding file generation**:
  - Generate and download speaker feature files (.npy) from audio
  - Generate files without registering them in the system

### 3. Summary Generation
- **Prompt selection**:
  - Standard: Balanced summary
  - Detailed: In-depth analysis including background and context
  - Concise: Bullet points of key items only
- **Outputs**:
  - Meeting summary
  - Decisions
  - Action items

## API Endpoints

### Minutes Management
- `GET /api/minutes` - List minutes
- `POST /api/minutes` - Create minutes
- `GET /api/minutes/{id}` - Get minutes detail
- `GET /api/minutes/{id}/download` - Download minutes

### Audio Processing
- `POST /api/process_audio` - Audio processing (transcription and speaker identification)

### Speaker Management
- `GET /api/speakers` - List registered speakers
- `POST /api/speakers` - Add a speaker
- `DELETE /api/speakers/{name}` - Delete a speaker
- `POST /api/register_speaker` - Register a speaker from a segment
- `POST /api/create_speaker_embedding` - Generate a speaker embedding file

### Summary Generation
- `GET /api/prompts` - List summary prompts
- `POST /api/generate_summary` - Generate a summary

See the Swagger UI at `http://localhost:8000/docs` for details.

## Usage

### Navigation Bar
Use the navigation bar at the top to access each feature screen:
- **Minute Creation**: Main minutes creation workflow
- **Speaker Management**: Register/Delete speakers and generate embedding files
- **Prompt Management**: Manage prompts for summarization
- **Settings**: Choose LLM providers and Whisper models

### Settings Options
- **LLM Model**: Choose the model (e.g., GPT-4o) used for minutes generation.
- **Provider**: Switch providers such as Azure OpenAI or a local LLM.
- **Whisper Model**: Configure faster-whisper model size and device.

**Important**: Work in each screen is preserved even when switching tabs. You can change settings or register speakers while transcription is running, then return to the â€œMinute Creationâ€ tab to continue.

### Basic Flow
1. Select the **Minute Creation** tab (default view)
2. Drag & drop an audio or video file
3. Choose a model (GPT-4o / Whisper) (can be preset in Settings)
4. Click â€œStart Generationâ€
5. Review and edit transcription results when processing completes
6. Register speakers as needed (also possible in the Speaker Management tab)
7. Choose a summary prompt and generate the summary
8. Download the minutes as Word / Excel

## Speaker Registration Methods

#### Method 1: Register from Segments
1. Click the â€œ+â€ icon in the transcription table
2. Enter the speaker name
3. Click â€œRegisterâ€
4. The same voice will be identified automatically in future processing

#### Method 2: Register from an Audio File
1. Go to the â€œSpeaker Managementâ€ page
2. In â€œNew Registration,â€ choose a speaker name and audio file
3. Click â€œRegisterâ€

#### Method 3: Generate an Embedding File (without registration)
1. Go to the â€œSpeaker Managementâ€ page
2. In â€œEmbedding File Generator,â€ select an audio file
3. Click â€œGenerate & Downloadâ€
4. A `.npy` file will be downloaded
5. The file can be used later in another system

## Project Structure

```
minute_maker/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ azure_conversation_generation.py  # Azure OpenAI conversation generation
â”‚   â”‚   â””â”€â”€ tests/                     # Backend tests
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ uploads/                   # Uploaded audio files
â”‚   â”‚   â””â”€â”€ speakers/                  # Registered speaker embedding files
â”‚   â”œâ”€â”€ tmp_model/                     # SpeechBrain model files
â”‚   â””â”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ MinuteGenerator.tsx   # Main minutes generation component
â”‚   â”‚   â”‚   â””â”€â”€ SpeakerManager.tsx    # Speaker management component
â”‚   â”‚   â”œâ”€â”€ App.tsx                    # Top-level application
â”‚   â”‚   â””â”€â”€ main.tsx                   # Entry point
â”‚   â”œâ”€â”€ public/                        # Static assets
â”‚   â””â”€â”€ package.json                   # Node dependencies
â”œâ”€â”€ download_model.py                  # SpeechBrain model download script
â”œâ”€â”€ .env                               # Environment variables (to be created)
â”œâ”€â”€ AGENTS.md                          # AI development log
â”œâ”€â”€ INSTALLATION.md                    # Installation guide
â””â”€â”€ README.md                          # This file
```

## Tech Stack

### Backend
- **FastAPI**: High-performance Python web framework
- **Azure OpenAI**: Transcription/Summarization with GPT-4o / Whisper (optional)
- **faster-whisper**: OSS Whisper for fast transcription (optional)
- **SpeechBrain**: Speaker recognition (ECAPA-TDNN model)
- **PyTorch**: Machine learning framework
- **pydub**: Audio file conversion

### Frontend
- **React 18**: UI library
- **TypeScript**: Type safety
- **Vite**: Fast build tool
- **Lucide React**: Icon library

## Troubleshooting

### SpeechBrain Model Fails to Load
1. Run `download_model.py` to download the model.
2. Ensure the following files exist in `backend/tmp_model/`:
   - `embedding_model.ckpt` (79.46 MB)
   - `classifier.ckpt` (5.28 MB)
   - `label_encoder.txt`
   - `hyperparams.yaml`

### 404 Errors
- Confirm both backend and frontend are running.
- Ensure the `VITE_API_BASE` environment variable is set correctly (default: `http://localhost:8000`).

### Speaker Identification Not Working
1. Verify the SpeechBrain model is downloaded correctly.
2. Ensure at least one speaker is registered.
3. Confirm the audio segment is at least 0.5 seconds long.

See the troubleshooting section in [INSTALLATION.md](INSTALLATION.md) for details.

## Production Build & Deployment

### Frontend
```bash
cd frontend
npm run build
```
Build outputs are placed in `frontend/dist/`.

### Backend
```bash
# Uvicorn (development)
uvicorn backend.app.main:app --host 0.0.0.0 --port 8000

# Gunicorn + Uvicorn workers (production)
gunicorn backend.app.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

## License

This project is released under the MIT License.

This project uses open-source libraries under MIT, Apache 2.0, BSD-3-Clause, and other licenses. See [NOTICE.md](NOTICE.md) for details on third-party libraries.

## Support

- **Development Log**: [AGENTS.md](AGENTS.md)
- **Installation Guide**: [INSTALLATION.md](INSTALLATION.md)
- **License Information**: [NOTICE.md](NOTICE.md)
- **API Documentation**: `http://localhost:8000/docs`

## Acknowledgements

This project uses the following open-source projects:
- [SpeechBrain](https://speechbrain.github.io/)
- [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [React](https://react.dev/)

---

# Minute Makerï¼ˆæ—¥æœ¬èªï¼‰

FastAPI ã¨ Vite + React + TypeScript ã‚’çµ„ã¿åˆã‚ã›ãŸè­°äº‹éŒ²è‡ªå‹•ç”Ÿæˆã‚¢ãƒ—ãƒªã§ã™ã€‚éŸ³å£°ã‚„å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€æ–‡å­—èµ·ã“ã—ãƒ»è©±è€…è­˜åˆ¥ãƒ»è¦ç´„ã‚’è¡Œã„ã€Word / Excel å½¢å¼ã®è­°äº‹éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚

## ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

Minute Makerã¯ã€**ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’æœ€å„ªå…ˆ**ã«è¨­è¨ˆã•ã‚ŒãŸè­°äº‹éŒ²ä½œæˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚¯ãƒ©ã‚¦ãƒ‰ã‚„ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ç’°å¢ƒã§ã®é‹ç”¨ã‚’æƒ³å®šã—ã€ä¼æ¥­ã‚„çµ„ç¹”ã®å³æ ¼ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶ã«å¯¾å¿œã—ã¾ã™ã€‚

### ä¸»è¦ãªè¨­è¨ˆæ€æƒ³

#### ğŸ”’ ã‚»ã‚­ãƒ¥ã‚¢ãªè¨­è¨ˆ
- **ä¼šè­°çµæœã‚’æ°¸ç¶šåŒ–ã—ãªã„**: ã‚µãƒ¼ãƒå´ã«æ–‡å­—èµ·ã“ã—çµæœã‚„è¦ç´„ã‚’ä¿å­˜ã—ã¾ã›ã‚“
- **æœ€å°é™ã®è¢«å®³**: ã‚µã‚¤ãƒãƒ¼æ”»æ’ƒã‚’å—ã‘ãŸå ´åˆã§ã‚‚ã€æ©Ÿå¯†æƒ…å ±ã®æ¼æ´©ãƒªã‚¹ã‚¯ã‚’æœ€å°åŒ–
- **å‡¦ç†å®Œäº†å¾Œã¯è‡ªå‹•å‰Šé™¤**: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‡¦ç†å¾Œã«å‰Šé™¤å¯èƒ½
- **ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯¾å¿œ**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰éš”é›¢ã•ã‚ŒãŸç’°å¢ƒã§ã‚‚å‹•ä½œ

#### ğŸ¯ ä¼æ¥­å›ºæœ‰ã®ãƒã‚¦ãƒã‚¦ã‚’åæ˜ 
- **æŸ”è»Ÿãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ**: çµ„ç¹”ç‰¹æœ‰ã®è­°äº‹éŒ²ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚„ç”¨èªã«å¯¾å¿œ
- **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªè¦ç´„**: æ¥­ç•Œæ…£ç¿’ã‚„ç¤¾å†…ãƒ«ãƒ¼ãƒ«ã‚’åæ˜ ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
- **æ‹¡å¼µæ€§**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¿½åŠ ãƒ»ç·¨é›†ã«ã‚ˆã‚Šã€éƒ¨é–€ã”ã¨ã®è¦ä»¶ã«å¯¾å¿œ

#### ğŸ¢ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆç’°å¢ƒã§ã®é‹ç”¨
- **ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹å¯¾å¿œ**: è‡ªç¤¾ã‚µãƒ¼ãƒãƒ¼ã‚„å°‚ç”¨ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§å®Œçµ
- **LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠå¯èƒ½**: Azure OpenAIã€Ollamaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMï¼‰ãªã©è¤‡æ•°ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¯¾å¿œ
- **Whisperå®Ÿè£…ã®é¸æŠ**: ã‚¯ãƒ©ã‚¦ãƒ‰ã¾ãŸã¯OSSç‰ˆï¼ˆfaster-whisperï¼‰ã‚’ç’°å¢ƒã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘

## ã‚¢ãƒ—ãƒªã®æ¦‚è¦

### ä¸»è¦æ©Ÿèƒ½
- **éŸ³å£°ãƒ»å‹•ç”»ã®æ–‡å­—èµ·ã“ã—**:
  - Azure OpenAIï¼ˆGPT-4o / Whisperï¼‰ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãªæ–‡å­—èµ·ã“ã—ã¨è©±è€…è­˜åˆ¥
  - OSSç‰ˆWhisperï¼ˆfaster-whisperï¼‰ã«ã‚ˆã‚‹é«˜é€Ÿãªæ–‡å­—èµ·ã“ã—
- **è©±è€…è­˜åˆ¥**: SpeechBrainã‚’ä½¿ç”¨ã—ãŸè‡ªå‹•è©±è€…è­˜åˆ¥ã¨è©±è€…ç™»éŒ²æ©Ÿèƒ½
- **è¦ç´„ç”Ÿæˆ**: Azure OpenAI GPT-4oã«ã‚ˆã‚‹è­°äº‹éŒ²ã®è‡ªå‹•è¦ç´„
- **è­°äº‹éŒ²ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**: Word / Excel å½¢å¼ã§ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- **è©±è€…ç®¡ç†**:
  - è©±è€…ã®ç™»éŒ²ãƒ»å‰Šé™¤
  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«(.npy)ã®ç”Ÿæˆãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- **ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³**:
  - è­°äº‹éŒ²ä½œæˆã€è©±è€…ç®¡ç†ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã€è¨­å®šç”»é¢ã®é–“ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«åˆ‡ã‚Šæ›¿ãˆ
  - ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆæ™‚ã‚‚ä½œæ¥­å†…å®¹ã‚’ä¿æŒ

### å‡¦ç†ãƒ•ãƒ­ãƒ¼
1. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: MP3/WAV/MP4/M4A å¯¾å¿œã®ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—
2. **æ–‡å­—èµ·ã“ã—**: é¸æŠãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-4o / Whisperï¼‰ã§éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
3. **è©±è€…è­˜åˆ¥**: ç™»éŒ²æ¸ˆã¿è©±è€…ã®è‡ªå‹•è­˜åˆ¥
4. **ç¢ºèªãƒ»ç·¨é›†**: ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ï¼ˆé–‹å§‹ãƒ»çµ‚äº†æ™‚é–“ã€è©±è€…ã€ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã§è¡¨ç¤ºãƒ»ç·¨é›†
5. **è¦ç´„ãƒ»æ•´å½¢**: è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠã—ã¦è­°äº‹éŒ²ã‚’ç”Ÿæˆ
6. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: Word / Excel å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

## ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ

### ãƒ›ãƒ¼ãƒ ç”»é¢ (è­°äº‹éŒ²ä½œæˆ)
ã‚·ãƒ³ãƒ—ãƒ«ã§ç›´æ„Ÿçš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»é¢ã§ã™ã€‚
![Home](docs/images/home.png)

### è©±è€…ç®¡ç†
ç™»éŒ²æ¸ˆã¿è©±è€…ã®ç®¡ç†ã‚„ã€åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¯èƒ½ã§ã™ã€‚
![Speaker Manager](docs/images/speaker_manager.png)

### è¨­å®š
LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚„ãƒ¢ãƒ‡ãƒ«ã®é¸æŠã€Whisperã®è¨­å®šãªã©ã‚’æŸ”è»Ÿã«å¤‰æ›´ã§ãã¾ã™ã€‚
![Settings](docs/images/settings.png)

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### å‰ææ¡ä»¶
- Python 3.12
- Node.js 18 ä»¥é™
- uv (Python ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼)

è©³ç´°ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ã¯ [INSTALLATION.md](INSTALLATION.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### ç°¡æ˜“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 1. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
```bash
# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv sync

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼‰
# AZURE_OPENAI_ENDPOINT=your_endpoint_here
# AZURE_OPENAI_API_KEY=your_api_key_here

# SpeechBrainãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆé‡è¦ï¼ï¼‰
uv run python download_model.py

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
uv run uvicorn backend.app.main:app --reload
```

**OSSç‰ˆWhisperã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ:**
```bash
# .envãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼ˆAzure OpenAIè¨­å®šã¯ä¸è¦ï¼‰
# WHISPER_PROVIDER=faster-whisper
# OSS_WHISPER_MODEL=base  # tiny/base/small/medium/large-v2/large-v3
# OSS_WHISPER_DEVICE=cpu  # ã¾ãŸã¯ cudaï¼ˆGPUä½¿ç”¨æ™‚ï¼‰

# ä¾å­˜é–¢ä¿‚ã®å†åŒæœŸ
uv sync

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
uv run uvicorn backend.app.main:app --reload
```

**Ollamaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMï¼‰ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ:**
```bash
# Ollama ãŒå‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: http://localhost:11434ï¼‰
ollama serve &

# å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆä¾‹: llama3.1ï¼‰
ollama pull llama3.1

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¿½åŠ 
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3.1

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
uv run uvicorn backend.app.main:app --reload
```

è¨­å®šç”»é¢ã®ã€Œãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã€ã§ **Ollamaï¼ˆã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ï¼‰** ã‚’é¸æŠã™ã‚‹ã¨ã€.env ã®å€¤ã‚’ä¸Šæ›¸ãã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã« `ollama_base_url` ã¨ `ollama_model` ã‚’æŒ‡å®šã§ãã¾ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: `http://localhost:11434/v1` / `llama3.1`ï¼‰ã€‚

#### 2. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
```bash
cd frontend
npm install
npm run dev -- --host
```

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ `http://localhost:5173` ã§åˆ©ç”¨ã§ãã¾ã™ã€‚

## ä¸»è¦æ©Ÿèƒ½ã®è©³ç´°

### 1. æ–‡å­—èµ·ã“ã—
- **ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ**:
  - **Azure OpenAI**: GPT-4oï¼ˆè©±è€…è­˜åˆ¥è¾¼ã¿ï¼‰ã¾ãŸã¯Whisperï¼ˆæ–‡å­—èµ·ã“ã—ã®ã¿ï¼‰
  - **OSS Whisper**: faster-whisperï¼ˆæ–‡å­—èµ·ã“ã—ã®ã¿ã€å¾Œã‹ã‚‰SpeechBrainã§è©±è€…è­˜åˆ¥ï¼‰
- **å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: MP3, WAV, MP4, M4A
- **ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—**: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®é–‹å§‹ãƒ»çµ‚äº†æ™‚åˆ»ã‚’è¨˜éŒ²

### 2. è©±è€…ç®¡ç†
- **è©±è€…ç™»éŒ²**:
  - æ–‡å­—èµ·ã“ã—çµæœã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰è©±è€…ã‚’ç™»éŒ²
  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç›´æ¥ç™»éŒ²
- **è©±è€…è­˜åˆ¥**:
  - ç™»éŒ²æ¸ˆã¿è©±è€…ã®è‡ªå‹•æ¤œå‡º
  - ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã«ã‚ˆã‚‹ç…§åˆï¼ˆé–¾å€¤: 0.65ï¼‰
- **åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ**:
  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è©±è€…ç‰¹å¾´é‡ï¼ˆ.npyï¼‰ã‚’ç”Ÿæˆãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  - ã‚·ã‚¹ãƒ†ãƒ ã«ç™»éŒ²ã›ãšãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã®ã¿ã‚‚å¯èƒ½

### 3. è¦ç´„ç”Ÿæˆ
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ**:
  - æ¨™æº–æ ¡æ­£: ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸè¦ç´„
  - è©³ç´°: èƒŒæ™¯æƒ…å ±ã¨çµŒç·¯ã‚’å«ã‚€è©³ç´°åˆ†æ
  - ç°¡æ½”: è¦ç‚¹ã®ã¿ã®ç®‡æ¡æ›¸ã
- **å‡ºåŠ›å†…å®¹**:
  - ä¼šè­°ã®è¦ç´„
  - æ±ºå®šäº‹é …
  - ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 

## API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

### è­°äº‹éŒ²ç®¡ç†
- `GET /api/minutes` - è­°äº‹éŒ²ä¸€è¦§å–å¾—
- `POST /api/minutes` - è­°äº‹éŒ²ä½œæˆ
- `GET /api/minutes/{id}` - è­°äº‹éŒ²è©³ç´°å–å¾—
- `GET /api/minutes/{id}/download` - è­°äº‹éŒ²ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

### éŸ³å£°å‡¦ç†
- `POST /api/process_audio` - éŸ³å£°å‡¦ç†ï¼ˆæ–‡å­—èµ·ã“ã—ãƒ»è©±è€…è­˜åˆ¥ï¼‰

### è©±è€…ç®¡ç†
- `GET /api/speakers` - ç™»éŒ²æ¸ˆã¿è©±è€…ä¸€è¦§
- `POST /api/speakers` - è©±è€…è¿½åŠ 
- `DELETE /api/speakers/{name}` - è©±è€…å‰Šé™¤
- `POST /api/register_speaker` - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰è©±è€…ç™»éŒ²
- `POST /api/create_speaker_embedding` - è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ

### è¦ç´„ç”Ÿæˆ
- `GET /api/prompts` - è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§
- `POST /api/generate_summary` - è¦ç´„ç”Ÿæˆ

è©³ç´°ã¯ `http://localhost:8000/docs` ã®Swagger UIã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ä½¿ã„æ–¹

### ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä¸Šéƒ¨ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã§å„æ©Ÿèƒ½ç”»é¢ã«ç§»å‹•ã§ãã¾ã™ï¼š
- **è­°äº‹éŒ²ä½œæˆ**: ãƒ¡ã‚¤ãƒ³ã®è­°äº‹éŒ²ä½œæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **è©±è€…ç®¡ç†**: è©±è€…ã®ç™»éŒ²ãƒ»å‰Šé™¤ã€åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†**: è¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç®¡ç†
- **è¨­å®š**: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚„Whisperãƒ¢ãƒ‡ãƒ«ã®é¸æŠ

### è¨­å®šç”»é¢ã§é¸æŠã§ãã‚‹é …ç›®
- **LLMãƒ¢ãƒ‡ãƒ«**: GPT-4o ãªã©ã€è­°äº‹éŒ²ç”Ÿæˆã«åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠå¯èƒ½ã§ã™ã€‚
- **ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼**: Azure OpenAI ã‚„ãƒ­ãƒ¼ã‚«ãƒ«LLMãªã©ã€åˆ©ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚
- **Whisperãƒ¢ãƒ‡ãƒ«**: faster-whisper ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„ãƒ‡ãƒã‚¤ã‚¹ã‚’è¨­å®šã§ãã¾ã™ã€‚

**é‡è¦**: ã‚¿ãƒ–ã‚’åˆ‡ã‚Šæ›¿ãˆã¦ã‚‚ã€å„ç”»é¢ã®ä½œæ¥­å†…å®¹ã¯ä¿æŒã•ã‚Œã¾ã™ã€‚æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã§ã‚‚ã€è¨­å®šå¤‰æ›´ã‚„è©±è€…ç™»éŒ²ã®ãŸã‚ã«ä»–ã®ã‚¿ãƒ–ã«ç§»å‹•ã—ã€å¾Œã§ã€Œè­°äº‹éŒ²ä½œæˆã€ã‚¿ãƒ–ã«æˆ»ã£ã¦ä½œæ¥­ã‚’ç¶šã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

### åŸºæœ¬çš„ãªæµã‚Œ
1. **è­°äº‹éŒ²ä½œæˆ**ã‚¿ãƒ–ã‚’é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¡¨ç¤ºï¼‰
2. éŸ³å£°ã¾ãŸã¯å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—
3. ãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-4o / Whisperï¼‰ã‚’é¸æŠï¼ˆè¨­å®šã‚¿ãƒ–ã§äº‹å‰ã«è¨­å®šå¯èƒ½ï¼‰
4. ã€Œç”Ÿæˆã‚’é–‹å§‹ã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
5. å‡¦ç†å®Œäº†å¾Œã€æ–‡å­—èµ·ã“ã—çµæœã‚’ç¢ºèªãƒ»ç·¨é›†
6. å¿…è¦ã«å¿œã˜ã¦è©±è€…ã‚’ç™»éŒ²ï¼ˆè©±è€…ç®¡ç†ã‚¿ãƒ–ã§ã‚‚å¯èƒ½ï¼‰
7. è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠã—ã¦è¦ç´„ã‚’ç”Ÿæˆ
8. Word / Excelã§è­°äº‹éŒ²ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

## è©±è€…ç™»éŒ²æ–¹æ³•

#### æ–¹æ³•1: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ç™»éŒ²
1. æ–‡å­—èµ·ã“ã—çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã®ã€Œï¼‹ã€ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
2. è©±è€…åã‚’å…¥åŠ›
3. ã€Œç™»éŒ²ã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
4. ä»¥é™ã®å‡¦ç†ã§è‡ªå‹•çš„ã«åŒã˜å£°ãŒè­˜åˆ¥ã•ã‚Œã¾ã™

#### æ–¹æ³•2: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç™»éŒ²
1. ã€Œè©±è€…ç®¡ç†ã€ãƒšãƒ¼ã‚¸ã«ç§»å‹•
2. ã€Œæ–°è¦ç™»éŒ²ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è©±è€…åã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
3. ã€Œç™»éŒ²ã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯

#### æ–¹æ³•3: åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆï¼ˆç™»éŒ²ãªã—ï¼‰
1. ã€Œè©±è€…ç®¡ç†ã€ãƒšãƒ¼ã‚¸ã«ç§»å‹•
2. ã€ŒåŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ„ãƒ¼ãƒ«ã€ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
3. ã€Œç”Ÿæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
4. `.npy`ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™
5. ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¾Œã§åˆ¥ã®ã‚·ã‚¹ãƒ†ãƒ ã§ä½¿ç”¨ã§ãã¾ã™

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

```
minute_maker/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”‚   â”œâ”€â”€ azure_conversation_generation.py  # Azure OpenAIä¼šè©±ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ tests/                     # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ uploads/                   # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”‚   â””â”€â”€ speakers/                  # ç™»éŒ²æ¸ˆã¿è©±è€…ã®åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ tmp_model/                     # SpeechBrainãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â””â”€â”€ requirements.txt               # Pythonä¾å­˜é–¢ä¿‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ MinuteGenerator.tsx   # ãƒ¡ã‚¤ãƒ³è­°äº‹éŒ²ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
â”‚   â”‚   â”‚   â””â”€â”€ SpeakerManager.tsx    # è©±è€…ç®¡ç†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
â”‚   â”‚   â”œâ”€â”€ App.tsx                    # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”‚   â””â”€â”€ main.tsx                   # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ public/                        # é™çš„ã‚¢ã‚»ãƒƒãƒˆ
â”‚   â””â”€â”€ package.json                   # Nodeä¾å­˜é–¢ä¿‚
â”œâ”€â”€ download_model.py                  # SpeechBrainãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ .env                               # ç’°å¢ƒå¤‰æ•°ï¼ˆè¦ä½œæˆï¼‰
â”œâ”€â”€ AGENTS.md                          # AIé–‹ç™ºãƒ­ã‚°
â”œâ”€â”€ INSTALLATION.md                    # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰
â””â”€â”€ README.md                          # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
- **FastAPI**: é«˜é€ŸãªPython Webãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **Azure OpenAI**: GPT-4o / Whisper ã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã—ãƒ»è¦ç´„ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- **faster-whisper**: OSSç‰ˆWhisperï¼ˆé«˜é€Ÿæ–‡å­—èµ·ã“ã—ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- **SpeechBrain**: è©±è€…èªè­˜ï¼ˆECAPA-TDNN ãƒ¢ãƒ‡ãƒ«ï¼‰
- **PyTorch**: æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **pydub**: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
- **React 18**: UIãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **TypeScript**: å‹å®‰å…¨æ€§
- **Vite**: é«˜é€Ÿãƒ“ãƒ«ãƒ‰ãƒ„ãƒ¼ãƒ«
- **Lucide React**: ã‚¢ã‚¤ã‚³ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### SpeechBrainãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã‚ãªã„
1. `download_model.py` ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
2. `backend/tmp_model/` ã«ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª:
   - `embedding_model.ckpt` (79.46 MB)
   - `classifier.ckpt` (5.28 MB)
   - `label_encoder.txt`
   - `hyperparams.yaml`

### 404ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹
- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒä¸¡æ–¹èµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
- `VITE_API_BASE` ç’°å¢ƒå¤‰æ•°ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: `http://localhost:8000`ï¼‰

### è©±è€…è­˜åˆ¥ãŒå‹•ä½œã—ãªã„
1. SpeechBrainãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
2. å°‘ãªãã¨ã‚‚1äººã®è©±è€…ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
3. éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒ0.5ç§’ä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª

è©³ç´°ã¯ [INSTALLATION.md](INSTALLATION.md) ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## æœ¬ç•ªãƒ“ãƒ«ãƒ‰ã¨ãƒ‡ãƒ—ãƒ­ã‚¤

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
```bash
cd frontend
npm run build
```
ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ `frontend/dist/` ã«å‡ºåŠ›ã•ã‚Œã¾ã™ã€‚

### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
```bash
# Uvicornï¼ˆé–‹ç™ºç”¨ï¼‰
uvicorn backend.app.main:app --host 0.0.0.0 --port 8000

# Gunicorn + Uvicorn workersï¼ˆæœ¬ç•ªç”¨ï¼‰
gunicorn backend.app.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ MIT ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€MITã€Apache 2.0ã€BSD-3-Clause ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãªã©ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ä½¿ç”¨ã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[NOTICE.md](NOTICE.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ã‚µãƒãƒ¼ãƒˆ

- **é–‹ç™ºãƒ­ã‚°**: [AGENTS.md](AGENTS.md)
- **ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰**: [INSTALLATION.md](INSTALLATION.md)
- **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±**: [NOTICE.md](NOTICE.md)
- **API Documentation**: `http://localhost:8000/docs`

## è¬è¾

ä»¥ä¸‹ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™:
- [SpeechBrain](https://speechbrain.github.io/)
- [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [React](https://react.dev/)
